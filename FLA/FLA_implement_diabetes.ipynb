{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main as a\n",
    "from datasets import load_diabetes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle as pkl\n",
    "from importlib import reload\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([data['X_train'][k] for k in data['X_train'].keys()], axis=1)\n",
    "X_test = pd.concat([data['X_test'][k] for k in data['X_test'].keys()], axis=1)\n",
    "X_raw = pd.concat([X_train, X_test], axis=0).to_numpy()\n",
    "y = pd.concat([data['y_train'], data['y_test']], axis=0).to_numpy().flatten()\n",
    "y_counts = np.unique(y, return_counts=True)[1]\n",
    "weight = torch.tensor([y_counts[0]/y_counts[1]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_imputed_not_norm = imputer.fit_transform(X_raw)\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X_imputed_not_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'main' from '/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/main.py'>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1380\n",
      "Epoch 2, Validation Loss: 1.1236\n",
      "Epoch 3, Validation Loss: 1.1483\n",
      "Epoch 4, Validation Loss: 1.1107\n",
      "Epoch 5, Validation Loss: 1.1083\n",
      "Epoch 6, Validation Loss: 1.1271\n",
      "Epoch 7, Validation Loss: 1.1275\n",
      "Epoch 8, Validation Loss: 1.1341\n",
      "Epoch 9, Validation Loss: 1.1186\n",
      "Epoch 10, Validation Loss: 1.1288\n",
      "Epoch 11, Validation Loss: 1.1471\n",
      "Epoch 12, Validation Loss: 1.1409\n",
      "Epoch 13, Validation Loss: 1.1359\n",
      "Epoch 14, Validation Loss: 1.1820\n",
      "Epoch 15, Validation Loss: 1.1645\n",
      "Early stopping after epoch 15 with validation loss 1.1083\n",
      "Test Loss: 1.2466, Test Score: 0.2978 for seed 1 and 0 heads.\n",
      "seed 2, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1711\n",
      "Epoch 2, Validation Loss: 1.1381\n",
      "Epoch 3, Validation Loss: 1.1454\n",
      "Epoch 4, Validation Loss: 1.1184\n",
      "Epoch 5, Validation Loss: 1.1253\n",
      "Epoch 6, Validation Loss: 1.1469\n",
      "Epoch 7, Validation Loss: 1.1363\n",
      "Epoch 8, Validation Loss: 1.1289\n",
      "Epoch 9, Validation Loss: 1.1545\n",
      "Epoch 10, Validation Loss: 1.1487\n",
      "Epoch 11, Validation Loss: 1.1600\n",
      "Epoch 12, Validation Loss: 1.1393\n",
      "Epoch 13, Validation Loss: 1.2601\n",
      "Epoch 14, Validation Loss: 1.2402\n",
      "Early stopping after epoch 14 with validation loss 1.1184\n",
      "Test Loss: 1.2060, Test Score: 0.2805 for seed 2 and 0 heads.\n",
      "seed 3, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1058\n",
      "Epoch 2, Validation Loss: 1.0944\n",
      "Epoch 3, Validation Loss: 1.1899\n",
      "Epoch 4, Validation Loss: 1.1073\n",
      "Epoch 5, Validation Loss: 1.1079\n",
      "Epoch 6, Validation Loss: 1.1139\n",
      "Epoch 7, Validation Loss: 1.1100\n",
      "Epoch 8, Validation Loss: 1.1298\n",
      "Epoch 9, Validation Loss: 1.1336\n",
      "Epoch 10, Validation Loss: 1.1206\n",
      "Epoch 11, Validation Loss: 1.1365\n",
      "Epoch 12, Validation Loss: 1.1472\n",
      "Early stopping after epoch 12 with validation loss 1.0944\n",
      "Test Loss: 1.1840, Test Score: 0.2561 for seed 3 and 0 heads.\n",
      "seed 4, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1729\n",
      "Epoch 2, Validation Loss: 1.1761\n",
      "Epoch 3, Validation Loss: 1.1567\n",
      "Epoch 4, Validation Loss: 1.1862\n",
      "Epoch 5, Validation Loss: 1.1508\n",
      "Epoch 6, Validation Loss: 1.1702\n",
      "Epoch 7, Validation Loss: 1.1669\n",
      "Epoch 8, Validation Loss: 1.1527\n",
      "Epoch 9, Validation Loss: 1.1706\n",
      "Epoch 10, Validation Loss: 1.1825\n",
      "Epoch 11, Validation Loss: 1.2191\n",
      "Epoch 12, Validation Loss: 1.1697\n",
      "Epoch 13, Validation Loss: 1.2016\n",
      "Epoch 14, Validation Loss: 1.2157\n",
      "Epoch 15, Validation Loss: 1.1886\n",
      "Early stopping after epoch 15 with validation loss 1.1508\n",
      "Test Loss: 1.1846, Test Score: 0.2640 for seed 4 and 0 heads.\n",
      "seed 5, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1656\n",
      "Epoch 2, Validation Loss: 1.1109\n",
      "Epoch 3, Validation Loss: 1.0955\n",
      "Epoch 4, Validation Loss: 1.0917\n",
      "Epoch 5, Validation Loss: 1.0867\n",
      "Epoch 6, Validation Loss: 1.0824\n",
      "Epoch 7, Validation Loss: 1.1017\n",
      "Epoch 8, Validation Loss: 1.1091\n",
      "Epoch 9, Validation Loss: 1.0995\n",
      "Epoch 10, Validation Loss: 1.1218\n",
      "Epoch 11, Validation Loss: 1.1110\n",
      "Epoch 12, Validation Loss: 1.1210\n",
      "Epoch 13, Validation Loss: 1.1279\n",
      "Epoch 14, Validation Loss: 1.1465\n",
      "Epoch 15, Validation Loss: 1.1614\n",
      "Epoch 16, Validation Loss: 1.1888\n",
      "Early stopping after epoch 16 with validation loss 1.0824\n",
      "Test Loss: 1.2360, Test Score: 0.2570 for seed 5 and 0 heads.\n",
      "seed 6, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1920\n",
      "Epoch 2, Validation Loss: 1.1144\n",
      "Epoch 3, Validation Loss: 1.1240\n",
      "Epoch 4, Validation Loss: 1.1042\n",
      "Epoch 5, Validation Loss: 1.1004\n",
      "Epoch 6, Validation Loss: 1.0945\n",
      "Epoch 7, Validation Loss: 1.1313\n",
      "Epoch 8, Validation Loss: 1.1071\n",
      "Epoch 9, Validation Loss: 1.1467\n",
      "Epoch 10, Validation Loss: 1.1559\n",
      "Epoch 11, Validation Loss: 1.1390\n",
      "Epoch 12, Validation Loss: 1.1795\n",
      "Epoch 13, Validation Loss: 1.1862\n",
      "Epoch 14, Validation Loss: 1.2110\n",
      "Epoch 15, Validation Loss: 1.2888\n",
      "Epoch 16, Validation Loss: 1.3081\n",
      "Early stopping after epoch 16 with validation loss 1.0945\n",
      "Test Loss: 1.2933, Test Score: 0.2569 for seed 6 and 0 heads.\n",
      "seed 7, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1415\n",
      "Epoch 2, Validation Loss: 1.1291\n",
      "Epoch 3, Validation Loss: 1.1702\n",
      "Epoch 4, Validation Loss: 1.1272\n",
      "Epoch 5, Validation Loss: 1.1325\n",
      "Epoch 6, Validation Loss: 1.1191\n",
      "Epoch 7, Validation Loss: 1.1148\n",
      "Epoch 8, Validation Loss: 1.1413\n",
      "Epoch 9, Validation Loss: 1.1120\n",
      "Epoch 10, Validation Loss: 1.1261\n",
      "Epoch 11, Validation Loss: 1.1744\n",
      "Epoch 12, Validation Loss: 1.1309\n",
      "Epoch 13, Validation Loss: 1.1162\n",
      "Epoch 14, Validation Loss: 1.1738\n",
      "Epoch 15, Validation Loss: 1.1976\n",
      "Epoch 16, Validation Loss: 1.2136\n",
      "Epoch 17, Validation Loss: 1.1681\n",
      "Epoch 18, Validation Loss: 1.1715\n",
      "Epoch 19, Validation Loss: 1.1796\n",
      "Early stopping after epoch 19 with validation loss 1.1120\n",
      "Test Loss: 1.2148, Test Score: 0.2863 for seed 7 and 0 heads.\n",
      "seed 8, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1736\n",
      "Epoch 2, Validation Loss: 1.1552\n",
      "Epoch 3, Validation Loss: 1.2090\n",
      "Epoch 4, Validation Loss: 1.1971\n",
      "Epoch 5, Validation Loss: 1.1436\n",
      "Epoch 6, Validation Loss: 1.2013\n",
      "Epoch 7, Validation Loss: 1.1842\n",
      "Epoch 8, Validation Loss: 1.1595\n",
      "Epoch 9, Validation Loss: 1.1517\n",
      "Epoch 10, Validation Loss: 1.1586\n",
      "Epoch 11, Validation Loss: 1.1763\n",
      "Epoch 12, Validation Loss: 1.2084\n",
      "Epoch 13, Validation Loss: 1.1942\n",
      "Epoch 14, Validation Loss: 1.2381\n",
      "Epoch 15, Validation Loss: 1.2480\n",
      "Early stopping after epoch 15 with validation loss 1.1436\n",
      "Test Loss: 1.2630, Test Score: 0.2987 for seed 8 and 0 heads.\n",
      "seed 9, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1780\n",
      "Epoch 2, Validation Loss: 1.1638\n",
      "Epoch 3, Validation Loss: 1.1468\n",
      "Epoch 4, Validation Loss: 1.1465\n",
      "Epoch 5, Validation Loss: 1.1867\n",
      "Epoch 6, Validation Loss: 1.1413\n",
      "Epoch 7, Validation Loss: 1.1798\n",
      "Epoch 8, Validation Loss: 1.1717\n",
      "Epoch 9, Validation Loss: 1.1353\n",
      "Epoch 10, Validation Loss: 1.1475\n",
      "Epoch 11, Validation Loss: 1.1308\n",
      "Epoch 12, Validation Loss: 1.1600\n",
      "Epoch 13, Validation Loss: 1.2021\n",
      "Epoch 14, Validation Loss: 1.2292\n",
      "Epoch 15, Validation Loss: 1.1693\n",
      "Epoch 16, Validation Loss: 1.2760\n",
      "Epoch 17, Validation Loss: 1.2995\n",
      "Epoch 18, Validation Loss: 1.2249\n",
      "Epoch 19, Validation Loss: 1.3403\n",
      "Epoch 20, Validation Loss: 1.4321\n",
      "Epoch 21, Validation Loss: 1.3922\n",
      "Early stopping after epoch 21 with validation loss 1.1308\n",
      "Test Loss: 1.3725, Test Score: 0.2455 for seed 9 and 0 heads.\n",
      "seed 10, with 0 heads\n",
      "Epoch 1, Validation Loss: 1.1509\n",
      "Epoch 2, Validation Loss: 1.2167\n",
      "Epoch 3, Validation Loss: 1.1750\n",
      "Epoch 4, Validation Loss: 1.1442\n",
      "Epoch 5, Validation Loss: 1.1358\n",
      "Epoch 6, Validation Loss: 1.1509\n",
      "Epoch 7, Validation Loss: 1.1548\n",
      "Epoch 8, Validation Loss: 1.1412\n",
      "Epoch 9, Validation Loss: 1.1655\n",
      "Epoch 10, Validation Loss: 1.1704\n",
      "Epoch 11, Validation Loss: 1.1662\n",
      "Epoch 12, Validation Loss: 1.1959\n",
      "Epoch 13, Validation Loss: 1.1793\n",
      "Epoch 14, Validation Loss: 1.1748\n",
      "Epoch 15, Validation Loss: 1.2051\n",
      "Early stopping after epoch 15 with validation loss 1.1358\n",
      "Test Loss: 1.1977, Test Score: 0.3022 for seed 10 and 0 heads.\n"
     ]
    }
   ],
   "source": [
    "head_counts = [0]#[0,5,10,15]\n",
    "test_prediction_dict = {h: [] for h in head_counts}\n",
    "test_label_list = []\n",
    "losses = {h: [] for h in head_counts}\n",
    "\n",
    "forward_times = []\n",
    "loss_times = []\n",
    "backwards_times = []\n",
    "optimizer_times = []\n",
    "\n",
    "for seed in range(10):\n",
    "    for head in head_counts:\n",
    "        print(f'seed {seed+1}, with {head} heads')\n",
    "        #split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.2, random_state=seed)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, stratify=y_train, test_size=0.1, random_state=seed)\n",
    "        train_dataset = a.npDataset(X_train,y_train)\n",
    "        test_dataset = a.npDataset(X_test,y_test)\n",
    "        val_dataset = a.npDataset(X_val,y_val)\n",
    "        batch_size = 100\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        #make model\n",
    "        hidden_dims = [50,25,10]\n",
    "        attn_heads = head\n",
    "        model = a.FLANN(input_dim=108, hidden_dims=hidden_dims, output_dim=1, attn_heads=attn_heads, activation=nn.ReLU())\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        #train\n",
    "        num_epochs = 500\n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        patience = 10\n",
    "        early_stop_counter = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                start_f = time.time()\n",
    "                outputs = model(inputs)\n",
    "                end_f = time.time()\n",
    "                forward_times.append(end_f-start_f)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                start_l = time.time()\n",
    "                loss = criterion(outputs, labels)\n",
    "                end_l = time.time()\n",
    "                loss_times.append(end_l-start_l)\n",
    "                start_b = time.time()\n",
    "                loss.backward()\n",
    "                end_b = time.time()\n",
    "                backwards_times.append(end_b-start_b)\n",
    "                start_o = time.time()\n",
    "                optimizer.step()\n",
    "                end_o = time.time()\n",
    "                optimizer_times.append(end_o-start_o)\n",
    "\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            for inputs, labels in val_loader:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    labels = labels.unsqueeze(1)\n",
    "                    val_loss = criterion(outputs, labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "            \n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model = model.state_dict()\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "            \n",
    "            if early_stop_counter >= patience:\n",
    "                print(f'Early stopping after epoch {epoch+1} with validation loss {best_val_loss:.4f}')\n",
    "                break\n",
    "            \n",
    "        model.load_state_dict(best_model)\n",
    "\n",
    "        #eval\n",
    "        test_losses = []\n",
    "        test_predictions = []\n",
    "        test_true_labels = []\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                test_loss = criterion(outputs, labels)\n",
    "                test_losses.append(test_loss.item())\n",
    "                test_predictions.extend(outputs.cpu().numpy())\n",
    "                test_true_labels.extend(labels.cpu().numpy())\n",
    "        avg_test_loss = np.mean(test_losses)\n",
    "        test_predictions_f1 = [y>0.5 for y in test_predictions]\n",
    "        test_score = f1_score(test_true_labels, test_predictions_f1)\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}, Test Score: {test_score:.4f} for seed {seed+1} and {head} heads.')\n",
    "        if head == 0:\n",
    "            test_label_list.append(test_true_labels)\n",
    "        test_prediction_dict[head].append(test_predictions)\n",
    "        losses[head].append(avg_test_loss)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/diabetes/test_pred_dict_20s.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(test_prediction_dict, file=file)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/diabetes/test_losses_dict_20s.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(losses, file=file)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/diabetes/test_labels.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(test_label_list, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.20159912109375e-05\n",
      "2.3126602172851562e-05\n",
      "0.00014281272888183594\n",
      "0.0001850128173828125\n"
     ]
    }
   ],
   "source": [
    "print(np.median(forward_times))\n",
    "print(np.median(loss_times))\n",
    "print(np.median(backwards_times))\n",
    "print(np.median(optimizer_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Average epoch time: 0.047626495361328125'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Average epoch time: {(np.median(forward_times)+np.median(loss_times)+np.median(backwards_times)+np.median(optimizer_times))*110}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
