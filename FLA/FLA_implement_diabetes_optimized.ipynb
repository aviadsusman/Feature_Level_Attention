{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fla_parallelized as a\n",
    "from datasets import load_diabetes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle as pkl\n",
    "from importlib import reload\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import pickle as pkl\n",
    "# from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=os.getcwd()\n",
    "with open(f\"{cwd}/data/diabetes/X.pkl\", \"rb\") as file:\n",
    "    X_raw = pkl.load(file)\n",
    "with open(f\"{cwd}/data/diabetes/y.pkl\", \"rb\") as file:\n",
    "    y = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_counts = np.unique(y, return_counts=True)[1]\n",
    "weight = torch.tensor([y_counts[0]/y_counts[1]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_imputed_not_norm = imputer.fit_transform(X_raw)\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X_imputed_not_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15149, 108)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1, with 20 heads\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0787\n",
      "back: 0.1166\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0608\n",
      "back: 0.0955\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0624\n",
      "back: 0.0961\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0643\n",
      "back: 0.0990\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0638\n",
      "back: 0.0954\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0654\n",
      "back: 0.1019\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0644\n",
      "back: 0.1015\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0621\n",
      "back: 0.0914\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0595\n",
      "back: 0.0971\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0607\n",
      "back: 0.1047\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0586\n",
      "back: 0.0973\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0647\n",
      "back: 0.0950\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0622\n",
      "back: 0.0938\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0633\n",
      "back: 0.1030\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0673\n",
      "back: 0.1037\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0667\n",
      "back: 0.1051\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0646\n",
      "back: 0.1013\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0696\n",
      "back: 0.0958\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0612\n",
      "back: 0.1717\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0758\n",
      "back: 0.1125\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0737\n",
      "back: 0.1117\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0597\n",
      "back: 0.0943\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0609\n",
      "back: 0.0984\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0681\n",
      "back: 0.1006\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0608\n",
      "back: 0.0960\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0647\n",
      "back: 0.0938\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0598\n",
      "back: 0.1038\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0672\n",
      "back: 0.0994\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0715\n",
      "back: 0.1028\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0638\n",
      "back: 0.1163\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0719\n",
      "back: 0.1148\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0633\n",
      "back: 0.0952\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0639\n",
      "back: 0.0948\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0617\n",
      "back: 0.0988\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0625\n",
      "back: 0.1046\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0678\n",
      "back: 0.0972\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0604\n",
      "back: 0.0977\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0616\n",
      "back: 0.0941\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0595\n",
      "back: 0.0981\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0617\n",
      "back: 0.0940\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0605\n",
      "back: 0.0971\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0632\n",
      "back: 0.0960\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0614\n",
      "back: 0.0931\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0641\n",
      "back: 0.1016\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0620\n",
      "back: 0.1111\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0666\n",
      "back: 0.0960\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0630\n",
      "back: 0.0961\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0625\n",
      "back: 0.0982\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0588\n",
      "back: 0.0944\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0604\n",
      "back: 0.1004\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0611\n",
      "back: 0.1009\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0644\n",
      "back: 0.0929\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0661\n",
      "back: 0.1008\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0616\n",
      "back: 0.1041\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0631\n",
      "back: 0.0970\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0621\n",
      "back: 0.0989\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0704\n",
      "back: 0.0971\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0712\n",
      "back: 0.1033\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0598\n",
      "back: 0.0938\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0597\n",
      "back: 0.0942\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0593\n",
      "back: 0.0955\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0640\n",
      "back: 0.0978\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0639\n",
      "back: 0.0921\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0635\n",
      "back: 0.0964\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0561\n",
      "back: 0.0931\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0652\n",
      "back: 0.0951\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0628\n",
      "back: 0.0979\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0573\n",
      "back: 0.0990\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0654\n",
      "back: 0.0986\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0711\n",
      "back: 0.1015\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0607\n",
      "back: 0.0989\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0621\n",
      "back: 0.1005\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0649\n",
      "back: 0.0990\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0652\n",
      "back: 0.0975\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0646\n",
      "back: 0.0936\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0635\n",
      "back: 0.1015\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0602\n",
      "back: 0.0987\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0641\n",
      "back: 0.0979\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0657\n",
      "back: 0.1014\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0650\n",
      "back: 0.0987\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0620\n",
      "back: 0.1017\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0610\n",
      "back: 0.1015\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0638\n",
      "back: 0.1845\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0607\n",
      "back: 0.0995\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0650\n",
      "back: 0.0916\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0654\n",
      "back: 0.0986\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0579\n",
      "back: 0.0961\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0622\n",
      "back: 0.0974\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0632\n",
      "back: 0.0928\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0640\n",
      "back: 0.0963\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0633\n",
      "back: 0.1003\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0633\n",
      "back: 0.0922\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0610\n",
      "back: 0.0954\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0701\n",
      "back: 0.1061\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0626\n",
      "back: 0.0951\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0647\n",
      "back: 0.0907\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0564\n",
      "back: 0.0951\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0587\n",
      "back: 0.1007\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0637\n",
      "back: 0.0980\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0662\n",
      "back: 0.0978\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0606\n",
      "back: 0.0936\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0618\n",
      "back: 0.1050\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0649\n",
      "back: 0.0991\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0652\n",
      "back: 0.0985\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0605\n",
      "back: 0.0991\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0623\n",
      "back: 0.0970\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0595\n",
      "back: 0.0957\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0634\n",
      "back: 0.0949\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0633\n",
      "back: 0.0953\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0618\n",
      "back: 0.0935\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0673\n",
      "back: 0.0939\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0591\n",
      "back: 0.0954\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0651\n",
      "back: 0.0962\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0640\n",
      "back: 0.0959\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0609\n",
      "back: 0.1023\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0619\n",
      "back: 0.0974\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0592\n",
      "back: 0.1006\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0636\n",
      "back: 0.0992\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0645\n",
      "back: 0.0937\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0608\n",
      "back: 0.0957\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0586\n",
      "back: 0.0963\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0584\n",
      "back: 0.0957\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0633\n",
      "back: 0.1012\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0651\n",
      "back: 0.0940\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0617\n",
      "back: 0.0964\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0620\n",
      "back: 0.0961\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0632\n",
      "back: 0.0955\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0599\n",
      "back: 0.0993\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0611\n",
      "back: 0.0986\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0612\n",
      "back: 0.0987\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0614\n",
      "back: 0.0989\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0630\n",
      "back: 0.0974\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0636\n",
      "back: 0.0925\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0590\n",
      "back: 0.0960\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0649\n",
      "back: 0.0968\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0784\n",
      "back: 0.1006\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0605\n",
      "back: 0.0944\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0629\n",
      "back: 0.0957\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0616\n",
      "back: 0.0985\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0619\n",
      "back: 0.0981\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0619\n",
      "back: 0.0944\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0620\n",
      "back: 0.0950\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0624\n",
      "back: 0.0965\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0658\n",
      "back: 0.0998\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0633\n",
      "back: 0.0988\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0655\n",
      "back: 0.1005\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0642\n",
      "back: 0.1061\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0684\n",
      "back: 0.1035\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0688\n",
      "back: 0.0984\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0604\n",
      "back: 0.0983\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0679\n",
      "back: 0.0962\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0590\n",
      "back: 0.0972\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0623\n",
      "back: 0.0959\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0606\n",
      "back: 0.0957\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0632\n",
      "back: 0.1035\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0677\n",
      "back: 0.1131\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0671\n",
      "back: 0.0954\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0671\n",
      "back: 0.1089\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0666\n",
      "back: 0.1022\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0622\n",
      "back: 0.1002\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0637\n",
      "back: 0.1033\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0684\n",
      "back: 0.1018\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0664\n",
      "back: 0.0991\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0655\n",
      "back: 0.1006\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0647\n",
      "back: 0.1010\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0694\n",
      "back: 0.1073\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0653\n",
      "back: 0.0970\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0622\n",
      "back: 0.0966\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0665\n",
      "back: 0.1005\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0606\n",
      "back: 0.1009\n",
      "torch.Size([27, 1])\n",
      "forwards: 0.0320\n",
      "back: 0.0481\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([64, 1])\n",
      "torch.Size([60, 1])\n",
      "Epoch 1, Validation Loss: 1.1835\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0628\n",
      "back: 0.0994\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0641\n",
      "back: 0.1020\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0639\n",
      "back: 0.0981\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0600\n",
      "back: 0.0960\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0605\n",
      "back: 0.0989\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0723\n",
      "back: 0.1087\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0696\n",
      "back: 0.1058\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0649\n",
      "back: 0.1046\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0664\n",
      "back: 0.1005\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0694\n",
      "back: 0.1034\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0697\n",
      "back: 0.1099\n",
      "torch.Size([64, 1])\n",
      "forwards: 0.0787\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m loss_times\u001b[38;5;241m.\u001b[39mappend(end_l\u001b[38;5;241m-\u001b[39mstart_l)\n\u001b[1;32m     53\u001b[0m start_b \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 54\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m end_b \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mback: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_b\u001b[38;5;241m-\u001b[39mstart_b\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/.venv/lib/python3.11/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(a)\n",
    "head_counts = [20]#,2,3,4]\n",
    "test_prediction_dict = {h: [] for h in head_counts}\n",
    "test_label_list = []\n",
    "losses = {h: [] for h in head_counts}\n",
    "\n",
    "forward_times = []\n",
    "loss_times = []\n",
    "backwards_times = []\n",
    "optimizer_times = []\n",
    "\n",
    "for seed in range(10):\n",
    "    for i, head in enumerate(head_counts):\n",
    "        print(f'seed {seed+1}, with {head} heads')\n",
    "        #split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.2, random_state=seed)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, stratify=y_train, test_size=0.1, random_state=seed)\n",
    "        train_dataset = a.npDataset(X_train,y_train)\n",
    "        test_dataset = a.npDataset(X_test,y_test)\n",
    "        val_dataset = a.npDataset(X_val,y_val)\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        #make model\n",
    "        hidden_dims = [50,25,10]\n",
    "        attn_heads = head\n",
    "        model = a.FLANN(input_dim=108, hidden_dims=hidden_dims, output_dim=1, attn_heads=attn_heads, activation=nn.ReLU)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        #train\n",
    "        num_epochs = 500\n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        patience = 10\n",
    "        early_stop_counter = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                start_f = time.time()\n",
    "                outputs = model(inputs)\n",
    "                end_f = time.time()\n",
    "                print(f'forwards: {end_f-start_f:.4f}')\n",
    "                forward_times.append(end_f-start_f)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                start_l = time.time()\n",
    "                loss = criterion(outputs, labels)\n",
    "                end_l = time.time()\n",
    "                loss_times.append(end_l-start_l)\n",
    "                start_b = time.time()\n",
    "                loss.backward()\n",
    "                end_b = time.time()\n",
    "                print(f'back: {end_b-start_b:.4f}')\n",
    "                backwards_times.append(end_b-start_b)\n",
    "                start_o = time.time()\n",
    "                optimizer.step()\n",
    "                end_o = time.time()\n",
    "                optimizer_times.append(end_o-start_o)\n",
    "\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            for inputs, labels in val_loader:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    labels = labels.unsqueeze(1)\n",
    "                    val_loss = criterion(outputs, labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "            \n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model = model.state_dict()\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "            \n",
    "            if early_stop_counter >= patience:\n",
    "                print(f'Early stopping after epoch {epoch+1} with validation loss {best_val_loss:.4f}')\n",
    "                break\n",
    "            \n",
    "        model.load_state_dict(best_model)\n",
    "\n",
    "        #eval\n",
    "        test_losses = []\n",
    "        test_predictions = []\n",
    "        test_true_labels = []\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                test_loss = criterion(outputs, labels)\n",
    "                test_losses.append(test_loss.item())\n",
    "                test_predictions.extend(outputs.cpu().numpy())\n",
    "                test_true_labels.extend(labels.cpu().numpy())\n",
    "        avg_test_loss = np.mean(test_losses)\n",
    "        test_predictions_f1 = [y>0.5 for y in test_predictions]\n",
    "        test_score = f1_score(test_true_labels, test_predictions_f1)\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}, Test Score: {test_score:.4f} for seed {seed+1} and {head} heads.')\n",
    "        if i == 0:\n",
    "            test_label_list.append(test_true_labels)\n",
    "        test_prediction_dict[head].append(test_predictions)\n",
    "        losses[head].append(avg_test_loss)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/diabetes/test_pred_dict_1_to_4.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(test_prediction_dict, file=file)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/diabetes/test_losses_dict_1_to_4.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(losses, file=file)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/diabetes/test_labels.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(test_label_list, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006627082824707031\n",
      "9.012222290039062e-05\n",
      "0.010902166366577148\n",
      "0.0005478858947753906\n"
     ]
    }
   ],
   "source": [
    "print(np.median(forward_times))\n",
    "print(np.median(loss_times))\n",
    "print(np.median(backwards_times))\n",
    "print(np.median(optimizer_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Average epoch time: 1.9983983039855957'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'Average epoch time: {(np.median(forward_times)+np.median(loss_times)+np.median(backwards_times)+np.median(optimizer_times))*110}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1561\n",
      "Epoch 2, Validation Loss: 1.1341\n",
      "Epoch 3, Validation Loss: 1.1271\n",
      "Epoch 4, Validation Loss: 1.1310\n",
      "Epoch 5, Validation Loss: 1.1266\n",
      "Epoch 6, Validation Loss: 1.1189\n",
      "Epoch 7, Validation Loss: 1.1234\n",
      "Epoch 8, Validation Loss: 1.1038\n",
      "Epoch 9, Validation Loss: 1.1047\n",
      "Epoch 10, Validation Loss: 1.1144\n",
      "Epoch 11, Validation Loss: 1.1365\n",
      "Epoch 12, Validation Loss: 1.1285\n",
      "Epoch 13, Validation Loss: 1.1717\n",
      "Epoch 14, Validation Loss: 1.1717\n",
      "Epoch 15, Validation Loss: 1.1428\n",
      "Epoch 16, Validation Loss: 1.1483\n",
      "Epoch 17, Validation Loss: 1.1608\n",
      "Epoch 18, Validation Loss: 1.1975\n",
      "Early stopping after epoch 18 with validation loss 1.1038\n",
      "Test Loss: 1.2938, Test Score: 0.1437 for seed 1 and 1 heads.\n",
      "seed 1, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1390\n",
      "Epoch 2, Validation Loss: 1.1213\n",
      "Epoch 3, Validation Loss: 1.1075\n",
      "Epoch 4, Validation Loss: 1.1199\n",
      "Epoch 5, Validation Loss: 1.1396\n",
      "Epoch 6, Validation Loss: 1.1274\n",
      "Epoch 7, Validation Loss: 1.1363\n",
      "Epoch 8, Validation Loss: 1.1211\n",
      "Epoch 9, Validation Loss: 1.1485\n",
      "Epoch 10, Validation Loss: 1.1461\n",
      "Epoch 11, Validation Loss: 1.1442\n",
      "Epoch 12, Validation Loss: 1.1430\n",
      "Epoch 13, Validation Loss: 1.1453\n",
      "Early stopping after epoch 13 with validation loss 1.1075\n",
      "Test Loss: 1.1892, Test Score: 0.2745 for seed 1 and 2 heads.\n",
      "seed 1, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1690\n",
      "Epoch 2, Validation Loss: 1.1287\n",
      "Epoch 3, Validation Loss: 1.1258\n",
      "Epoch 4, Validation Loss: 1.1549\n",
      "Epoch 5, Validation Loss: 1.1321\n",
      "Epoch 6, Validation Loss: 1.1138\n",
      "Epoch 7, Validation Loss: 1.1278\n",
      "Epoch 8, Validation Loss: 1.1135\n",
      "Epoch 9, Validation Loss: 1.1191\n",
      "Epoch 10, Validation Loss: 1.1239\n",
      "Epoch 11, Validation Loss: 1.1257\n",
      "Epoch 12, Validation Loss: 1.1189\n",
      "Epoch 13, Validation Loss: 1.1270\n",
      "Epoch 14, Validation Loss: 1.1392\n",
      "Epoch 15, Validation Loss: 1.1319\n",
      "Epoch 16, Validation Loss: 1.1268\n",
      "Epoch 17, Validation Loss: 1.1205\n",
      "Epoch 18, Validation Loss: 1.1284\n",
      "Early stopping after epoch 18 with validation loss 1.1135\n",
      "Test Loss: 1.1693, Test Score: 0.2639 for seed 1 and 3 heads.\n",
      "seed 1, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.2002\n",
      "Epoch 2, Validation Loss: 1.1599\n",
      "Epoch 3, Validation Loss: 1.1488\n",
      "Epoch 4, Validation Loss: 1.1354\n",
      "Epoch 5, Validation Loss: 1.1191\n",
      "Epoch 6, Validation Loss: 1.1164\n",
      "Epoch 7, Validation Loss: 1.1235\n",
      "Epoch 8, Validation Loss: 1.1481\n",
      "Epoch 9, Validation Loss: 1.1427\n",
      "Epoch 10, Validation Loss: 1.1235\n",
      "Epoch 11, Validation Loss: 1.1348\n",
      "Epoch 12, Validation Loss: 1.1148\n",
      "Epoch 13, Validation Loss: 1.1292\n",
      "Epoch 14, Validation Loss: 1.1282\n",
      "Epoch 15, Validation Loss: 1.1810\n",
      "Epoch 16, Validation Loss: 1.1707\n",
      "Epoch 17, Validation Loss: 1.1372\n",
      "Epoch 18, Validation Loss: 1.1287\n",
      "Epoch 19, Validation Loss: 1.1295\n",
      "Epoch 20, Validation Loss: 1.1288\n",
      "Epoch 21, Validation Loss: 1.2029\n",
      "Epoch 22, Validation Loss: 1.1249\n",
      "Early stopping after epoch 22 with validation loss 1.1148\n",
      "Test Loss: 1.1670, Test Score: 0.2825 for seed 1 and 4 heads.\n",
      "seed 2, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1313\n",
      "Epoch 2, Validation Loss: 1.1233\n",
      "Epoch 3, Validation Loss: 1.1157\n",
      "Epoch 4, Validation Loss: 1.1266\n",
      "Epoch 5, Validation Loss: 1.1248\n",
      "Epoch 6, Validation Loss: 1.1158\n",
      "Epoch 7, Validation Loss: 1.1091\n",
      "Epoch 8, Validation Loss: 1.1109\n",
      "Epoch 9, Validation Loss: 1.1219\n",
      "Epoch 10, Validation Loss: 1.1128\n",
      "Epoch 11, Validation Loss: 1.1130\n",
      "Epoch 12, Validation Loss: 1.1352\n",
      "Epoch 13, Validation Loss: 1.1003\n",
      "Epoch 14, Validation Loss: 1.1337\n",
      "Epoch 15, Validation Loss: 1.1381\n",
      "Epoch 16, Validation Loss: 1.1451\n",
      "Epoch 17, Validation Loss: 1.2008\n",
      "Epoch 18, Validation Loss: 1.2000\n",
      "Epoch 19, Validation Loss: 1.2208\n",
      "Epoch 20, Validation Loss: 1.1585\n",
      "Epoch 21, Validation Loss: 1.2205\n",
      "Epoch 22, Validation Loss: 1.2517\n",
      "Epoch 23, Validation Loss: 1.2166\n",
      "Early stopping after epoch 23 with validation loss 1.1003\n",
      "Test Loss: 1.2400, Test Score: 0.2815 for seed 2 and 1 heads.\n",
      "seed 2, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1263\n",
      "Epoch 2, Validation Loss: 1.0984\n",
      "Epoch 3, Validation Loss: 1.1141\n",
      "Epoch 4, Validation Loss: 1.1225\n",
      "Epoch 5, Validation Loss: 1.1260\n",
      "Epoch 6, Validation Loss: 1.1445\n",
      "Epoch 7, Validation Loss: 1.1293\n",
      "Epoch 8, Validation Loss: 1.1170\n",
      "Epoch 9, Validation Loss: 1.1034\n",
      "Epoch 10, Validation Loss: 1.0882\n",
      "Epoch 11, Validation Loss: 1.1047\n",
      "Epoch 12, Validation Loss: 1.1360\n",
      "Epoch 13, Validation Loss: 1.1169\n",
      "Epoch 14, Validation Loss: 1.1284\n",
      "Epoch 15, Validation Loss: 1.1256\n",
      "Epoch 16, Validation Loss: 1.1669\n",
      "Epoch 17, Validation Loss: 1.1462\n",
      "Epoch 18, Validation Loss: 1.1356\n",
      "Epoch 19, Validation Loss: 1.1302\n",
      "Epoch 20, Validation Loss: 1.1457\n",
      "Early stopping after epoch 20 with validation loss 1.0882\n",
      "Test Loss: 1.2124, Test Score: 0.2628 for seed 2 and 2 heads.\n",
      "seed 2, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1840\n",
      "Epoch 2, Validation Loss: 1.1431\n",
      "Epoch 3, Validation Loss: 1.1273\n",
      "Epoch 4, Validation Loss: 1.1457\n",
      "Epoch 5, Validation Loss: 1.1089\n",
      "Epoch 6, Validation Loss: 1.1201\n",
      "Epoch 7, Validation Loss: 1.1146\n",
      "Epoch 8, Validation Loss: 1.1067\n",
      "Epoch 9, Validation Loss: 1.1104\n",
      "Epoch 10, Validation Loss: 1.1161\n",
      "Epoch 11, Validation Loss: 1.1612\n",
      "Epoch 12, Validation Loss: 1.0991\n",
      "Epoch 13, Validation Loss: 1.1361\n",
      "Epoch 14, Validation Loss: 1.1108\n",
      "Epoch 15, Validation Loss: 1.1422\n",
      "Epoch 16, Validation Loss: 1.1038\n",
      "Epoch 17, Validation Loss: 1.1209\n",
      "Epoch 18, Validation Loss: 1.1151\n",
      "Epoch 19, Validation Loss: 1.0930\n",
      "Epoch 20, Validation Loss: 1.1350\n",
      "Epoch 21, Validation Loss: 1.1431\n",
      "Epoch 22, Validation Loss: 1.1675\n",
      "Epoch 23, Validation Loss: 1.1597\n",
      "Epoch 24, Validation Loss: 1.2135\n",
      "Epoch 25, Validation Loss: 1.1955\n",
      "Epoch 26, Validation Loss: 1.1904\n",
      "Epoch 27, Validation Loss: 1.1795\n",
      "Epoch 28, Validation Loss: 1.1629\n",
      "Epoch 29, Validation Loss: 1.2083\n",
      "Early stopping after epoch 29 with validation loss 1.0930\n",
      "Test Loss: 1.2244, Test Score: 0.2744 for seed 2 and 3 heads.\n",
      "seed 2, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.1787\n",
      "Epoch 2, Validation Loss: 1.1497\n",
      "Epoch 3, Validation Loss: 1.1115\n",
      "Epoch 4, Validation Loss: 1.1350\n",
      "Epoch 5, Validation Loss: 1.1067\n",
      "Epoch 6, Validation Loss: 1.1134\n",
      "Epoch 7, Validation Loss: 1.1016\n",
      "Epoch 8, Validation Loss: 1.1514\n",
      "Epoch 9, Validation Loss: 1.1119\n",
      "Epoch 10, Validation Loss: 1.1995\n",
      "Epoch 11, Validation Loss: 1.1642\n",
      "Epoch 12, Validation Loss: 1.1490\n",
      "Epoch 13, Validation Loss: 1.1418\n",
      "Epoch 14, Validation Loss: 1.1141\n",
      "Epoch 15, Validation Loss: 1.0984\n",
      "Epoch 16, Validation Loss: 1.1347\n",
      "Epoch 17, Validation Loss: 1.1189\n",
      "Epoch 18, Validation Loss: 1.1346\n",
      "Epoch 19, Validation Loss: 1.1034\n",
      "Epoch 20, Validation Loss: 1.1070\n",
      "Epoch 21, Validation Loss: 1.1043\n",
      "Epoch 22, Validation Loss: 1.1187\n",
      "Epoch 23, Validation Loss: 1.1399\n",
      "Epoch 24, Validation Loss: 1.1074\n",
      "Epoch 25, Validation Loss: 1.1955\n",
      "Early stopping after epoch 25 with validation loss 1.0984\n",
      "Test Loss: 1.2350, Test Score: 0.2238 for seed 2 and 4 heads.\n",
      "seed 3, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1719\n",
      "Epoch 2, Validation Loss: 1.1383\n",
      "Epoch 3, Validation Loss: 1.1240\n",
      "Epoch 4, Validation Loss: 1.1242\n",
      "Epoch 5, Validation Loss: 1.1341\n",
      "Epoch 6, Validation Loss: 1.1460\n",
      "Epoch 7, Validation Loss: 1.1312\n",
      "Epoch 8, Validation Loss: 1.1509\n",
      "Epoch 9, Validation Loss: 1.1422\n",
      "Epoch 10, Validation Loss: 1.1518\n",
      "Epoch 11, Validation Loss: 1.1535\n",
      "Epoch 12, Validation Loss: 1.1445\n",
      "Epoch 13, Validation Loss: 1.1574\n",
      "Early stopping after epoch 13 with validation loss 1.1240\n",
      "Test Loss: 1.1724, Test Score: 0.2895 for seed 3 and 1 heads.\n",
      "seed 3, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1653\n",
      "Epoch 2, Validation Loss: 1.1355\n",
      "Epoch 3, Validation Loss: 1.1492\n",
      "Epoch 4, Validation Loss: 1.1374\n",
      "Epoch 5, Validation Loss: 1.1575\n",
      "Epoch 6, Validation Loss: 1.1265\n",
      "Epoch 7, Validation Loss: 1.1367\n",
      "Epoch 8, Validation Loss: 1.1357\n",
      "Epoch 9, Validation Loss: 1.1728\n",
      "Epoch 10, Validation Loss: 1.1397\n",
      "Epoch 11, Validation Loss: 1.1455\n",
      "Epoch 12, Validation Loss: 1.1846\n",
      "Epoch 13, Validation Loss: 1.1426\n",
      "Epoch 14, Validation Loss: 1.1653\n",
      "Epoch 15, Validation Loss: 1.1993\n",
      "Epoch 16, Validation Loss: 1.1658\n",
      "Early stopping after epoch 16 with validation loss 1.1265\n",
      "Test Loss: 1.1490, Test Score: 0.2934 for seed 3 and 2 heads.\n",
      "seed 3, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1670\n",
      "Epoch 2, Validation Loss: 1.1975\n",
      "Epoch 3, Validation Loss: 1.1530\n",
      "Epoch 4, Validation Loss: 1.1290\n",
      "Epoch 5, Validation Loss: 1.1524\n",
      "Epoch 6, Validation Loss: 1.1365\n",
      "Epoch 7, Validation Loss: 1.1336\n",
      "Epoch 8, Validation Loss: 1.1427\n",
      "Epoch 9, Validation Loss: 1.1788\n",
      "Epoch 10, Validation Loss: 1.1342\n",
      "Epoch 11, Validation Loss: 1.1339\n",
      "Epoch 12, Validation Loss: 1.1429\n",
      "Epoch 13, Validation Loss: 1.1211\n",
      "Epoch 14, Validation Loss: 1.1563\n",
      "Epoch 15, Validation Loss: 1.1671\n",
      "Epoch 16, Validation Loss: 1.1859\n",
      "Epoch 17, Validation Loss: 1.1818\n",
      "Epoch 18, Validation Loss: 1.1772\n",
      "Epoch 19, Validation Loss: 1.1596\n",
      "Epoch 20, Validation Loss: 1.1768\n",
      "Epoch 21, Validation Loss: 1.2162\n",
      "Epoch 22, Validation Loss: 1.2393\n",
      "Epoch 23, Validation Loss: 1.1847\n",
      "Early stopping after epoch 23 with validation loss 1.1211\n",
      "Test Loss: 1.1713, Test Score: 0.2677 for seed 3 and 3 heads.\n",
      "seed 3, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.1550\n",
      "Epoch 2, Validation Loss: 1.1897\n",
      "Epoch 3, Validation Loss: 1.1442\n",
      "Epoch 4, Validation Loss: 1.1391\n",
      "Epoch 5, Validation Loss: 1.1299\n",
      "Epoch 6, Validation Loss: 1.1235\n",
      "Epoch 7, Validation Loss: 1.1216\n",
      "Epoch 8, Validation Loss: 1.1255\n",
      "Epoch 9, Validation Loss: 1.1622\n",
      "Epoch 10, Validation Loss: 1.1295\n",
      "Epoch 11, Validation Loss: 1.1346\n",
      "Epoch 12, Validation Loss: 1.1413\n",
      "Epoch 13, Validation Loss: 1.1256\n",
      "Epoch 14, Validation Loss: 1.1305\n",
      "Epoch 15, Validation Loss: 1.1452\n",
      "Epoch 16, Validation Loss: 1.1308\n",
      "Epoch 17, Validation Loss: 1.1284\n",
      "Early stopping after epoch 17 with validation loss 1.1216\n",
      "Test Loss: 1.1283, Test Score: 0.2828 for seed 3 and 4 heads.\n",
      "seed 4, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1978\n",
      "Epoch 2, Validation Loss: 1.1485\n",
      "Epoch 3, Validation Loss: 1.1354\n",
      "Epoch 4, Validation Loss: 1.1551\n",
      "Epoch 5, Validation Loss: 1.1312\n",
      "Epoch 6, Validation Loss: 1.1543\n",
      "Epoch 7, Validation Loss: 1.1510\n",
      "Epoch 8, Validation Loss: 1.1480\n",
      "Epoch 9, Validation Loss: 1.1363\n",
      "Epoch 10, Validation Loss: 1.1321\n",
      "Epoch 11, Validation Loss: 1.1522\n",
      "Epoch 12, Validation Loss: 1.1030\n",
      "Epoch 13, Validation Loss: 1.1641\n",
      "Epoch 14, Validation Loss: 1.1709\n",
      "Epoch 15, Validation Loss: 1.1667\n",
      "Epoch 16, Validation Loss: 1.1754\n",
      "Epoch 17, Validation Loss: 1.2114\n",
      "Epoch 18, Validation Loss: 1.2307\n",
      "Epoch 19, Validation Loss: 1.2436\n",
      "Epoch 20, Validation Loss: 1.3628\n",
      "Epoch 21, Validation Loss: 1.3329\n",
      "Epoch 22, Validation Loss: 1.3687\n",
      "Early stopping after epoch 22 with validation loss 1.1030\n",
      "Test Loss: 1.3971, Test Score: 0.2685 for seed 4 and 1 heads.\n",
      "seed 4, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1706\n",
      "Epoch 2, Validation Loss: 1.1826\n",
      "Epoch 3, Validation Loss: 1.1602\n",
      "Epoch 4, Validation Loss: 1.1563\n",
      "Epoch 5, Validation Loss: 1.1476\n",
      "Epoch 6, Validation Loss: 1.1653\n",
      "Epoch 7, Validation Loss: 1.1513\n",
      "Epoch 8, Validation Loss: 1.1297\n",
      "Epoch 9, Validation Loss: 1.1329\n",
      "Epoch 10, Validation Loss: 1.1262\n",
      "Epoch 11, Validation Loss: 1.1449\n",
      "Epoch 12, Validation Loss: 1.1306\n",
      "Epoch 13, Validation Loss: 1.1490\n",
      "Epoch 14, Validation Loss: 1.1479\n",
      "Epoch 15, Validation Loss: 1.1864\n",
      "Epoch 16, Validation Loss: 1.1467\n",
      "Epoch 17, Validation Loss: 1.1592\n",
      "Epoch 18, Validation Loss: 1.1785\n",
      "Epoch 19, Validation Loss: 1.1609\n",
      "Epoch 20, Validation Loss: 1.2146\n",
      "Early stopping after epoch 20 with validation loss 1.1262\n",
      "Test Loss: 1.1940, Test Score: 0.2672 for seed 4 and 2 heads.\n",
      "seed 4, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1749\n",
      "Epoch 2, Validation Loss: 1.1646\n",
      "Epoch 3, Validation Loss: 1.1569\n",
      "Epoch 4, Validation Loss: 1.1680\n",
      "Epoch 5, Validation Loss: 1.1469\n",
      "Epoch 6, Validation Loss: 1.1380\n",
      "Epoch 7, Validation Loss: 1.1338\n",
      "Epoch 8, Validation Loss: 1.1426\n",
      "Epoch 9, Validation Loss: 1.1371\n",
      "Epoch 10, Validation Loss: 1.1564\n",
      "Epoch 11, Validation Loss: 1.1337\n",
      "Epoch 12, Validation Loss: 1.1272\n",
      "Epoch 13, Validation Loss: 1.1539\n",
      "Epoch 14, Validation Loss: 1.1721\n",
      "Epoch 15, Validation Loss: 1.1428\n",
      "Epoch 16, Validation Loss: 1.1332\n",
      "Epoch 17, Validation Loss: 1.1628\n",
      "Epoch 18, Validation Loss: 1.1494\n",
      "Epoch 19, Validation Loss: 1.1354\n",
      "Epoch 20, Validation Loss: 1.1535\n",
      "Epoch 21, Validation Loss: 1.1520\n",
      "Epoch 22, Validation Loss: 1.1629\n",
      "Early stopping after epoch 22 with validation loss 1.1272\n",
      "Test Loss: 1.1614, Test Score: 0.2875 for seed 4 and 3 heads.\n",
      "seed 4, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.1588\n",
      "Epoch 2, Validation Loss: 1.1503\n",
      "Epoch 3, Validation Loss: 1.1585\n",
      "Epoch 4, Validation Loss: 1.1476\n",
      "Epoch 5, Validation Loss: 1.1360\n",
      "Epoch 6, Validation Loss: 1.1363\n",
      "Epoch 7, Validation Loss: 1.1380\n",
      "Epoch 8, Validation Loss: 1.1990\n",
      "Epoch 9, Validation Loss: 1.1403\n",
      "Epoch 10, Validation Loss: 1.1727\n",
      "Epoch 11, Validation Loss: 1.1384\n",
      "Epoch 12, Validation Loss: 1.2034\n",
      "Epoch 13, Validation Loss: 1.2034\n",
      "Epoch 14, Validation Loss: 1.2037\n",
      "Epoch 15, Validation Loss: 1.2034\n",
      "Early stopping after epoch 15 with validation loss 1.1360\n",
      "Test Loss: 1.2025, Test Score: 0.0000 for seed 4 and 4 heads.\n",
      "seed 5, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1734\n",
      "Epoch 2, Validation Loss: 1.1522\n",
      "Epoch 3, Validation Loss: 1.1454\n",
      "Epoch 4, Validation Loss: 1.1362\n",
      "Epoch 5, Validation Loss: 1.1468\n",
      "Epoch 6, Validation Loss: 1.1343\n",
      "Epoch 7, Validation Loss: 1.1310\n",
      "Epoch 8, Validation Loss: 1.1398\n",
      "Epoch 9, Validation Loss: 1.1397\n",
      "Epoch 10, Validation Loss: 1.1412\n",
      "Epoch 11, Validation Loss: 1.1439\n",
      "Epoch 12, Validation Loss: 1.1653\n",
      "Epoch 13, Validation Loss: 1.1816\n",
      "Epoch 14, Validation Loss: 1.1632\n",
      "Epoch 15, Validation Loss: 1.1749\n",
      "Epoch 16, Validation Loss: 1.1783\n",
      "Epoch 17, Validation Loss: 1.1843\n",
      "Early stopping after epoch 17 with validation loss 1.1310\n",
      "Test Loss: 1.2231, Test Score: 0.2774 for seed 5 and 1 heads.\n",
      "seed 5, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1870\n",
      "Epoch 2, Validation Loss: 1.1548\n",
      "Epoch 3, Validation Loss: 1.1485\n",
      "Epoch 4, Validation Loss: 1.1494\n",
      "Epoch 5, Validation Loss: 1.1504\n",
      "Epoch 6, Validation Loss: 1.1370\n",
      "Epoch 7, Validation Loss: 1.1219\n",
      "Epoch 8, Validation Loss: 1.1215\n",
      "Epoch 9, Validation Loss: 1.1240\n",
      "Epoch 10, Validation Loss: 1.1267\n",
      "Epoch 11, Validation Loss: 1.1394\n",
      "Epoch 12, Validation Loss: 1.1247\n",
      "Epoch 13, Validation Loss: 1.1273\n",
      "Epoch 14, Validation Loss: 1.1277\n",
      "Epoch 15, Validation Loss: 1.1430\n",
      "Epoch 16, Validation Loss: 1.1275\n",
      "Epoch 17, Validation Loss: 1.1270\n",
      "Epoch 18, Validation Loss: 1.1488\n",
      "Early stopping after epoch 18 with validation loss 1.1215\n",
      "Test Loss: 1.1862, Test Score: 0.2850 for seed 5 and 2 heads.\n",
      "seed 5, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1533\n",
      "Epoch 2, Validation Loss: 1.1483\n",
      "Epoch 3, Validation Loss: 1.1669\n",
      "Epoch 4, Validation Loss: 1.1509\n",
      "Epoch 5, Validation Loss: 1.1350\n",
      "Epoch 6, Validation Loss: 1.1331\n",
      "Epoch 7, Validation Loss: 1.1360\n",
      "Epoch 8, Validation Loss: 1.1261\n",
      "Epoch 9, Validation Loss: 1.1489\n",
      "Epoch 10, Validation Loss: 1.1597\n",
      "Epoch 11, Validation Loss: 1.1550\n",
      "Epoch 12, Validation Loss: 1.1227\n",
      "Epoch 13, Validation Loss: 1.1378\n",
      "Epoch 14, Validation Loss: 1.1432\n",
      "Epoch 15, Validation Loss: 1.1705\n",
      "Epoch 16, Validation Loss: 1.1765\n",
      "Epoch 17, Validation Loss: 1.1315\n",
      "Epoch 18, Validation Loss: 1.1516\n",
      "Epoch 19, Validation Loss: 1.1300\n",
      "Epoch 20, Validation Loss: 1.1391\n",
      "Epoch 21, Validation Loss: 1.1236\n",
      "Epoch 22, Validation Loss: 1.1246\n",
      "Early stopping after epoch 22 with validation loss 1.1227\n",
      "Test Loss: 1.1782, Test Score: 0.2767 for seed 5 and 3 heads.\n",
      "seed 5, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.1808\n",
      "Epoch 2, Validation Loss: 1.1552\n",
      "Epoch 3, Validation Loss: 1.1520\n",
      "Epoch 4, Validation Loss: 1.1710\n",
      "Epoch 5, Validation Loss: 1.1439\n",
      "Epoch 6, Validation Loss: 1.1328\n",
      "Epoch 7, Validation Loss: 1.1414\n",
      "Epoch 8, Validation Loss: 1.1290\n",
      "Epoch 9, Validation Loss: 1.1396\n",
      "Epoch 10, Validation Loss: 1.1439\n",
      "Epoch 11, Validation Loss: 1.1414\n",
      "Epoch 12, Validation Loss: 1.1605\n",
      "Epoch 13, Validation Loss: 1.1409\n",
      "Epoch 14, Validation Loss: 1.1495\n",
      "Epoch 15, Validation Loss: 1.1629\n",
      "Epoch 16, Validation Loss: 1.1349\n",
      "Epoch 17, Validation Loss: 1.1387\n",
      "Epoch 18, Validation Loss: 1.1481\n",
      "Early stopping after epoch 18 with validation loss 1.1290\n",
      "Test Loss: 1.1604, Test Score: 0.2904 for seed 5 and 4 heads.\n",
      "seed 6, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1574\n",
      "Epoch 2, Validation Loss: 1.1485\n",
      "Epoch 3, Validation Loss: 1.1106\n",
      "Epoch 4, Validation Loss: 1.1543\n",
      "Epoch 5, Validation Loss: 1.1146\n",
      "Epoch 6, Validation Loss: 1.1286\n",
      "Epoch 7, Validation Loss: 1.1490\n",
      "Epoch 8, Validation Loss: 1.1289\n",
      "Epoch 9, Validation Loss: 1.1441\n",
      "Epoch 10, Validation Loss: 1.2103\n",
      "Epoch 11, Validation Loss: 1.1055\n",
      "Epoch 12, Validation Loss: 1.1089\n",
      "Epoch 13, Validation Loss: 1.0826\n",
      "Epoch 14, Validation Loss: 1.1125\n",
      "Epoch 15, Validation Loss: 1.2539\n",
      "Epoch 16, Validation Loss: 1.2187\n",
      "Epoch 17, Validation Loss: 1.1606\n",
      "Epoch 18, Validation Loss: 1.2747\n",
      "Epoch 19, Validation Loss: 1.2763\n",
      "Epoch 20, Validation Loss: 1.2358\n",
      "Epoch 21, Validation Loss: 1.3282\n",
      "Epoch 22, Validation Loss: 1.2539\n",
      "Epoch 23, Validation Loss: 1.3266\n",
      "Early stopping after epoch 23 with validation loss 1.0826\n",
      "Test Loss: 1.3761, Test Score: 0.2838 for seed 6 and 1 heads.\n",
      "seed 6, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1492\n",
      "Epoch 2, Validation Loss: 1.1606\n",
      "Epoch 3, Validation Loss: 1.1210\n",
      "Epoch 4, Validation Loss: 1.1587\n",
      "Epoch 5, Validation Loss: 1.1178\n",
      "Epoch 6, Validation Loss: 1.1083\n",
      "Epoch 7, Validation Loss: 1.1109\n",
      "Epoch 8, Validation Loss: 1.1585\n",
      "Epoch 9, Validation Loss: 1.1213\n",
      "Epoch 10, Validation Loss: 1.1093\n",
      "Epoch 11, Validation Loss: 1.1321\n",
      "Epoch 12, Validation Loss: 1.1050\n",
      "Epoch 13, Validation Loss: 1.1143\n",
      "Epoch 14, Validation Loss: 1.1074\n",
      "Epoch 15, Validation Loss: 1.1249\n",
      "Epoch 16, Validation Loss: 1.1790\n",
      "Epoch 17, Validation Loss: 1.1723\n",
      "Epoch 18, Validation Loss: 1.2467\n",
      "Epoch 19, Validation Loss: 1.1508\n",
      "Epoch 20, Validation Loss: 1.2132\n",
      "Epoch 21, Validation Loss: 1.1849\n",
      "Epoch 22, Validation Loss: 1.3599\n",
      "Early stopping after epoch 22 with validation loss 1.1050\n",
      "Test Loss: 1.3608, Test Score: 0.2748 for seed 6 and 2 heads.\n",
      "seed 6, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1788\n",
      "Epoch 2, Validation Loss: 1.1436\n",
      "Epoch 3, Validation Loss: 1.1313\n",
      "Epoch 4, Validation Loss: 1.1554\n",
      "Epoch 5, Validation Loss: 1.1504\n",
      "Epoch 6, Validation Loss: 1.1494\n",
      "Epoch 7, Validation Loss: 1.1542\n",
      "Epoch 8, Validation Loss: 1.1306\n",
      "Epoch 9, Validation Loss: 1.1108\n",
      "Epoch 10, Validation Loss: 1.1146\n",
      "Epoch 11, Validation Loss: 1.1425\n",
      "Epoch 12, Validation Loss: 1.1132\n",
      "Epoch 13, Validation Loss: 1.1220\n",
      "Epoch 14, Validation Loss: 1.1047\n",
      "Epoch 15, Validation Loss: 1.1256\n",
      "Epoch 16, Validation Loss: 1.1790\n",
      "Epoch 17, Validation Loss: 1.1159\n",
      "Epoch 18, Validation Loss: 1.1278\n",
      "Epoch 19, Validation Loss: 1.0981\n",
      "Epoch 20, Validation Loss: 1.1112\n",
      "Epoch 21, Validation Loss: 1.1212\n",
      "Epoch 22, Validation Loss: 1.1605\n",
      "Epoch 23, Validation Loss: 1.1339\n",
      "Epoch 24, Validation Loss: 1.1202\n",
      "Epoch 25, Validation Loss: 1.1263\n",
      "Epoch 26, Validation Loss: 1.1256\n",
      "Epoch 27, Validation Loss: 1.1194\n",
      "Epoch 28, Validation Loss: 1.1227\n",
      "Epoch 29, Validation Loss: 1.1618\n",
      "Early stopping after epoch 29 with validation loss 1.0981\n",
      "Test Loss: 1.1651, Test Score: 0.0638 for seed 6 and 3 heads.\n",
      "seed 6, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.1871\n",
      "Epoch 2, Validation Loss: 1.1378\n",
      "Epoch 3, Validation Loss: 1.2275\n",
      "Epoch 4, Validation Loss: 1.1346\n",
      "Epoch 5, Validation Loss: 1.1163\n",
      "Epoch 6, Validation Loss: 1.1161\n",
      "Epoch 7, Validation Loss: 1.1228\n",
      "Epoch 8, Validation Loss: 1.1134\n",
      "Epoch 9, Validation Loss: 1.1247\n",
      "Epoch 10, Validation Loss: 1.1715\n",
      "Epoch 11, Validation Loss: 1.1175\n",
      "Epoch 12, Validation Loss: 1.1311\n",
      "Epoch 13, Validation Loss: 1.1162\n",
      "Epoch 14, Validation Loss: 1.1476\n",
      "Epoch 15, Validation Loss: 1.1435\n",
      "Epoch 16, Validation Loss: 1.1505\n",
      "Epoch 17, Validation Loss: 1.1497\n",
      "Epoch 18, Validation Loss: 1.1371\n",
      "Early stopping after epoch 18 with validation loss 1.1134\n",
      "Test Loss: 1.1669, Test Score: 0.1357 for seed 6 and 4 heads.\n",
      "seed 7, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1805\n",
      "Epoch 2, Validation Loss: 1.1392\n",
      "Epoch 3, Validation Loss: 1.1552\n",
      "Epoch 4, Validation Loss: 1.1139\n",
      "Epoch 5, Validation Loss: 1.1474\n",
      "Epoch 6, Validation Loss: 1.1369\n",
      "Epoch 7, Validation Loss: 1.1273\n",
      "Epoch 8, Validation Loss: 1.1025\n",
      "Epoch 9, Validation Loss: 1.1159\n",
      "Epoch 10, Validation Loss: 1.1106\n",
      "Epoch 11, Validation Loss: 1.1237\n",
      "Epoch 12, Validation Loss: 1.1206\n",
      "Epoch 13, Validation Loss: 1.2010\n",
      "Epoch 14, Validation Loss: 1.1391\n",
      "Epoch 15, Validation Loss: 1.1731\n",
      "Epoch 16, Validation Loss: 1.1778\n",
      "Epoch 17, Validation Loss: 1.1995\n",
      "Epoch 18, Validation Loss: 1.2694\n",
      "Early stopping after epoch 18 with validation loss 1.1025\n",
      "Test Loss: 1.2948, Test Score: 0.2927 for seed 7 and 1 heads.\n",
      "seed 7, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1600\n",
      "Epoch 2, Validation Loss: 1.1580\n",
      "Epoch 3, Validation Loss: 1.1552\n",
      "Epoch 4, Validation Loss: 1.1292\n",
      "Epoch 5, Validation Loss: 1.1529\n",
      "Epoch 6, Validation Loss: 1.1361\n",
      "Epoch 7, Validation Loss: 1.1515\n",
      "Epoch 8, Validation Loss: 1.1107\n",
      "Epoch 9, Validation Loss: 1.1298\n",
      "Epoch 10, Validation Loss: 1.1116\n",
      "Epoch 11, Validation Loss: 1.1517\n",
      "Epoch 12, Validation Loss: 1.1208\n",
      "Epoch 13, Validation Loss: 1.1264\n",
      "Epoch 14, Validation Loss: 1.1117\n",
      "Epoch 15, Validation Loss: 1.1146\n",
      "Epoch 16, Validation Loss: 1.1611\n",
      "Epoch 17, Validation Loss: 1.1662\n",
      "Epoch 18, Validation Loss: 1.1219\n",
      "Early stopping after epoch 18 with validation loss 1.1107\n",
      "Test Loss: 1.2219, Test Score: 0.2395 for seed 7 and 2 heads.\n",
      "seed 7, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1381\n",
      "Epoch 2, Validation Loss: 1.1745\n",
      "Epoch 3, Validation Loss: 1.1598\n",
      "Epoch 4, Validation Loss: 1.1576\n",
      "Epoch 5, Validation Loss: 1.1314\n",
      "Epoch 6, Validation Loss: 1.1502\n",
      "Epoch 7, Validation Loss: 1.1294\n",
      "Epoch 8, Validation Loss: 1.1329\n",
      "Epoch 9, Validation Loss: 1.1390\n",
      "Epoch 10, Validation Loss: 1.1380\n",
      "Epoch 11, Validation Loss: 1.1268\n",
      "Epoch 12, Validation Loss: 1.1291\n",
      "Epoch 13, Validation Loss: 1.1441\n",
      "Epoch 14, Validation Loss: 1.1731\n",
      "Epoch 15, Validation Loss: 1.1208\n",
      "Epoch 16, Validation Loss: 1.1469\n",
      "Epoch 17, Validation Loss: 1.1188\n",
      "Epoch 18, Validation Loss: 1.1037\n",
      "Epoch 19, Validation Loss: 1.1638\n",
      "Epoch 20, Validation Loss: 1.1234\n",
      "Epoch 21, Validation Loss: 1.1545\n",
      "Epoch 22, Validation Loss: 1.1269\n",
      "Epoch 23, Validation Loss: 1.1309\n",
      "Epoch 24, Validation Loss: 1.1798\n",
      "Epoch 25, Validation Loss: 1.2285\n",
      "Epoch 26, Validation Loss: 1.1550\n",
      "Epoch 27, Validation Loss: 1.1485\n",
      "Epoch 28, Validation Loss: 1.1582\n",
      "Early stopping after epoch 28 with validation loss 1.1037\n",
      "Test Loss: 1.1672, Test Score: 0.3013 for seed 7 and 3 heads.\n",
      "seed 7, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.2317\n",
      "Epoch 2, Validation Loss: 1.1415\n",
      "Epoch 3, Validation Loss: 1.1267\n",
      "Epoch 4, Validation Loss: 1.1538\n",
      "Epoch 5, Validation Loss: 1.1308\n",
      "Epoch 6, Validation Loss: 1.1407\n",
      "Epoch 7, Validation Loss: 1.1489\n",
      "Epoch 8, Validation Loss: 1.1335\n",
      "Epoch 9, Validation Loss: 1.1331\n",
      "Epoch 10, Validation Loss: 1.1330\n",
      "Epoch 11, Validation Loss: 1.1334\n",
      "Epoch 12, Validation Loss: 1.1386\n",
      "Epoch 13, Validation Loss: 1.1362\n",
      "Early stopping after epoch 13 with validation loss 1.1267\n",
      "Test Loss: 1.1257, Test Score: 0.2428 for seed 7 and 4 heads.\n",
      "seed 8, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1647\n",
      "Epoch 2, Validation Loss: 1.1688\n",
      "Epoch 3, Validation Loss: 1.1973\n",
      "Epoch 4, Validation Loss: 1.1546\n",
      "Epoch 5, Validation Loss: 1.1560\n",
      "Epoch 6, Validation Loss: 1.1458\n",
      "Epoch 7, Validation Loss: 1.1302\n",
      "Epoch 8, Validation Loss: 1.1759\n",
      "Epoch 9, Validation Loss: 1.1611\n",
      "Epoch 10, Validation Loss: 1.1518\n",
      "Epoch 11, Validation Loss: 1.1644\n",
      "Epoch 12, Validation Loss: 1.1634\n",
      "Epoch 13, Validation Loss: 1.2132\n",
      "Epoch 14, Validation Loss: 1.1404\n",
      "Epoch 15, Validation Loss: 1.2373\n",
      "Epoch 16, Validation Loss: 1.2052\n",
      "Epoch 17, Validation Loss: 1.2419\n",
      "Early stopping after epoch 17 with validation loss 1.1302\n",
      "Test Loss: 1.2404, Test Score: 0.2760 for seed 8 and 1 heads.\n",
      "seed 8, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1804\n",
      "Epoch 2, Validation Loss: 1.1998\n",
      "Epoch 3, Validation Loss: 1.1461\n",
      "Epoch 4, Validation Loss: 1.1261\n",
      "Epoch 5, Validation Loss: 1.1448\n",
      "Epoch 6, Validation Loss: 1.1715\n",
      "Epoch 7, Validation Loss: 1.1746\n",
      "Epoch 8, Validation Loss: 1.1406\n",
      "Epoch 9, Validation Loss: 1.1321\n",
      "Epoch 10, Validation Loss: 1.1429\n",
      "Epoch 11, Validation Loss: 1.1585\n",
      "Epoch 12, Validation Loss: 1.1466\n",
      "Epoch 13, Validation Loss: 1.1622\n",
      "Epoch 14, Validation Loss: 1.1349\n",
      "Early stopping after epoch 14 with validation loss 1.1261\n",
      "Test Loss: 1.1600, Test Score: 0.2692 for seed 8 and 2 heads.\n",
      "seed 8, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1588\n",
      "Epoch 2, Validation Loss: 1.1606\n",
      "Epoch 3, Validation Loss: 1.1699\n",
      "Epoch 4, Validation Loss: 1.1352\n",
      "Epoch 5, Validation Loss: 1.1521\n",
      "Epoch 6, Validation Loss: 1.1495\n",
      "Epoch 7, Validation Loss: 1.1385\n",
      "Epoch 8, Validation Loss: 1.1496\n",
      "Epoch 9, Validation Loss: 1.1392\n",
      "Epoch 10, Validation Loss: 1.1528\n",
      "Epoch 11, Validation Loss: 1.1284\n",
      "Epoch 12, Validation Loss: 1.1270\n",
      "Epoch 13, Validation Loss: 1.1443\n",
      "Epoch 14, Validation Loss: 1.1555\n",
      "Epoch 15, Validation Loss: 1.1592\n",
      "Epoch 16, Validation Loss: 1.1753\n",
      "Epoch 17, Validation Loss: 1.1512\n",
      "Epoch 18, Validation Loss: 1.1847\n",
      "Epoch 19, Validation Loss: 1.1998\n",
      "Epoch 20, Validation Loss: 1.2050\n",
      "Epoch 21, Validation Loss: 1.1858\n",
      "Epoch 22, Validation Loss: 1.1676\n",
      "Early stopping after epoch 22 with validation loss 1.1270\n",
      "Test Loss: 1.1936, Test Score: 0.2528 for seed 8 and 3 heads.\n",
      "seed 8, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.1613\n",
      "Epoch 2, Validation Loss: 1.1823\n",
      "Epoch 3, Validation Loss: 1.1751\n",
      "Epoch 4, Validation Loss: 1.1787\n",
      "Epoch 5, Validation Loss: 1.1541\n",
      "Epoch 6, Validation Loss: 1.1551\n",
      "Epoch 7, Validation Loss: 1.1667\n",
      "Epoch 8, Validation Loss: 1.1468\n",
      "Epoch 9, Validation Loss: 1.1589\n",
      "Epoch 10, Validation Loss: 1.1454\n",
      "Epoch 11, Validation Loss: 1.1387\n",
      "Epoch 12, Validation Loss: 1.2345\n",
      "Epoch 13, Validation Loss: 1.2111\n",
      "Epoch 14, Validation Loss: 1.2041\n",
      "Epoch 15, Validation Loss: 1.2074\n",
      "Epoch 16, Validation Loss: 1.2055\n",
      "Epoch 17, Validation Loss: 1.2055\n",
      "Epoch 18, Validation Loss: 1.2052\n",
      "Epoch 19, Validation Loss: 1.2038\n",
      "Epoch 20, Validation Loss: 1.2039\n",
      "Epoch 21, Validation Loss: 1.2039\n",
      "Early stopping after epoch 21 with validation loss 1.1387\n",
      "Test Loss: 1.2001, Test Score: 0.0000 for seed 8 and 4 heads.\n",
      "seed 9, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1467\n",
      "Epoch 2, Validation Loss: 1.1325\n",
      "Epoch 3, Validation Loss: 1.1385\n",
      "Epoch 4, Validation Loss: 1.1276\n",
      "Epoch 5, Validation Loss: 1.1549\n",
      "Epoch 6, Validation Loss: 1.1250\n",
      "Epoch 7, Validation Loss: 1.1333\n",
      "Epoch 8, Validation Loss: 1.1304\n",
      "Epoch 9, Validation Loss: 1.1408\n",
      "Epoch 10, Validation Loss: 1.1638\n",
      "Epoch 11, Validation Loss: 1.1446\n",
      "Epoch 12, Validation Loss: 1.1916\n",
      "Epoch 13, Validation Loss: 1.1603\n",
      "Epoch 14, Validation Loss: 1.3374\n",
      "Epoch 15, Validation Loss: 1.1729\n",
      "Epoch 16, Validation Loss: 1.2084\n",
      "Early stopping after epoch 16 with validation loss 1.1250\n",
      "Test Loss: 1.1932, Test Score: 0.2494 for seed 9 and 1 heads.\n",
      "seed 9, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1649\n",
      "Epoch 2, Validation Loss: 1.1423\n",
      "Epoch 3, Validation Loss: 1.1316\n",
      "Epoch 4, Validation Loss: 1.1861\n",
      "Epoch 5, Validation Loss: 1.1214\n",
      "Epoch 6, Validation Loss: 1.1242\n",
      "Epoch 7, Validation Loss: 1.1346\n",
      "Epoch 8, Validation Loss: 1.1381\n",
      "Epoch 9, Validation Loss: 1.1438\n",
      "Epoch 10, Validation Loss: 1.1568\n",
      "Epoch 11, Validation Loss: 1.1300\n",
      "Epoch 12, Validation Loss: 1.1937\n",
      "Epoch 13, Validation Loss: 1.1419\n",
      "Epoch 14, Validation Loss: 1.1777\n",
      "Epoch 15, Validation Loss: 1.1500\n",
      "Early stopping after epoch 15 with validation loss 1.1214\n",
      "Test Loss: 1.1774, Test Score: 0.2763 for seed 9 and 2 heads.\n",
      "seed 9, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1574\n",
      "Epoch 2, Validation Loss: 1.1664\n",
      "Epoch 3, Validation Loss: 1.1282\n",
      "Epoch 4, Validation Loss: 1.1470\n",
      "Epoch 5, Validation Loss: 1.1199\n",
      "Epoch 6, Validation Loss: 1.1211\n",
      "Epoch 7, Validation Loss: 1.1522\n",
      "Epoch 8, Validation Loss: 1.1330\n",
      "Epoch 9, Validation Loss: 1.1255\n",
      "Epoch 10, Validation Loss: 1.1745\n",
      "Epoch 11, Validation Loss: 1.1462\n",
      "Epoch 12, Validation Loss: 1.1374\n",
      "Epoch 13, Validation Loss: 1.1139\n",
      "Epoch 14, Validation Loss: 1.1314\n",
      "Epoch 15, Validation Loss: 1.1434\n",
      "Epoch 16, Validation Loss: 1.1701\n",
      "Epoch 17, Validation Loss: 1.1351\n",
      "Epoch 18, Validation Loss: 1.1566\n",
      "Epoch 19, Validation Loss: 1.1493\n",
      "Epoch 20, Validation Loss: 1.1580\n",
      "Epoch 21, Validation Loss: 1.1561\n",
      "Epoch 22, Validation Loss: 1.2061\n",
      "Epoch 23, Validation Loss: 1.1837\n",
      "Early stopping after epoch 23 with validation loss 1.1139\n",
      "Test Loss: 1.2566, Test Score: 0.2598 for seed 9 and 3 heads.\n",
      "seed 9, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.1434\n",
      "Epoch 2, Validation Loss: 1.1732\n",
      "Epoch 3, Validation Loss: 1.1541\n",
      "Epoch 4, Validation Loss: 1.1442\n",
      "Epoch 5, Validation Loss: 1.1386\n",
      "Epoch 6, Validation Loss: 1.2673\n",
      "Epoch 7, Validation Loss: 1.1365\n",
      "Epoch 8, Validation Loss: 1.1342\n",
      "Epoch 9, Validation Loss: 1.1318\n",
      "Epoch 10, Validation Loss: 1.1421\n",
      "Epoch 11, Validation Loss: 1.1075\n",
      "Epoch 12, Validation Loss: 1.1391\n",
      "Epoch 13, Validation Loss: 1.1203\n",
      "Epoch 14, Validation Loss: 1.1553\n",
      "Epoch 15, Validation Loss: 1.1445\n",
      "Epoch 16, Validation Loss: 1.1566\n",
      "Epoch 17, Validation Loss: 1.1693\n",
      "Epoch 18, Validation Loss: 1.1752\n",
      "Epoch 19, Validation Loss: 1.1904\n",
      "Epoch 20, Validation Loss: 1.1639\n",
      "Epoch 21, Validation Loss: 1.1474\n",
      "Early stopping after epoch 21 with validation loss 1.1075\n",
      "Test Loss: 1.1794, Test Score: 0.2421 for seed 9 and 4 heads.\n",
      "seed 10, with 1 heads\n",
      "Epoch 1, Validation Loss: 1.1493\n",
      "Epoch 2, Validation Loss: 1.1521\n",
      "Epoch 3, Validation Loss: 1.1186\n",
      "Epoch 4, Validation Loss: 1.1298\n",
      "Epoch 5, Validation Loss: 1.1272\n",
      "Epoch 6, Validation Loss: 1.1274\n",
      "Epoch 7, Validation Loss: 1.1367\n",
      "Epoch 8, Validation Loss: 1.1497\n",
      "Epoch 9, Validation Loss: 1.1417\n",
      "Epoch 10, Validation Loss: 1.1313\n",
      "Epoch 11, Validation Loss: 1.1628\n",
      "Epoch 12, Validation Loss: 1.1931\n",
      "Epoch 13, Validation Loss: 1.1588\n",
      "Early stopping after epoch 13 with validation loss 1.1186\n",
      "Test Loss: 1.1696, Test Score: 0.3077 for seed 10 and 1 heads.\n",
      "seed 10, with 2 heads\n",
      "Epoch 1, Validation Loss: 1.1536\n",
      "Epoch 2, Validation Loss: 1.1554\n",
      "Epoch 3, Validation Loss: 1.1338\n",
      "Epoch 4, Validation Loss: 1.1219\n",
      "Epoch 5, Validation Loss: 1.1240\n",
      "Epoch 6, Validation Loss: 1.1238\n",
      "Epoch 7, Validation Loss: 1.1288\n",
      "Epoch 8, Validation Loss: 1.1237\n",
      "Epoch 9, Validation Loss: 1.1572\n",
      "Epoch 10, Validation Loss: 1.1283\n",
      "Epoch 11, Validation Loss: 1.1484\n",
      "Epoch 12, Validation Loss: 1.1436\n",
      "Epoch 13, Validation Loss: 1.1246\n",
      "Epoch 14, Validation Loss: 1.1103\n",
      "Epoch 15, Validation Loss: 1.1684\n",
      "Epoch 16, Validation Loss: 1.1568\n",
      "Epoch 17, Validation Loss: 1.1469\n",
      "Epoch 18, Validation Loss: 1.1648\n",
      "Epoch 19, Validation Loss: 1.1534\n",
      "Epoch 20, Validation Loss: 1.2131\n",
      "Epoch 21, Validation Loss: 1.1511\n",
      "Epoch 22, Validation Loss: 1.1928\n",
      "Epoch 23, Validation Loss: 1.2249\n",
      "Epoch 24, Validation Loss: 1.2263\n",
      "Early stopping after epoch 24 with validation loss 1.1103\n",
      "Test Loss: 1.2441, Test Score: 0.2851 for seed 10 and 2 heads.\n",
      "seed 10, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1979\n",
      "Epoch 2, Validation Loss: 1.1330\n",
      "Epoch 3, Validation Loss: 1.1344\n",
      "Epoch 4, Validation Loss: 1.1390\n",
      "Epoch 5, Validation Loss: 1.1468\n",
      "Epoch 6, Validation Loss: 1.1475\n",
      "Epoch 7, Validation Loss: 1.1932\n",
      "Epoch 8, Validation Loss: 1.1500\n",
      "Epoch 9, Validation Loss: 1.1508\n",
      "Epoch 10, Validation Loss: 1.1428\n",
      "Epoch 11, Validation Loss: 1.1835\n",
      "Epoch 12, Validation Loss: 1.1605\n",
      "Early stopping after epoch 12 with validation loss 1.1330\n",
      "Test Loss: 1.1718, Test Score: 0.2786 for seed 10 and 3 heads.\n",
      "seed 10, with 4 heads\n",
      "Epoch 1, Validation Loss: 1.1701\n",
      "Epoch 2, Validation Loss: 1.1383\n",
      "Epoch 3, Validation Loss: 1.1397\n",
      "Epoch 4, Validation Loss: 1.1311\n",
      "Epoch 5, Validation Loss: 1.1274\n",
      "Epoch 6, Validation Loss: 1.1369\n",
      "Epoch 7, Validation Loss: 1.1385\n",
      "Epoch 8, Validation Loss: 1.1212\n",
      "Epoch 9, Validation Loss: 1.1215\n",
      "Epoch 10, Validation Loss: 1.1142\n",
      "Epoch 11, Validation Loss: 1.1502\n",
      "Epoch 12, Validation Loss: 1.1035\n",
      "Epoch 13, Validation Loss: 1.1197\n",
      "Epoch 14, Validation Loss: 1.1149\n",
      "Epoch 15, Validation Loss: 1.1480\n",
      "Epoch 16, Validation Loss: 1.1482\n",
      "Epoch 17, Validation Loss: 1.1425\n",
      "Epoch 18, Validation Loss: 1.1304\n",
      "Epoch 19, Validation Loss: 1.1307\n",
      "Epoch 20, Validation Loss: 1.1339\n",
      "Epoch 21, Validation Loss: 1.1528\n",
      "Epoch 22, Validation Loss: 1.1431\n",
      "Early stopping after epoch 22 with validation loss 1.1035\n",
      "Test Loss: 1.1505, Test Score: 0.2599 for seed 10 and 4 heads.\n"
     ]
    }
   ],
   "source": [
    "reload(a)\n",
    "from fla_parallelized import ResNN\n",
    "head_counts = [1,2,3,4]\n",
    "test_prediction_dict = {h: [] for h in head_counts}\n",
    "test_label_list = []\n",
    "losses = {h: [] for h in head_counts}\n",
    "\n",
    "forward_times = []\n",
    "loss_times = []\n",
    "backwards_times = []\n",
    "optimizer_times = []\n",
    "\n",
    "for seed in range(10):\n",
    "    for i, head in enumerate(head_counts):\n",
    "        print(f'seed {seed+1}, with {head} heads')\n",
    "        #split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.2, random_state=seed)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, stratify=y_train, test_size=0.1, random_state=seed)\n",
    "        train_dataset = a.npDataset(X_train,y_train)\n",
    "        test_dataset = a.npDataset(X_test,y_test)\n",
    "        val_dataset = a.npDataset(X_val,y_val)\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        #make model\n",
    "        hidden_dims = [50,25,10]\n",
    "        model = ResNN(input_dim=108, hidden_dims=hidden_dims, output_dim=1, res_heads=head, activation=nn.ReLU(), agg='proj')\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        #train\n",
    "        num_epochs = 500\n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        patience = 10\n",
    "        early_stop_counter = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                start_f = time.time()\n",
    "                outputs = model(inputs)\n",
    "                end_f = time.time()\n",
    "                forward_times.append(end_f-start_f)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                start_l = time.time()\n",
    "                loss = criterion(outputs, labels)\n",
    "                end_l = time.time()\n",
    "                loss_times.append(end_l-start_l)\n",
    "                start_b = time.time()\n",
    "                loss.backward()\n",
    "                end_b = time.time()\n",
    "                backwards_times.append(end_b-start_b)\n",
    "                start_o = time.time()\n",
    "                optimizer.step()\n",
    "                end_o = time.time()\n",
    "                optimizer_times.append(end_o-start_o)\n",
    "\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            for inputs, labels in val_loader:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    labels = labels.unsqueeze(1)\n",
    "                    val_loss = criterion(outputs, labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "            \n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model = model.state_dict()\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "            \n",
    "            if early_stop_counter >= patience:\n",
    "                print(f'Early stopping after epoch {epoch+1} with validation loss {best_val_loss:.4f}')\n",
    "                break\n",
    "            \n",
    "        model.load_state_dict(best_model)\n",
    "\n",
    "        #eval\n",
    "        test_losses = []\n",
    "        test_predictions = []\n",
    "        test_true_labels = []\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                test_loss = criterion(outputs, labels)\n",
    "                test_losses.append(test_loss.item())\n",
    "                test_predictions.extend(outputs.cpu().numpy())\n",
    "                test_true_labels.extend(labels.cpu().numpy())\n",
    "        avg_test_loss = np.mean(test_losses)\n",
    "        test_predictions_f1 = [y>0.5 for y in test_predictions]\n",
    "        test_score = f1_score(test_true_labels, test_predictions_f1)\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}, Test Score: {test_score:.4f} for seed {seed+1} and {head} heads.')\n",
    "        if i == 0:\n",
    "            test_label_list.append(test_true_labels)\n",
    "        test_prediction_dict[head].append(test_predictions)\n",
    "        losses[head].append(avg_test_loss)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/res/diabetes/test_pred_dict_1_to_4.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(test_prediction_dict, file=file)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/res/diabetes/test_losses_dict_1_to_4.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(losses, file=file)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/res/diabetes/test_labels.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(test_label_list, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
