{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fla_parallelized as a\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle as pkl\n",
    "from importlib import reload\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import pickle as pkl\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import utils as u\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=os.getcwd()\n",
    "with open(f\"{cwd}/data/diabetes/X.pkl\", \"rb\") as file:\n",
    "    X_raw = pkl.load(file)\n",
    "with open(f\"{cwd}/data/diabetes/y.pkl\", \"rb\") as file:\n",
    "    y = pkl.load(file)\n",
    "y_counts = np.unique(y, return_counts=True)[1]\n",
    "weight = torch.tensor([y_counts[0]/y_counts[1]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_imputed_not_norm = imputer.fit_transform(X_raw)\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X_imputed_not_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1\n",
      "Epoch 1, Validation Loss: 1.1436\n",
      "Epoch 2, Validation Loss: 1.1112\n",
      "Epoch 3, Validation Loss: 1.1171\n",
      "Epoch 4, Validation Loss: 1.1244\n",
      "Epoch 5, Validation Loss: 1.1294\n",
      "Epoch 6, Validation Loss: 1.1555\n",
      "Epoch 7, Validation Loss: 1.1717\n",
      "Epoch 8, Validation Loss: 1.1922\n",
      "Epoch 9, Validation Loss: 1.2582\n",
      "Epoch 10, Validation Loss: 1.2294\n",
      "Epoch 11, Validation Loss: 1.3149\n",
      "Epoch 12, Validation Loss: 1.3350\n",
      "Early stopping after epoch 12 with validation loss 1.1112\n",
      "Test Loss: 1.4854, Test Score: 0.2169 for seed 1\n",
      "seed 2\n",
      "Epoch 1, Validation Loss: 1.1507\n",
      "Epoch 2, Validation Loss: 1.1248\n",
      "Epoch 3, Validation Loss: 1.1236\n",
      "Epoch 4, Validation Loss: 1.1516\n",
      "Epoch 5, Validation Loss: 1.2134\n",
      "Epoch 6, Validation Loss: 1.2227\n",
      "Epoch 7, Validation Loss: 1.2607\n",
      "Epoch 8, Validation Loss: 1.3477\n",
      "Epoch 9, Validation Loss: 1.4526\n",
      "Epoch 10, Validation Loss: 1.6279\n",
      "Epoch 11, Validation Loss: 1.4567\n",
      "Epoch 12, Validation Loss: 1.6693\n",
      "Epoch 13, Validation Loss: 1.8569\n",
      "Early stopping after epoch 13 with validation loss 1.1236\n",
      "Test Loss: 1.9497, Test Score: 0.2531 for seed 2\n",
      "seed 3\n",
      "Epoch 1, Validation Loss: 1.1655\n",
      "Epoch 2, Validation Loss: 1.1264\n",
      "Epoch 3, Validation Loss: 1.1267\n",
      "Epoch 4, Validation Loss: 1.1494\n",
      "Epoch 5, Validation Loss: 1.1350\n",
      "Epoch 6, Validation Loss: 1.1873\n",
      "Epoch 7, Validation Loss: 1.2154\n",
      "Epoch 8, Validation Loss: 1.3246\n",
      "Epoch 9, Validation Loss: 1.3654\n",
      "Epoch 10, Validation Loss: 1.4044\n",
      "Epoch 11, Validation Loss: 1.4545\n",
      "Epoch 12, Validation Loss: 1.5568\n",
      "Early stopping after epoch 12 with validation loss 1.1264\n",
      "Test Loss: 1.5531, Test Score: 0.2743 for seed 3\n",
      "seed 4\n",
      "Epoch 1, Validation Loss: 1.1847\n",
      "Epoch 2, Validation Loss: 1.1708\n",
      "Epoch 3, Validation Loss: 1.1569\n",
      "Epoch 4, Validation Loss: 1.1606\n",
      "Epoch 5, Validation Loss: 1.1971\n",
      "Epoch 6, Validation Loss: 1.2267\n",
      "Epoch 7, Validation Loss: 1.2681\n",
      "Epoch 8, Validation Loss: 1.3037\n",
      "Epoch 9, Validation Loss: 1.3350\n",
      "Epoch 10, Validation Loss: 1.3894\n",
      "Epoch 11, Validation Loss: 1.4524\n",
      "Epoch 12, Validation Loss: 1.5225\n",
      "Epoch 13, Validation Loss: 1.5922\n",
      "Early stopping after epoch 13 with validation loss 1.1569\n",
      "Test Loss: 1.5082, Test Score: 0.2575 for seed 4\n",
      "seed 5\n",
      "Epoch 1, Validation Loss: 1.1429\n",
      "Epoch 2, Validation Loss: 1.1263\n",
      "Epoch 3, Validation Loss: 1.1345\n",
      "Epoch 4, Validation Loss: 1.1194\n",
      "Epoch 5, Validation Loss: 1.1180\n",
      "Epoch 6, Validation Loss: 1.1393\n",
      "Epoch 7, Validation Loss: 1.1795\n",
      "Epoch 8, Validation Loss: 1.2298\n",
      "Epoch 9, Validation Loss: 1.2672\n",
      "Epoch 10, Validation Loss: 1.2716\n",
      "Epoch 11, Validation Loss: 1.3493\n",
      "Epoch 12, Validation Loss: 1.4067\n",
      "Epoch 13, Validation Loss: 1.3741\n",
      "Epoch 14, Validation Loss: 1.4515\n",
      "Epoch 15, Validation Loss: 1.5090\n",
      "Early stopping after epoch 15 with validation loss 1.1180\n",
      "Test Loss: 1.5968, Test Score: 0.2763 for seed 5\n",
      "seed 6\n",
      "Epoch 1, Validation Loss: 1.1698\n",
      "Epoch 2, Validation Loss: 1.1295\n",
      "Epoch 3, Validation Loss: 1.1367\n",
      "Epoch 4, Validation Loss: 1.1576\n",
      "Epoch 5, Validation Loss: 1.1650\n",
      "Epoch 6, Validation Loss: 1.2527\n",
      "Epoch 7, Validation Loss: 1.2195\n",
      "Epoch 8, Validation Loss: 1.3046\n",
      "Epoch 9, Validation Loss: 1.3422\n",
      "Epoch 10, Validation Loss: 1.3783\n",
      "Epoch 11, Validation Loss: 1.5288\n",
      "Epoch 12, Validation Loss: 1.5619\n",
      "Early stopping after epoch 12 with validation loss 1.1295\n",
      "Test Loss: 1.5427, Test Score: 0.2788 for seed 6\n",
      "seed 7\n",
      "Epoch 1, Validation Loss: 1.1436\n",
      "Epoch 2, Validation Loss: 1.1206\n",
      "Epoch 3, Validation Loss: 1.1156\n",
      "Epoch 4, Validation Loss: 1.1237\n",
      "Epoch 5, Validation Loss: 1.1410\n",
      "Epoch 6, Validation Loss: 1.1686\n",
      "Epoch 7, Validation Loss: 1.2241\n",
      "Epoch 8, Validation Loss: 1.2679\n",
      "Epoch 9, Validation Loss: 1.2982\n",
      "Epoch 10, Validation Loss: 1.4106\n",
      "Epoch 11, Validation Loss: 1.5429\n",
      "Epoch 12, Validation Loss: 1.5915\n",
      "Epoch 13, Validation Loss: 1.7322\n",
      "Early stopping after epoch 13 with validation loss 1.1156\n",
      "Test Loss: 1.6167, Test Score: 0.2405 for seed 7\n",
      "seed 8\n",
      "Epoch 1, Validation Loss: 1.1733\n",
      "Epoch 2, Validation Loss: 1.1430\n",
      "Epoch 3, Validation Loss: 1.1503\n",
      "Epoch 4, Validation Loss: 1.1594\n",
      "Epoch 5, Validation Loss: 1.1701\n",
      "Epoch 6, Validation Loss: 1.2628\n",
      "Epoch 7, Validation Loss: 1.2818\n",
      "Epoch 8, Validation Loss: 1.4018\n",
      "Epoch 9, Validation Loss: 1.5036\n",
      "Epoch 10, Validation Loss: 1.5322\n",
      "Epoch 11, Validation Loss: 1.6253\n",
      "Epoch 12, Validation Loss: 1.6847\n",
      "Early stopping after epoch 12 with validation loss 1.1430\n",
      "Test Loss: 1.8003, Test Score: 0.2528 for seed 8\n",
      "seed 9\n",
      "Epoch 1, Validation Loss: 1.1712\n",
      "Epoch 2, Validation Loss: 1.1507\n",
      "Epoch 3, Validation Loss: 1.1562\n",
      "Epoch 4, Validation Loss: 1.1667\n",
      "Epoch 5, Validation Loss: 1.2060\n",
      "Epoch 6, Validation Loss: 1.2318\n",
      "Epoch 7, Validation Loss: 1.2812\n",
      "Epoch 8, Validation Loss: 1.4050\n",
      "Epoch 9, Validation Loss: 1.5433\n",
      "Epoch 10, Validation Loss: 1.6171\n",
      "Epoch 11, Validation Loss: 1.5804\n",
      "Epoch 12, Validation Loss: 1.7024\n",
      "Early stopping after epoch 12 with validation loss 1.1507\n",
      "Test Loss: 1.6587, Test Score: 0.2577 for seed 9\n",
      "seed 10\n",
      "Epoch 1, Validation Loss: 1.1501\n",
      "Epoch 2, Validation Loss: 1.1203\n",
      "Epoch 3, Validation Loss: 1.1176\n",
      "Epoch 4, Validation Loss: 1.1443\n",
      "Epoch 5, Validation Loss: 1.1672\n",
      "Epoch 6, Validation Loss: 1.2482\n",
      "Epoch 7, Validation Loss: 1.3350\n",
      "Epoch 8, Validation Loss: 1.3863\n",
      "Epoch 9, Validation Loss: 1.4588\n",
      "Epoch 10, Validation Loss: 1.4694\n",
      "Epoch 11, Validation Loss: 1.6206\n",
      "Epoch 12, Validation Loss: 1.6358\n",
      "Epoch 13, Validation Loss: 1.6083\n",
      "Early stopping after epoch 13 with validation loss 1.1176\n",
      "Test Loss: 1.6688, Test Score: 0.2698 for seed 10\n"
     ]
    }
   ],
   "source": [
    "reload(a)\n",
    "seeds = 10\n",
    "test_predictions_seed = [[]]*seeds\n",
    "test_label_list_seed = [[]]*seeds\n",
    "losses_seed = []\n",
    "activations = [nn.ReLU, nn.Sigmoid, a.GaussianActivation]\n",
    "forward_times = []\n",
    "for seed in range(seeds):\n",
    "    print(f'seed {seed+1}')\n",
    "    #split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.2, random_state=seed)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, stratify=y_train, test_size=0.1, random_state=seed)\n",
    "    train_dataset = a.npDataset(X_train,y_train)\n",
    "    test_dataset = a.npDataset(X_test,y_test)\n",
    "    val_dataset = a.npDataset(X_val,y_val)\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = nn.Sequential(\n",
    "        a.MultiActivationLinear(input_dim=108, activations=activations,nodes_per_activation=17),\n",
    "        a.MultiActivationLinear(input_dim=17*3, activations=activations,nodes_per_activation=8),\n",
    "        a.MultiActivationLinear(input_dim=8*3, activations=activations,nodes_per_activation=3),\n",
    "        nn.Linear(in_features=3*3,out_features=1)\n",
    "    )\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    #train\n",
    "    num_epochs = 500\n",
    "    best_val_loss = float('inf')\n",
    "    best_model = None\n",
    "    patience = 10\n",
    "    early_stop_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        for inputs, labels in val_loader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                val_loss = criterion(outputs, labels)\n",
    "                val_losses.append(val_loss.item())\n",
    "        \n",
    "        avg_val_loss = np.mean(val_losses)\n",
    "        print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}')\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            best_model = model.state_dict()\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "        \n",
    "        if early_stop_counter >= patience:\n",
    "            print(f'Early stopping after epoch {epoch+1} with validation loss {best_val_loss:.4f}')\n",
    "            break\n",
    "        \n",
    "    model.load_state_dict(best_model)\n",
    "\n",
    "    #eval\n",
    "    test_losses = []\n",
    "    test_predictions = []\n",
    "    test_true_labels = []\n",
    "\n",
    "    for inputs, labels in test_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.unsqueeze(1)\n",
    "            test_loss = criterion(outputs, labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "            test_predictions.extend(outputs.cpu().numpy())\n",
    "            test_true_labels.extend(labels.cpu().numpy())\n",
    "    avg_test_loss = np.mean(test_losses)\n",
    "    test_predictions_f1 = [F.sigmoid(torch.tensor(y))>0.5 for y in test_predictions]\n",
    "    test_score = f1_score(test_true_labels, test_predictions_f1)\n",
    "    print(f'Test Loss: {avg_test_loss:.4f}, Test Score: {test_score:.4f} for seed {seed+1}')\n",
    "    test_label_list_seed[seed].append(test_true_labels)\n",
    "    test_predictions_seed[seed].append(test_predictions)\n",
    "    losses_seed.append(avg_test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6067627109587193\n"
     ]
    }
   ],
   "source": [
    "print(np.median(losses_seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
