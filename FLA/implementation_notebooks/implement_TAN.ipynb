{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as u\n",
    "from importlib import reload\n",
    "from sklearn.model_selection import train_test_split\n",
    "import fla_parallelized as a\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, weight = u.diabetes_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1101\n",
      "Epoch 2, Validation Loss: 1.1183\n",
      "Epoch 3, Validation Loss: 1.1319\n",
      "Epoch 4, Validation Loss: 1.1320\n",
      "Epoch 5, Validation Loss: 1.1351\n",
      "Epoch 6, Validation Loss: 1.1155\n",
      "Epoch 7, Validation Loss: 1.1078\n",
      "Epoch 8, Validation Loss: 1.1241\n",
      "Epoch 9, Validation Loss: 1.1034\n",
      "Epoch 10, Validation Loss: 1.1235\n",
      "Epoch 11, Validation Loss: 1.1355\n",
      "Epoch 12, Validation Loss: 1.1479\n",
      "Epoch 13, Validation Loss: 1.1456\n",
      "Epoch 14, Validation Loss: 1.1107\n",
      "Epoch 15, Validation Loss: 1.1214\n",
      "Epoch 16, Validation Loss: 1.1155\n",
      "Epoch 17, Validation Loss: 1.1270\n",
      "Epoch 18, Validation Loss: 1.1415\n",
      "Epoch 19, Validation Loss: 1.1702\n",
      "Early stopping after epoch 19 with validation loss 1.1034\n",
      "Test Loss: 1.2097, Test Score: 0.2695 for seed 1 and 3 heads.\n",
      "seed 2, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1978\n",
      "Epoch 2, Validation Loss: 1.1481\n",
      "Epoch 3, Validation Loss: 1.1052\n",
      "Epoch 4, Validation Loss: 1.1299\n",
      "Epoch 5, Validation Loss: 1.1039\n",
      "Epoch 6, Validation Loss: 1.0989\n",
      "Epoch 7, Validation Loss: 1.1315\n",
      "Epoch 8, Validation Loss: 1.1117\n",
      "Epoch 9, Validation Loss: 1.0920\n",
      "Epoch 10, Validation Loss: 1.1333\n",
      "Epoch 11, Validation Loss: 1.1212\n",
      "Epoch 12, Validation Loss: 1.1003\n",
      "Epoch 13, Validation Loss: 1.0982\n",
      "Epoch 14, Validation Loss: 1.1446\n",
      "Epoch 15, Validation Loss: 1.1233\n",
      "Epoch 16, Validation Loss: 1.1066\n",
      "Epoch 17, Validation Loss: 1.1230\n",
      "Epoch 18, Validation Loss: 1.1278\n",
      "Epoch 19, Validation Loss: 1.1498\n",
      "Early stopping after epoch 19 with validation loss 1.0920\n",
      "Test Loss: 1.1799, Test Score: 0.2626 for seed 2 and 3 heads.\n",
      "seed 3, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1709\n",
      "Epoch 2, Validation Loss: 1.1421\n",
      "Epoch 3, Validation Loss: 1.1371\n",
      "Epoch 4, Validation Loss: 1.1243\n",
      "Epoch 5, Validation Loss: 1.1346\n",
      "Epoch 6, Validation Loss: 1.1259\n",
      "Epoch 7, Validation Loss: 1.1289\n",
      "Epoch 8, Validation Loss: 1.1387\n",
      "Epoch 9, Validation Loss: 1.1403\n",
      "Epoch 10, Validation Loss: 1.1453\n",
      "Epoch 11, Validation Loss: 1.1323\n",
      "Epoch 12, Validation Loss: 1.1408\n",
      "Epoch 13, Validation Loss: 1.1247\n",
      "Epoch 14, Validation Loss: 1.1388\n",
      "Early stopping after epoch 14 with validation loss 1.1243\n",
      "Test Loss: 1.1305, Test Score: 0.2860 for seed 3 and 3 heads.\n",
      "seed 4, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1480\n",
      "Epoch 2, Validation Loss: 1.1571\n",
      "Epoch 3, Validation Loss: 1.1443\n",
      "Epoch 4, Validation Loss: 1.1563\n",
      "Epoch 5, Validation Loss: 1.1446\n",
      "Epoch 6, Validation Loss: 1.1708\n",
      "Epoch 7, Validation Loss: 1.1443\n",
      "Epoch 8, Validation Loss: 1.1823\n",
      "Epoch 9, Validation Loss: 1.1478\n",
      "Epoch 10, Validation Loss: 1.1459\n",
      "Epoch 11, Validation Loss: 1.1611\n",
      "Epoch 12, Validation Loss: 1.1576\n",
      "Epoch 13, Validation Loss: 1.1300\n",
      "Epoch 14, Validation Loss: 1.1239\n",
      "Epoch 15, Validation Loss: 1.1513\n",
      "Epoch 16, Validation Loss: 1.1651\n",
      "Epoch 17, Validation Loss: 1.1762\n",
      "Epoch 18, Validation Loss: 1.1457\n",
      "Epoch 19, Validation Loss: 1.1258\n",
      "Epoch 20, Validation Loss: 1.1543\n",
      "Epoch 21, Validation Loss: 1.1292\n",
      "Epoch 22, Validation Loss: 1.1504\n",
      "Epoch 23, Validation Loss: 1.1513\n",
      "Epoch 24, Validation Loss: 1.1478\n",
      "Early stopping after epoch 24 with validation loss 1.1239\n",
      "Test Loss: 1.1644, Test Score: 0.3090 for seed 4 and 3 heads.\n",
      "seed 5, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1490\n",
      "Epoch 2, Validation Loss: 1.1505\n",
      "Epoch 3, Validation Loss: 1.1290\n",
      "Epoch 4, Validation Loss: 1.1425\n",
      "Epoch 5, Validation Loss: 1.1371\n",
      "Epoch 6, Validation Loss: 1.1410\n",
      "Epoch 7, Validation Loss: 1.1776\n",
      "Epoch 8, Validation Loss: 1.1414\n",
      "Epoch 9, Validation Loss: 1.1210\n",
      "Epoch 10, Validation Loss: 1.1552\n",
      "Epoch 11, Validation Loss: 1.1332\n",
      "Epoch 12, Validation Loss: 1.1436\n",
      "Epoch 13, Validation Loss: 1.1181\n",
      "Epoch 14, Validation Loss: 1.1899\n",
      "Epoch 15, Validation Loss: 1.1645\n",
      "Epoch 16, Validation Loss: 1.1644\n",
      "Epoch 17, Validation Loss: 1.1609\n",
      "Epoch 18, Validation Loss: 1.1832\n",
      "Epoch 19, Validation Loss: 1.2167\n",
      "Epoch 20, Validation Loss: 1.2791\n",
      "Epoch 21, Validation Loss: 1.2469\n",
      "Epoch 22, Validation Loss: 1.1906\n",
      "Epoch 23, Validation Loss: 1.2486\n",
      "Early stopping after epoch 23 with validation loss 1.1181\n",
      "Test Loss: 1.3387, Test Score: 0.2578 for seed 5 and 3 heads.\n",
      "seed 6, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.2641\n",
      "Epoch 2, Validation Loss: 1.1590\n",
      "Epoch 3, Validation Loss: 1.1292\n",
      "Epoch 4, Validation Loss: 1.1029\n",
      "Epoch 5, Validation Loss: 1.1074\n",
      "Epoch 6, Validation Loss: 1.1147\n",
      "Epoch 7, Validation Loss: 1.1552\n",
      "Epoch 8, Validation Loss: 1.1693\n",
      "Epoch 9, Validation Loss: 1.1088\n",
      "Epoch 10, Validation Loss: 1.1099\n",
      "Epoch 11, Validation Loss: 1.1273\n",
      "Epoch 12, Validation Loss: 1.1486\n",
      "Epoch 13, Validation Loss: 1.1187\n",
      "Epoch 14, Validation Loss: 1.2059\n",
      "Early stopping after epoch 14 with validation loss 1.1029\n",
      "Test Loss: 1.2078, Test Score: 0.2432 for seed 6 and 3 heads.\n",
      "seed 7, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1545\n",
      "Epoch 2, Validation Loss: 1.1687\n",
      "Epoch 3, Validation Loss: 1.1590\n",
      "Epoch 4, Validation Loss: 1.1370\n",
      "Epoch 5, Validation Loss: 1.1355\n",
      "Epoch 6, Validation Loss: 1.1318\n",
      "Epoch 7, Validation Loss: 1.1346\n",
      "Epoch 8, Validation Loss: 1.1697\n",
      "Epoch 9, Validation Loss: 1.1406\n",
      "Epoch 10, Validation Loss: 1.1287\n",
      "Epoch 11, Validation Loss: 1.1401\n",
      "Epoch 12, Validation Loss: 1.1215\n",
      "Epoch 13, Validation Loss: 1.1281\n",
      "Epoch 14, Validation Loss: 1.1551\n",
      "Epoch 15, Validation Loss: 1.1709\n",
      "Epoch 16, Validation Loss: 1.1309\n",
      "Epoch 17, Validation Loss: 1.1366\n",
      "Epoch 18, Validation Loss: 1.1164\n",
      "Epoch 19, Validation Loss: 1.1325\n",
      "Epoch 20, Validation Loss: 1.1494\n",
      "Epoch 21, Validation Loss: 1.1348\n",
      "Epoch 22, Validation Loss: 1.1243\n",
      "Epoch 23, Validation Loss: 1.1475\n",
      "Epoch 24, Validation Loss: 1.1428\n",
      "Epoch 25, Validation Loss: 1.1692\n",
      "Epoch 26, Validation Loss: 1.1380\n",
      "Epoch 27, Validation Loss: 1.1660\n",
      "Epoch 28, Validation Loss: 1.1589\n",
      "Early stopping after epoch 28 with validation loss 1.1164\n",
      "Test Loss: 1.1599, Test Score: 0.3078 for seed 7 and 3 heads.\n",
      "seed 8, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1629\n",
      "Epoch 2, Validation Loss: 1.1458\n",
      "Epoch 3, Validation Loss: 1.1457\n",
      "Epoch 4, Validation Loss: 1.1410\n",
      "Epoch 5, Validation Loss: 1.1379\n",
      "Epoch 6, Validation Loss: 1.1359\n",
      "Epoch 7, Validation Loss: 1.1615\n",
      "Epoch 8, Validation Loss: 1.1453\n",
      "Epoch 9, Validation Loss: 1.1442\n",
      "Epoch 10, Validation Loss: 1.1487\n",
      "Epoch 11, Validation Loss: 1.1520\n",
      "Epoch 12, Validation Loss: 1.1808\n",
      "Epoch 13, Validation Loss: 1.1691\n",
      "Epoch 14, Validation Loss: 1.1635\n",
      "Epoch 15, Validation Loss: 1.1820\n",
      "Epoch 16, Validation Loss: 1.1540\n",
      "Early stopping after epoch 16 with validation loss 1.1359\n",
      "Test Loss: 1.1645, Test Score: 0.2784 for seed 8 and 3 heads.\n",
      "seed 9, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1565\n",
      "Epoch 2, Validation Loss: 1.1841\n",
      "Epoch 3, Validation Loss: 1.1391\n",
      "Epoch 4, Validation Loss: 1.1342\n",
      "Epoch 5, Validation Loss: 1.1304\n",
      "Epoch 6, Validation Loss: 1.1113\n",
      "Epoch 7, Validation Loss: 1.1289\n",
      "Epoch 8, Validation Loss: 1.1507\n",
      "Epoch 9, Validation Loss: 1.1398\n",
      "Epoch 10, Validation Loss: 1.1164\n",
      "Epoch 11, Validation Loss: 1.1270\n",
      "Epoch 12, Validation Loss: 1.1409\n",
      "Epoch 13, Validation Loss: 1.1509\n",
      "Epoch 14, Validation Loss: 1.1646\n",
      "Epoch 15, Validation Loss: 1.1506\n",
      "Epoch 16, Validation Loss: 1.1495\n",
      "Early stopping after epoch 16 with validation loss 1.1113\n",
      "Test Loss: 1.1967, Test Score: 0.2452 for seed 9 and 3 heads.\n",
      "seed 10, with 3 heads\n",
      "Epoch 1, Validation Loss: 1.1703\n",
      "Epoch 2, Validation Loss: 1.1415\n",
      "Epoch 3, Validation Loss: 1.1573\n",
      "Epoch 4, Validation Loss: 1.1395\n",
      "Epoch 5, Validation Loss: 1.1544\n",
      "Epoch 6, Validation Loss: 1.1422\n",
      "Epoch 7, Validation Loss: 1.1367\n",
      "Epoch 8, Validation Loss: 1.1535\n",
      "Epoch 9, Validation Loss: 1.1296\n",
      "Epoch 10, Validation Loss: 1.1410\n",
      "Epoch 11, Validation Loss: 1.1232\n",
      "Epoch 12, Validation Loss: 1.1361\n",
      "Epoch 13, Validation Loss: 1.1411\n",
      "Epoch 14, Validation Loss: 1.1232\n",
      "Epoch 15, Validation Loss: 1.1377\n",
      "Epoch 16, Validation Loss: 1.1181\n",
      "Epoch 17, Validation Loss: 1.1405\n",
      "Epoch 18, Validation Loss: 1.1539\n",
      "Epoch 19, Validation Loss: 1.1821\n",
      "Epoch 20, Validation Loss: 1.1599\n",
      "Epoch 21, Validation Loss: 1.1539\n",
      "Epoch 22, Validation Loss: 1.2016\n",
      "Epoch 23, Validation Loss: 1.1679\n",
      "Epoch 24, Validation Loss: 1.1654\n",
      "Epoch 25, Validation Loss: 1.2181\n",
      "Epoch 26, Validation Loss: 1.1813\n",
      "Early stopping after epoch 26 with validation loss 1.1181\n",
      "Test Loss: 1.1997, Test Score: 0.2479 for seed 10 and 3 heads.\n"
     ]
    }
   ],
   "source": [
    "reload(a)\n",
    "head_counts = [3]#,2,3,4,5,6,7,8,9,10,15,20]\n",
    "test_prediction_dict = {h: [] for h in head_counts}\n",
    "test_label_list = []\n",
    "losses = {h: [] for h in head_counts}\n",
    "\n",
    "forward_times = []\n",
    "loss_times = []\n",
    "backwards_times = []\n",
    "optimizer_times = []\n",
    "\n",
    "for seed in range(10):\n",
    "    for i, head in enumerate(head_counts):\n",
    "        print(f'seed {seed+1}, with {head} heads')\n",
    "        #split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.2, random_state=seed)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, stratify=y_train, test_size=0.1, random_state=seed)\n",
    "        train_dataset = a.npDataset(X_train,y_train)\n",
    "        test_dataset = a.npDataset(X_test,y_test)\n",
    "        val_dataset = a.npDataset(X_val,y_val)\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        #make model\n",
    "        hidden_dims = [50,25,10]\n",
    "        attn_heads = head\n",
    "        model = a.TabularAwarenessNetwork(input_dim=108, hidden_dims=hidden_dims, output_dim=1, \n",
    "                                          n_heads=attn_heads, agg='proj', activation=nn.ReLU(), mech='film')\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        #train\n",
    "        num_epochs = 500\n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        patience = 10\n",
    "        early_stop_counter = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                start_f = time.time()\n",
    "                outputs = model(inputs)\n",
    "                end_f = time.time()\n",
    "                # print(f'forwards: {end_f-start_f:.4f}')\n",
    "                forward_times.append(end_f-start_f)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                start_l = time.time()\n",
    "                loss = criterion(outputs, labels)\n",
    "                end_l = time.time()\n",
    "                loss_times.append(end_l-start_l)\n",
    "                start_b = time.time()\n",
    "                loss.backward()\n",
    "                end_b = time.time()\n",
    "                # print(f'back: {end_b-start_b:.4f}')\n",
    "                backwards_times.append(end_b-start_b)\n",
    "                start_o = time.time()\n",
    "                optimizer.step()\n",
    "                end_o = time.time()\n",
    "                optimizer_times.append(end_o-start_o)\n",
    "\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            for inputs, labels in val_loader:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    labels = labels.unsqueeze(1)\n",
    "                    val_loss = criterion(outputs, labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "            \n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model = model.state_dict()\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "            \n",
    "            if early_stop_counter >= patience:\n",
    "                print(f'Early stopping after epoch {epoch+1} with validation loss {best_val_loss:.4f}')\n",
    "                break\n",
    "            \n",
    "        model.load_state_dict(best_model)\n",
    "\n",
    "        #eval\n",
    "        test_losses = []\n",
    "        test_predictions = []\n",
    "        test_true_labels = []\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                test_loss = criterion(outputs, labels)\n",
    "                test_losses.append(test_loss.item())\n",
    "                test_predictions.extend(outputs.cpu().numpy())\n",
    "                test_true_labels.extend(labels.cpu().numpy())\n",
    "        avg_test_loss = np.mean(test_losses)\n",
    "        test_predictions_f1 = [y>0.5 for y in test_predictions]\n",
    "        test_score = f1_score(test_true_labels, test_predictions_f1)\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}, Test Score: {test_score:.4f} for seed {seed+1} and {head} heads.')\n",
    "        if i == 0:\n",
    "            test_label_list.append(test_true_labels)\n",
    "        test_prediction_dict[head].append(test_predictions)\n",
    "        losses[head].append(avg_test_loss)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/diabetes/film/test_pred_dict_1_to_4.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(test_prediction_dict, file=file)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/diabetes/film/test_losses_dict_1_to_4.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(losses, file=file)\n",
    "# with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/diabetes/film/test_labels.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(test_label_list, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1.1883294240882\n"
     ]
    }
   ],
   "source": [
    "for k,v in losses.items():\n",
    "    print(k, np.median(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0.3032605967970069\n"
     ]
    }
   ],
   "source": [
    "fmaxes = {}\n",
    "for k,v in test_prediction_dict.items():\n",
    "    fmaxes[k] = []\n",
    "    for i in range(10):\n",
    "        activated_preds = [u.sig(x) for x in v[i]]\n",
    "        fmaxes[k].append(u.fmax_score(test_label_list[i], activated_preds)[0])\n",
    "    print(k, np.median(fmaxes[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "fmaxes_df = pd.DataFrame(fmaxes)\n",
    "fmaxes_df.plot.box()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/film/sum/diabetes/test_pred_dict.pkl\", \"wb\") as file:\n",
    "    pkl.dump(test_prediction_dict, file=file)\n",
    "with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/film/sum/diabetes/test_losses_dict.pkl\", \"wb\") as file:\n",
    "    pkl.dump(losses, file=file)\n",
    "with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/film/sum/diabetes/test_labels.pkl\", \"wb\") as file:\n",
    "    pkl.dump(test_label_list, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
