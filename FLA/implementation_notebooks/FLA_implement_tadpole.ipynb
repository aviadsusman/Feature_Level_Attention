{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main as a\n",
    "import pickle as pkl\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/tadpole/X.pkl\", \"rb\") as file:\n",
    "    X = pkl.load(file)\n",
    "early = False\n",
    "with open(\"data/tadpole/y.pkl\", \"rb\") as file:\n",
    "    if early:\n",
    "        y = pkl.load(file)[:,1:]\n",
    "    else:\n",
    "        y = pkl.load(file)[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0]*X.shape[1], X.shape[2])\n",
    "y = y.flatten()\n",
    "weight = torch.tensor(compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, stratify=y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'main' from '/Users/aviadsusman/Documents/Python_Projects/FLA_2/FLA/main.py'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = a.npDataset(X_train,y_train)\n",
    "test_dataset = a.npDataset(X_test,y_test)\n",
    "val_dataset = a.npDataset(X_val,y_val)\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [160,40,10]\n",
    "attn_heads = 1\n",
    "model = a.FLANN(input_dim=337, hidden_dims=hidden_dims, output_dim=3, attn_heads=attn_heads, activation=nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "metric = a.MacroF1Score(num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1108], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0725], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.6380], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.6316], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.3881], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4458], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for x in model.flas[0].parameters():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010940074920654297 337\n",
      "0.0029408931732177734 160\n",
      "0.0007979869842529297 40\n",
      "0.009449958801269531 337\n",
      "0.002869129180908203 160\n",
      "0.00022029876708984375 40\n",
      "0.009325027465820312 337\n",
      "0.0026140213012695312 160\n",
      "0.00018167495727539062 40\n",
      "0.007921934127807617 337\n",
      "0.002045869827270508 160\n",
      "0.0001671314239501953 40\n",
      "0.006518125534057617 337\n",
      "0.0015680789947509766 160\n",
      "0.00012302398681640625 40\n",
      "0.0068590641021728516 337\n",
      "0.001667022705078125 160\n",
      "0.00012612342834472656 40\n",
      "0.0057830810546875 337\n",
      "0.0014879703521728516 160\n",
      "0.00025391578674316406 40\n",
      "0.0058820247650146484 337\n",
      "0.0015850067138671875 160\n",
      "0.00015306472778320312 40\n",
      "0.0060389041900634766 337\n",
      "0.0013899803161621094 160\n",
      "0.00019288063049316406 40\n",
      "0.005957126617431641 337\n",
      "0.0019369125366210938 160\n",
      "0.00037288665771484375 40\n",
      "0.005857944488525391 337\n",
      "0.001219034194946289 160\n",
      "0.000164031982421875 40\n",
      "0.0065920352935791016 337\n",
      "0.0016820430755615234 160\n",
      "0.0001418590545654297 40\n",
      "0.0061109066009521484 337\n",
      "0.0012211799621582031 160\n",
      "0.00013685226440429688 40\n",
      "0.005923032760620117 337\n",
      "0.0017249584197998047 160\n",
      "0.00013399124145507812 40\n",
      "0.0059049129486083984 337\n",
      "0.001547098159790039 160\n",
      "0.0003330707550048828 40\n",
      "0.005676984786987305 337\n",
      "0.0012221336364746094 160\n",
      "0.0001270771026611328 40\n",
      "0.006085872650146484 337\n",
      "0.0012369155883789062 160\n",
      "0.0001461505889892578 40\n",
      "0.0058422088623046875 337\n",
      "0.0012810230255126953 160\n",
      "0.0001327991485595703 40\n",
      "0.00591731071472168 337\n",
      "0.001766204833984375 160\n",
      "0.0001049041748046875 40\n",
      "0.005785942077636719 337\n",
      "0.0014379024505615234 160\n",
      "0.0003268718719482422 40\n",
      "0.005872249603271484 337\n",
      "0.0019519329071044922 160\n",
      "0.0001590251922607422 40\n",
      "0.0032591819763183594 337\n",
      "0.0007529258728027344 160\n",
      "0.0001049041748046875 40\n",
      "0.006737947463989258 337\n",
      "0.0018680095672607422 160\n",
      "0.00010967254638671875 40\n",
      "0.006248950958251953 337\n",
      "0.0016570091247558594 160\n",
      "0.00011014938354492188 40\n",
      "0.003056764602661133 337\n",
      "0.0005450248718261719 160\n",
      "0.00015783309936523438 40\n",
      "Epoch 1, Validation Loss: 0.8218\n",
      "0.00587010383605957 337\n",
      "0.0013818740844726562 160\n",
      "0.000186920166015625 40\n",
      "0.006249904632568359 337\n",
      "0.001374959945678711 160\n",
      "0.0001742839813232422 40\n",
      "0.005982160568237305 337\n",
      "0.0013151168823242188 160\n",
      "0.00011992454528808594 40\n",
      "0.0069010257720947266 337\n",
      "0.0013179779052734375 160\n",
      "0.000125885009765625 40\n",
      "0.006396293640136719 337\n",
      "0.0012388229370117188 160\n",
      "0.00014901161193847656 40\n",
      "0.005568981170654297 337\n",
      "0.0012388229370117188 160\n",
      "0.00010991096496582031 40\n",
      "0.00654292106628418 337\n",
      "0.0012538433074951172 160\n",
      "0.0003180503845214844 40\n",
      "0.00583195686340332 337\n",
      "0.0014567375183105469 160\n",
      "0.0002079010009765625 40\n",
      "0.005811929702758789 337\n",
      "0.0013561248779296875 160\n",
      "0.00031185150146484375 40\n",
      "0.006064891815185547 337\n",
      "0.0013821125030517578 160\n",
      "0.0001761913299560547 40\n",
      "0.005844831466674805 337\n",
      "0.0012390613555908203 160\n",
      "0.0003440380096435547 40\n",
      "0.0065479278564453125 337\n",
      "0.0014581680297851562 160\n",
      "0.00016379356384277344 40\n",
      "0.005913257598876953 337\n",
      "0.0012638568878173828 160\n",
      "0.00012493133544921875 40\n",
      "0.0062677860260009766 337\n",
      "0.0013439655303955078 160\n",
      "0.00011992454528808594 40\n",
      "0.005949974060058594 337\n",
      "0.0016319751739501953 160\n",
      "0.0001430511474609375 40\n",
      "0.005705833435058594 337\n",
      "0.0014259815216064453 160\n",
      "0.00012969970703125 40\n",
      "0.0059239864349365234 337\n",
      "0.0013000965118408203 160\n",
      "0.00013113021850585938 40\n",
      "0.006125211715698242 337\n",
      "0.0012309551239013672 160\n",
      "0.00016832351684570312 40\n",
      "0.006365060806274414 337\n",
      "0.0013039112091064453 160\n",
      "0.00012803077697753906 40\n",
      "0.006239891052246094 337\n",
      "0.0014846324920654297 160\n",
      "0.00014591217041015625 40\n",
      "0.005697011947631836 337\n",
      "0.0015192031860351562 160\n",
      "0.00011396408081054688 40\n",
      "0.003303050994873047 337\n",
      "0.0010502338409423828 160\n",
      "8.20159912109375e-05 40\n",
      "0.0065381526947021484 337\n",
      "0.001583099365234375 160\n",
      "8.58306884765625e-05 40\n",
      "0.007166147232055664 337\n",
      "0.0017507076263427734 160\n",
      "0.00012993812561035156 40\n",
      "0.0029587745666503906 337\n",
      "0.0005080699920654297 160\n",
      "0.0001590251922607422 40\n",
      "Epoch 2, Validation Loss: 0.7001\n",
      "0.005913972854614258 337\n",
      "0.001477956771850586 160\n",
      "0.00011801719665527344 40\n",
      "0.005806684494018555 337\n",
      "0.0013129711151123047 160\n",
      "0.0002467632293701172 40\n",
      "0.005692243576049805 337\n",
      "0.0013272762298583984 160\n",
      "0.00014162063598632812 40\n",
      "0.005778074264526367 337\n",
      "0.0015079975128173828 160\n",
      "9.322166442871094e-05 40\n",
      "0.0058710575103759766 337\n",
      "0.0012149810791015625 160\n",
      "0.00019884109497070312 40\n",
      "0.005620002746582031 337\n",
      "0.0012450218200683594 160\n",
      "0.00014495849609375 40\n",
      "0.005995035171508789 337\n",
      "0.0012128353118896484 160\n",
      "0.0001270771026611328 40\n",
      "0.005761861801147461 337\n",
      "0.0013267993927001953 160\n",
      "0.00013303756713867188 40\n",
      "0.005856990814208984 337\n",
      "0.0017080307006835938 160\n",
      "0.0001552104949951172 40\n",
      "0.0067901611328125 337\n",
      "0.0019571781158447266 160\n",
      "0.00020503997802734375 40\n",
      "0.005900859832763672 337\n",
      "0.0012128353118896484 160\n",
      "0.0002048015594482422 40\n",
      "0.005813121795654297 337\n",
      "0.001417398452758789 160\n",
      "0.0001571178436279297 40\n",
      "0.005906105041503906 337\n",
      "0.0014200210571289062 160\n",
      "0.00010704994201660156 40\n",
      "0.0056951045989990234 337\n",
      "0.0016241073608398438 160\n",
      "0.0001437664031982422 40\n",
      "0.006270885467529297 337\n",
      "0.0014467239379882812 160\n",
      "0.0003380775451660156 40\n",
      "0.0058209896087646484 337\n",
      "0.001413106918334961 160\n",
      "0.0002980232238769531 40\n",
      "0.006495952606201172 337\n",
      "0.0019609928131103516 160\n",
      "0.00013899803161621094 40\n",
      "0.00657200813293457 337\n",
      "0.001748800277709961 160\n",
      "0.0002300739288330078 40\n",
      "0.006498813629150391 337\n",
      "0.0015799999237060547 160\n",
      "0.0001728534698486328 40\n",
      "0.0058917999267578125 337\n",
      "0.0015110969543457031 160\n",
      "0.00027370452880859375 40\n",
      "0.0059871673583984375 337\n",
      "0.0016350746154785156 160\n",
      "0.00018286705017089844 40\n",
      "0.003906965255737305 337\n",
      "0.0010387897491455078 160\n",
      "0.00012183189392089844 40\n",
      "0.006977081298828125 337\n",
      "0.0013577938079833984 160\n",
      "0.00017499923706054688 40\n",
      "0.007255077362060547 337\n",
      "0.0017201900482177734 160\n",
      "0.00013709068298339844 40\n",
      "0.0032470226287841797 337\n",
      "0.0006861686706542969 160\n",
      "5.91278076171875e-05 40\n",
      "Epoch 3, Validation Loss: 0.5661\n",
      "0.0057621002197265625 337\n",
      "0.0014410018920898438 160\n",
      "0.0001621246337890625 40\n",
      "0.00669407844543457 337\n",
      "0.0014908313751220703 160\n",
      "0.00013303756713867188 40\n",
      "0.006443023681640625 337\n",
      "0.0015518665313720703 160\n",
      "0.00026702880859375 40\n",
      "0.006724834442138672 337\n",
      "0.001987934112548828 160\n",
      "0.00015997886657714844 40\n",
      "0.006776094436645508 337\n",
      "0.0017867088317871094 160\n",
      "0.00018405914306640625 40\n",
      "0.006448984146118164 337\n",
      "0.0016269683837890625 160\n",
      "0.0002129077911376953 40\n",
      "0.006332874298095703 337\n",
      "0.0017583370208740234 160\n",
      "0.00036406517028808594 40\n",
      "0.00657200813293457 337\n",
      "0.0016710758209228516 160\n",
      "0.00013184547424316406 40\n",
      "0.005766153335571289 337\n",
      "0.0013318061828613281 160\n",
      "0.0001418590545654297 40\n",
      "0.005739688873291016 337\n",
      "0.0011949539184570312 160\n",
      "0.00018405914306640625 40\n",
      "0.005831003189086914 337\n",
      "0.001318216323852539 160\n",
      "0.00013184547424316406 40\n",
      "0.0056459903717041016 337\n",
      "0.0013840198516845703 160\n",
      "0.0002868175506591797 40\n",
      "0.006027936935424805 337\n",
      "0.001439809799194336 160\n",
      "0.00014710426330566406 40\n",
      "0.0056400299072265625 337\n",
      "0.001516103744506836 160\n",
      "0.00022912025451660156 40\n",
      "0.00627589225769043 337\n",
      "0.0012788772583007812 160\n",
      "0.00010704994201660156 40\n",
      "0.005650043487548828 337\n",
      "0.0013952255249023438 160\n",
      "0.00019502639770507812 40\n",
      "0.005525112152099609 337\n",
      "0.0015377998352050781 160\n",
      "0.0001308917999267578 40\n",
      "0.0057373046875 337\n",
      "0.0012297630310058594 160\n",
      "0.00014019012451171875 40\n",
      "0.006335020065307617 337\n",
      "0.0014870166778564453 160\n",
      "0.00011801719665527344 40\n",
      "0.005631923675537109 337\n",
      "0.0013539791107177734 160\n",
      "0.00013303756713867188 40\n",
      "0.0057408809661865234 337\n",
      "0.001500844955444336 160\n",
      "0.0003681182861328125 40\n",
      "0.003370046615600586 337\n",
      "0.0010743141174316406 160\n",
      "0.00013780593872070312 40\n",
      "0.007367134094238281 337\n",
      "0.00138092041015625 160\n",
      "0.00016117095947265625 40\n",
      "0.006930351257324219 337\n",
      "0.0013058185577392578 160\n",
      "0.0002837181091308594 40\n",
      "0.0030400753021240234 337\n",
      "0.0007731914520263672 160\n",
      "0.00013399124145507812 40\n",
      "Epoch 4, Validation Loss: 0.4884\n",
      "0.006431102752685547 337\n",
      "0.0012218952178955078 160\n",
      "0.0002689361572265625 40\n",
      "0.005754232406616211 337\n",
      "0.0020020008087158203 160\n",
      "0.0001380443572998047 40\n",
      "0.0061321258544921875 337\n",
      "0.0015628337860107422 160\n",
      "0.00019288063049316406 40\n",
      "0.0062062740325927734 337\n",
      "0.0012867450714111328 160\n",
      "0.00018525123596191406 40\n",
      "0.006432056427001953 337\n",
      "0.0013990402221679688 160\n",
      "0.00015592575073242188 40\n",
      "0.006523847579956055 337\n",
      "0.001252889633178711 160\n",
      "0.00020194053649902344 40\n",
      "0.005897998809814453 337\n",
      "0.0016498565673828125 160\n",
      "0.0001819133758544922 40\n",
      "0.005751132965087891 337\n",
      "0.0014221668243408203 160\n",
      "0.00028705596923828125 40\n",
      "0.006075143814086914 337\n",
      "0.0015900135040283203 160\n",
      "0.00017499923706054688 40\n",
      "0.005711793899536133 337\n",
      "0.0012788772583007812 160\n",
      "0.00017690658569335938 40\n",
      "0.005702972412109375 337\n",
      "0.0013890266418457031 160\n",
      "0.0001308917999267578 40\n",
      "0.00616908073425293 337\n",
      "0.0012829303741455078 160\n",
      "0.00022983551025390625 40\n",
      "0.0058901309967041016 337\n",
      "0.0013828277587890625 160\n",
      "0.0001289844512939453 40\n",
      "0.005865812301635742 337\n",
      "0.00121307373046875 160\n",
      "0.000263214111328125 40\n",
      "0.005658864974975586 337\n",
      "0.0013048648834228516 160\n",
      "0.00024580955505371094 40\n",
      "0.006521940231323242 337\n",
      "0.0012249946594238281 160\n",
      "0.00014901161193847656 40\n",
      "0.0059931278228759766 337\n",
      "0.001271963119506836 160\n",
      "0.00014209747314453125 40\n",
      "0.006936073303222656 337\n",
      "0.0013298988342285156 160\n",
      "0.0001621246337890625 40\n",
      "0.0060422420501708984 337\n",
      "0.0018720626831054688 160\n",
      "0.00020313262939453125 40\n",
      "0.005876064300537109 337\n",
      "0.001329183578491211 160\n",
      "0.00011301040649414062 40\n",
      "0.005553007125854492 337\n",
      "0.0012969970703125 160\n",
      "0.0003120899200439453 40\n",
      "0.0034410953521728516 337\n",
      "0.0010330677032470703 160\n",
      "9.083747863769531e-05 40\n",
      "0.007756710052490234 337\n",
      "0.0017707347869873047 160\n",
      "0.000148773193359375 40\n",
      "0.0077250003814697266 337\n",
      "0.0016219615936279297 160\n",
      "0.00022983551025390625 40\n",
      "0.0034313201904296875 337\n",
      "0.0006630420684814453 160\n",
      "7.081031799316406e-05 40\n",
      "Epoch 5, Validation Loss: 0.6143\n",
      "0.005994081497192383 337\n",
      "0.001689910888671875 160\n",
      "0.00032019615173339844 40\n",
      "0.006172895431518555 337\n",
      "0.0016620159149169922 160\n",
      "0.00021195411682128906 40\n",
      "0.00598597526550293 337\n",
      "0.0013151168823242188 160\n",
      "0.00015401840209960938 40\n",
      "0.0059359073638916016 337\n",
      "0.0013339519500732422 160\n",
      "0.0002601146697998047 40\n",
      "0.006353855133056641 337\n",
      "0.0012900829315185547 160\n",
      "0.00026798248291015625 40\n",
      "0.005548000335693359 337\n",
      "0.0016140937805175781 160\n",
      "0.00014901161193847656 40\n",
      "0.006551027297973633 337\n",
      "0.0016410350799560547 160\n",
      "0.00017786026000976562 40\n",
      "0.006058931350708008 337\n",
      "0.0017158985137939453 160\n",
      "0.00020813941955566406 40\n",
      "0.00580286979675293 337\n",
      "0.0019028186798095703 160\n",
      "0.00013113021850585938 40\n",
      "0.005519866943359375 337\n",
      "0.0018029212951660156 160\n",
      "0.00017786026000976562 40\n",
      "0.005815982818603516 337\n",
      "0.0016448497772216797 160\n",
      "0.00013208389282226562 40\n",
      "0.005934953689575195 337\n",
      "0.0012867450714111328 160\n",
      "0.0002849102020263672 40\n",
      "0.0058231353759765625 337\n",
      "0.0013303756713867188 160\n",
      "0.00016880035400390625 40\n",
      "0.005839824676513672 337\n",
      "0.0015227794647216797 160\n",
      "0.0002970695495605469 40\n",
      "0.005419015884399414 337\n",
      "0.0012726783752441406 160\n",
      "0.00018095970153808594 40\n",
      "0.005960941314697266 337\n",
      "0.0013327598571777344 160\n",
      "0.00015091896057128906 40\n",
      "0.005798816680908203 337\n",
      "0.001680135726928711 160\n",
      "0.0001499652862548828 40\n",
      "0.006026029586791992 337\n",
      "0.0013811588287353516 160\n",
      "0.000125885009765625 40\n",
      "0.0054318904876708984 337\n",
      "0.0012841224670410156 160\n",
      "0.00012612342834472656 40\n",
      "0.0058820247650146484 337\n",
      "0.0012040138244628906 160\n",
      "0.0001327991485595703 40\n",
      "0.0056231021881103516 337\n",
      "0.0012121200561523438 160\n",
      "0.0001289844512939453 40\n",
      "0.003125905990600586 337\n",
      "0.0006372928619384766 160\n",
      "0.00011205673217773438 40\n",
      "0.007117033004760742 337\n",
      "0.001299142837524414 160\n",
      "0.00010704994201660156 40\n",
      "0.007141828536987305 337\n",
      "0.0015790462493896484 160\n",
      "0.00010609626770019531 40\n",
      "0.0025370121002197266 337\n",
      "0.0005042552947998047 160\n",
      "5.626678466796875e-05 40\n",
      "Epoch 6, Validation Loss: 0.4596\n",
      "0.0056841373443603516 337\n",
      "0.0018329620361328125 160\n",
      "0.0001430511474609375 40\n",
      "0.005468845367431641 337\n",
      "0.0013570785522460938 160\n",
      "0.00012183189392089844 40\n",
      "0.0054340362548828125 337\n",
      "0.0013003349304199219 160\n",
      "0.0001327991485595703 40\n",
      "0.005541324615478516 337\n",
      "0.0012862682342529297 160\n",
      "0.00021505355834960938 40\n",
      "0.0060880184173583984 337\n",
      "0.0017290115356445312 160\n",
      "0.00012493133544921875 40\n",
      "0.005501985549926758 337\n",
      "0.0013599395751953125 160\n",
      "0.0001399517059326172 40\n",
      "0.005595207214355469 337\n",
      "0.0012729167938232422 160\n",
      "0.0001239776611328125 40\n",
      "0.005465030670166016 337\n",
      "0.0012211799621582031 160\n",
      "0.0001232624053955078 40\n",
      "0.005640268325805664 337\n",
      "0.0012221336364746094 160\n",
      "0.00014710426330566406 40\n",
      "0.005837917327880859 337\n",
      "0.0012199878692626953 160\n",
      "0.00011706352233886719 40\n",
      "0.006793975830078125 337\n",
      "0.001979827880859375 160\n",
      "0.00018095970153808594 40\n",
      "0.006379127502441406 337\n",
      "0.0017688274383544922 160\n",
      "0.00011897087097167969 40\n",
      "0.0054438114166259766 337\n",
      "0.0016088485717773438 160\n",
      "0.0001270771026611328 40\n",
      "0.005702018737792969 337\n",
      "0.001332998275756836 160\n",
      "0.00014901161193847656 40\n",
      "0.005454063415527344 337\n",
      "0.0012140274047851562 160\n",
      "0.0001430511474609375 40\n",
      "0.005491971969604492 337\n",
      "0.001219034194946289 160\n",
      "0.00014281272888183594 40\n",
      "0.005496978759765625 337\n",
      "0.0015649795532226562 160\n",
      "0.00014281272888183594 40\n",
      "0.0054929256439208984 337\n",
      "0.0012128353118896484 160\n",
      "0.00011992454528808594 40\n",
      "0.005485057830810547 337\n",
      "0.0012569427490234375 160\n",
      "0.00011706352233886719 40\n",
      "0.005522966384887695 337\n",
      "0.001209259033203125 160\n",
      "0.0001418590545654297 40\n",
      "0.005578041076660156 337\n",
      "0.0012021064758300781 160\n",
      "0.0001430511474609375 40\n",
      "0.0031549930572509766 337\n",
      "0.0006561279296875 160\n",
      "0.00010395050048828125 40\n",
      "0.006616115570068359 337\n",
      "0.0013120174407958984 160\n",
      "0.00010395050048828125 40\n",
      "0.00595402717590332 337\n",
      "0.0013401508331298828 160\n",
      "9.679794311523438e-05 40\n",
      "0.002531766891479492 337\n",
      "0.0006227493286132812 160\n",
      "6.29425048828125e-05 40\n",
      "Epoch 7, Validation Loss: 0.6860\n",
      "0.0058460235595703125 337\n",
      "0.0017080307006835938 160\n",
      "0.0001270771026611328 40\n",
      "0.00589299201965332 337\n",
      "0.0016210079193115234 160\n",
      "0.00011086463928222656 40\n",
      "0.005909919738769531 337\n",
      "0.0013048648834228516 160\n",
      "0.000125885009765625 40\n",
      "0.0062329769134521484 337\n",
      "0.0012898445129394531 160\n",
      "0.00024700164794921875 40\n",
      "0.005606174468994141 337\n",
      "0.0012121200561523438 160\n",
      "0.00010895729064941406 40\n",
      "0.005457878112792969 337\n",
      "0.001252889633178711 160\n",
      "0.00014591217041015625 40\n",
      "0.005560874938964844 337\n",
      "0.0017180442810058594 160\n",
      "0.00011801719665527344 40\n",
      "0.005569934844970703 337\n",
      "0.0012061595916748047 160\n",
      "0.0001747608184814453 40\n",
      "0.005877017974853516 337\n",
      "0.0011951923370361328 160\n",
      "0.0001468658447265625 40\n",
      "0.005457878112792969 337\n",
      "0.0012631416320800781 160\n",
      "0.00015807151794433594 40\n",
      "0.00554203987121582 337\n",
      "0.001386880874633789 160\n",
      "0.000125885009765625 40\n",
      "0.005504131317138672 337\n",
      "0.0012180805206298828 160\n",
      "0.00012302398681640625 40\n",
      "0.005485057830810547 337\n",
      "0.0013108253479003906 160\n",
      "0.0001251697540283203 40\n",
      "0.00546717643737793 337\n",
      "0.0011870861053466797 160\n",
      "0.0001347064971923828 40\n",
      "0.005638837814331055 337\n",
      "0.0013370513916015625 160\n",
      "0.00013899803161621094 40\n",
      "0.005496025085449219 337\n",
      "0.0012149810791015625 160\n",
      "0.00022912025451660156 40\n",
      "0.005403280258178711 337\n",
      "0.0012848377227783203 160\n",
      "0.00011014938354492188 40\n",
      "0.005713939666748047 337\n",
      "0.0019278526306152344 160\n",
      "0.0001442432403564453 40\n",
      "0.005516767501831055 337\n",
      "0.0012197494506835938 160\n",
      "0.00012493133544921875 40\n",
      "0.005569934844970703 337\n",
      "0.0012297630310058594 160\n",
      "0.0001049041748046875 40\n",
      "0.007180929183959961 337\n",
      "0.0012516975402832031 160\n",
      "0.0001220703125 40\n",
      "0.0031011104583740234 337\n",
      "0.000659942626953125 160\n",
      "0.00010204315185546875 40\n",
      "0.007504940032958984 337\n",
      "0.002206087112426758 160\n",
      "0.00027108192443847656 40\n",
      "0.007925033569335938 337\n",
      "0.0021092891693115234 160\n",
      "0.00030994415283203125 40\n",
      "0.0034799575805664062 337\n",
      "0.0008368492126464844 160\n",
      "0.00014972686767578125 40\n",
      "Epoch 8, Validation Loss: 0.4275\n",
      "0.00555109977722168 337\n",
      "0.0012691020965576172 160\n",
      "0.00012183189392089844 40\n",
      "0.006105661392211914 337\n",
      "0.0012247562408447266 160\n",
      "0.00014090538024902344 40\n",
      "0.005441904067993164 337\n",
      "0.0012547969818115234 160\n",
      "0.0001289844512939453 40\n",
      "0.005439043045043945 337\n",
      "0.0012159347534179688 160\n",
      "0.0001277923583984375 40\n",
      "0.005507946014404297 337\n",
      "0.0012431144714355469 160\n",
      "0.0002200603485107422 40\n",
      "0.005478858947753906 337\n",
      "0.0012271404266357422 160\n",
      "0.00012993812561035156 40\n",
      "0.0055141448974609375 337\n",
      "0.0012023448944091797 160\n",
      "0.0001461505889892578 40\n",
      "0.006536006927490234 337\n",
      "0.0016930103302001953 160\n",
      "0.00015592575073242188 40\n",
      "0.005589008331298828 337\n",
      "0.0013458728790283203 160\n",
      "0.0001239776611328125 40\n",
      "0.005798816680908203 337\n",
      "0.0015702247619628906 160\n",
      "0.00022077560424804688 40\n",
      "0.005658864974975586 337\n",
      "0.0012612342834472656 160\n",
      "0.00012493133544921875 40\n",
      "0.0056362152099609375 337\n",
      "0.001260995864868164 160\n",
      "0.0001239776611328125 40\n",
      "0.007341861724853516 337\n",
      "0.0022101402282714844 160\n",
      "0.0003838539123535156 40\n",
      "0.005744218826293945 337\n",
      "0.001306772232055664 160\n",
      "0.0001621246337890625 40\n",
      "0.00570988655090332 337\n",
      "0.001275777816772461 160\n",
      "0.00012612342834472656 40\n",
      "0.005830049514770508 337\n",
      "0.0012531280517578125 160\n",
      "9.799003601074219e-05 40\n",
      "0.0058858394622802734 337\n",
      "0.0013289451599121094 160\n",
      "0.0001251697540283203 40\n",
      "0.005837917327880859 337\n",
      "0.0014710426330566406 160\n",
      "0.00013184547424316406 40\n",
      "0.00580286979675293 337\n",
      "0.0012631416320800781 160\n",
      "0.00016379356384277344 40\n",
      "0.006011247634887695 337\n",
      "0.0013608932495117188 160\n",
      "0.00016188621520996094 40\n",
      "0.005852937698364258 337\n",
      "0.0012159347534179688 160\n",
      "0.0001418590545654297 40\n",
      "0.0032579898834228516 337\n",
      "0.0006749629974365234 160\n",
      "8.225440979003906e-05 40\n",
      "0.006975889205932617 337\n",
      "0.0014910697937011719 160\n",
      "0.00010704994201660156 40\n",
      "0.006567955017089844 337\n",
      "0.0015759468078613281 160\n",
      "9.989738464355469e-05 40\n",
      "0.0026259422302246094 337\n",
      "0.00048279762268066406 160\n",
      "5.5789947509765625e-05 40\n",
      "Epoch 9, Validation Loss: 0.3776\n",
      "0.005569934844970703 337\n",
      "0.0012547969818115234 160\n",
      "0.00012612342834472656 40\n",
      "0.005544900894165039 337\n",
      "0.001210927963256836 160\n",
      "0.00017595291137695312 40\n",
      "0.005718708038330078 337\n",
      "0.0012049674987792969 160\n",
      "0.0002009868621826172 40\n",
      "0.005706787109375 337\n",
      "0.0012331008911132812 160\n",
      "0.00011992454528808594 40\n",
      "0.005918979644775391 337\n",
      "0.001322031021118164 160\n",
      "0.0001289844512939453 40\n",
      "0.005445957183837891 337\n",
      "0.0012521743774414062 160\n",
      "0.00014019012451171875 40\n",
      "0.005674123764038086 337\n",
      "0.0012099742889404297 160\n",
      "0.0001437664031982422 40\n",
      "0.005593776702880859 337\n",
      "0.0013051033020019531 160\n",
      "0.0001327991485595703 40\n",
      "0.0055999755859375 337\n",
      "0.0014700889587402344 160\n",
      "0.00012993812561035156 40\n",
      "0.00539398193359375 337\n",
      "0.0013277530670166016 160\n",
      "0.00012731552124023438 40\n",
      "0.005585193634033203 337\n",
      "0.0012850761413574219 160\n",
      "0.00011992454528808594 40\n",
      "0.005671977996826172 337\n",
      "0.0013151168823242188 160\n",
      "0.00011801719665527344 40\n",
      "0.006284952163696289 337\n",
      "0.0013337135314941406 160\n",
      "0.0002601146697998047 40\n",
      "0.0053598880767822266 337\n",
      "0.0012061595916748047 160\n",
      "0.00014281272888183594 40\n",
      "0.005926847457885742 337\n",
      "0.0012784004211425781 160\n",
      "0.00012493133544921875 40\n",
      "0.005446195602416992 337\n",
      "0.0013000965118408203 160\n",
      "0.00012373924255371094 40\n",
      "0.005475044250488281 337\n",
      "0.0013172626495361328 160\n",
      "0.0001220703125 40\n",
      "0.005561113357543945 337\n",
      "0.0012259483337402344 160\n",
      "0.00011587142944335938 40\n",
      "0.0075283050537109375 337\n",
      "0.0016167163848876953 160\n",
      "0.00014829635620117188 40\n",
      "0.006032228469848633 337\n",
      "0.0016911029815673828 160\n",
      "0.00014090538024902344 40\n",
      "0.005483150482177734 337\n",
      "0.0011920928955078125 160\n",
      "0.0001246929168701172 40\n",
      "0.003512144088745117 337\n",
      "0.00067901611328125 160\n",
      "7.295608520507812e-05 40\n",
      "0.006649017333984375 337\n",
      "0.0013427734375 160\n",
      "0.00010704994201660156 40\n",
      "0.006450176239013672 337\n",
      "0.0017139911651611328 160\n",
      "0.00011587142944335938 40\n",
      "0.0023849010467529297 337\n",
      "0.0006070137023925781 160\n",
      "0.00010395050048828125 40\n",
      "Epoch 10, Validation Loss: 0.5102\n",
      "0.005793094635009766 337\n",
      "0.0012428760528564453 160\n",
      "0.00015091896057128906 40\n",
      "0.005721092224121094 337\n",
      "0.0013511180877685547 160\n",
      "0.00016999244689941406 40\n",
      "0.005429983139038086 337\n",
      "0.0013208389282226562 160\n",
      "0.00012230873107910156 40\n",
      "0.006085872650146484 337\n",
      "0.0012309551239013672 160\n",
      "0.00011873245239257812 40\n",
      "0.006094694137573242 337\n",
      "0.0016989707946777344 160\n",
      "0.0001289844512939453 40\n",
      "0.00564885139465332 337\n",
      "0.0013689994812011719 160\n",
      "0.00023889541625976562 40\n",
      "0.005545854568481445 337\n",
      "0.0016300678253173828 160\n",
      "0.00013113021850585938 40\n",
      "0.006105184555053711 337\n",
      "0.002042055130004883 160\n",
      "0.000225067138671875 40\n",
      "0.0056269168853759766 337\n",
      "0.0016219615936279297 160\n",
      "0.0002779960632324219 40\n",
      "0.006112098693847656 337\n",
      "0.0016338825225830078 160\n",
      "0.00012493133544921875 40\n",
      "0.005937814712524414 337\n",
      "0.0012271404266357422 160\n",
      "0.00011920928955078125 40\n",
      "0.005691051483154297 337\n",
      "0.001547098159790039 160\n",
      "0.00024390220642089844 40\n",
      "0.006083011627197266 337\n",
      "0.00133514404296875 160\n",
      "0.00010013580322265625 40\n",
      "0.005568981170654297 337\n",
      "0.0013010501861572266 160\n",
      "0.00012803077697753906 40\n",
      "0.005815029144287109 337\n",
      "0.0012679100036621094 160\n",
      "0.00012493133544921875 40\n",
      "0.005639076232910156 337\n",
      "0.0013570785522460938 160\n",
      "0.00013303756713867188 40\n",
      "0.005808830261230469 337\n",
      "0.0012540817260742188 160\n",
      "0.0001289844512939453 40\n",
      "0.00561213493347168 337\n",
      "0.0013191699981689453 160\n",
      "0.0001251697540283203 40\n",
      "0.006933927536010742 337\n",
      "0.0012941360473632812 160\n",
      "0.0003120899200439453 40\n",
      "0.005496025085449219 337\n",
      "0.001207113265991211 160\n",
      "0.00012302398681640625 40\n",
      "0.0055468082427978516 337\n",
      "0.0012068748474121094 160\n",
      "0.00011897087097167969 40\n",
      "0.0031630992889404297 337\n",
      "0.0010139942169189453 160\n",
      "0.00010204315185546875 40\n",
      "0.007311105728149414 337\n",
      "0.0013852119445800781 160\n",
      "0.0002429485321044922 40\n",
      "0.006656169891357422 337\n",
      "0.002048969268798828 160\n",
      "0.00011491775512695312 40\n",
      "0.0028333663940429688 337\n",
      "0.000743865966796875 160\n",
      "8.702278137207031e-05 40\n",
      "Epoch 11, Validation Loss: 0.5367\n",
      "0.005702018737792969 337\n",
      "0.0013360977172851562 160\n",
      "0.00014209747314453125 40\n",
      "0.005324125289916992 337\n",
      "0.0012140274047851562 160\n",
      "0.00012302398681640625 40\n",
      "0.005539894104003906 337\n",
      "0.0012509822845458984 160\n",
      "0.00012493133544921875 40\n",
      "0.0056149959564208984 337\n",
      "0.0012412071228027344 160\n",
      "0.00012230873107910156 40\n",
      "0.005445957183837891 337\n",
      "0.0012249946594238281 160\n",
      "0.00011491775512695312 40\n",
      "0.005548954010009766 337\n",
      "0.0012710094451904297 160\n",
      "0.00012612342834472656 40\n",
      "0.005623817443847656 337\n",
      "0.00121307373046875 160\n",
      "0.00014472007751464844 40\n",
      "0.005509138107299805 337\n",
      "0.0013229846954345703 160\n",
      "0.00014495849609375 40\n",
      "0.005548000335693359 337\n",
      "0.0012669563293457031 160\n",
      "0.0001201629638671875 40\n",
      "0.005522012710571289 337\n",
      "0.0013530254364013672 160\n",
      "0.00024318695068359375 40\n",
      "0.006009101867675781 337\n",
      "0.0013689994812011719 160\n",
      "0.00032901763916015625 40\n",
      "0.005852222442626953 337\n",
      "0.0012390613555908203 160\n",
      "0.00011491775512695312 40\n",
      "0.005919933319091797 337\n",
      "0.0016071796417236328 160\n",
      "0.00015592575073242188 40\n",
      "0.0056400299072265625 337\n",
      "0.00173187255859375 160\n",
      "0.0001308917999267578 40\n",
      "0.006188869476318359 337\n",
      "0.0016183853149414062 160\n",
      "0.00011801719665527344 40\n",
      "0.005647897720336914 337\n",
      "0.0012669563293457031 160\n",
      "0.00014901161193847656 40\n",
      "0.0059051513671875 337\n",
      "0.0013880729675292969 160\n",
      "0.0002701282501220703 40\n",
      "0.005532026290893555 337\n",
      "0.0012149810791015625 160\n",
      "0.00011897087097167969 40\n",
      "0.005897045135498047 337\n",
      "0.0014426708221435547 160\n",
      "0.00012493133544921875 40\n",
      "0.005907297134399414 337\n",
      "0.0016109943389892578 160\n",
      "0.00012183189392089844 40\n",
      "0.006748199462890625 337\n",
      "0.0018947124481201172 160\n",
      "0.0001399517059326172 40\n",
      "0.003297090530395508 337\n",
      "0.0006771087646484375 160\n",
      "0.00011110305786132812 40\n",
      "0.0066492557525634766 337\n",
      "0.0016210079193115234 160\n",
      "0.0002448558807373047 40\n",
      "0.007074117660522461 337\n",
      "0.0016930103302001953 160\n",
      "0.00011205673217773438 40\n",
      "0.002705097198486328 337\n",
      "0.0006899833679199219 160\n",
      "0.00010085105895996094 40\n",
      "Epoch 12, Validation Loss: 0.5913\n",
      "0.005828142166137695 337\n",
      "0.0013098716735839844 160\n",
      "0.00014591217041015625 40\n",
      "0.006004810333251953 337\n",
      "0.001332998275756836 160\n",
      "0.00011873245239257812 40\n",
      "0.00650787353515625 337\n",
      "0.0017421245574951172 160\n",
      "0.00015306472778320312 40\n",
      "0.0060882568359375 337\n",
      "0.0013189315795898438 160\n",
      "0.00014591217041015625 40\n",
      "0.006175994873046875 337\n",
      "0.00121307373046875 160\n",
      "0.00016379356384277344 40\n",
      "0.006218910217285156 337\n",
      "0.0018301010131835938 160\n",
      "0.00013208389282226562 40\n",
      "0.006271839141845703 337\n",
      "0.0019690990447998047 160\n",
      "0.00014734268188476562 40\n",
      "0.005861759185791016 337\n",
      "0.0015790462493896484 160\n",
      "0.0001819133758544922 40\n",
      "0.005731105804443359 337\n",
      "0.0012180805206298828 160\n",
      "0.0001468658447265625 40\n",
      "0.005980968475341797 337\n",
      "0.0012202262878417969 160\n",
      "0.00016498565673828125 40\n",
      "0.005689144134521484 337\n",
      "0.0015861988067626953 160\n",
      "0.0001590251922607422 40\n",
      "0.005767107009887695 337\n",
      "0.0017049312591552734 160\n",
      "0.00014710426330566406 40\n",
      "0.006159067153930664 337\n",
      "0.0018188953399658203 160\n",
      "0.0004239082336425781 40\n",
      "0.0068531036376953125 337\n",
      "0.0013611316680908203 160\n",
      "0.00017213821411132812 40\n",
      "0.0063130855560302734 337\n",
      "0.001300811767578125 160\n",
      "0.0001380443572998047 40\n",
      "0.005515098571777344 337\n",
      "0.0012767314910888672 160\n",
      "0.00015115737915039062 40\n",
      "0.005769968032836914 337\n",
      "0.0016131401062011719 160\n",
      "0.00019621849060058594 40\n",
      "0.005736827850341797 337\n",
      "0.0015568733215332031 160\n",
      "0.00010395050048828125 40\n",
      "0.005732059478759766 337\n",
      "0.003020048141479492 160\n",
      "0.0010352134704589844 40\n",
      "0.0058078765869140625 337\n",
      "0.001402139663696289 160\n",
      "0.00013494491577148438 40\n",
      "0.0060460567474365234 337\n",
      "0.00121307373046875 160\n",
      "0.00012493133544921875 40\n",
      "0.0033850669860839844 337\n",
      "0.0008137226104736328 160\n",
      "0.00015616416931152344 40\n",
      "0.006611347198486328 337\n",
      "0.0018918514251708984 160\n",
      "0.00019884109497070312 40\n",
      "0.006876945495605469 337\n",
      "0.0016019344329833984 160\n",
      "0.0002608299255371094 40\n",
      "0.0027723312377929688 337\n",
      "0.0004990100860595703 160\n",
      "8.893013000488281e-05 40\n",
      "Epoch 13, Validation Loss: 0.6069\n",
      "0.006054878234863281 337\n",
      "0.0016939640045166016 160\n",
      "0.0001709461212158203 40\n",
      "0.0060482025146484375 337\n",
      "0.0014989376068115234 160\n",
      "0.00015091896057128906 40\n",
      "0.00574493408203125 337\n",
      "0.0014100074768066406 160\n",
      "0.0001850128173828125 40\n",
      "0.006518125534057617 337\n",
      "0.0015611648559570312 160\n",
      "0.00022077560424804688 40\n",
      "0.0064771175384521484 337\n",
      "0.0014278888702392578 160\n",
      "0.00017881393432617188 40\n",
      "0.0062410831451416016 337\n",
      "0.001600027084350586 160\n",
      "0.00015997886657714844 40\n",
      "0.006277322769165039 337\n",
      "0.0015020370483398438 160\n",
      "0.0003261566162109375 40\n",
      "0.0065042972564697266 337\n",
      "0.001699209213256836 160\n",
      "0.00022673606872558594 40\n",
      "0.006016969680786133 337\n",
      "0.0013568401336669922 160\n",
      "0.00014472007751464844 40\n",
      "0.00585174560546875 337\n",
      "0.0012369155883789062 160\n",
      "0.0001430511474609375 40\n",
      "0.006486177444458008 337\n",
      "0.0012359619140625 160\n",
      "0.00014281272888183594 40\n",
      "0.0061190128326416016 337\n",
      "0.0012211799621582031 160\n",
      "0.00014090538024902344 40\n",
      "0.006251096725463867 337\n",
      "0.0013360977172851562 160\n",
      "0.0001761913299560547 40\n",
      "0.005840778350830078 337\n",
      "0.0013070106506347656 160\n",
      "0.0001277923583984375 40\n",
      "0.006489992141723633 337\n",
      "0.0016341209411621094 160\n",
      "0.00013113021850585938 40\n",
      "0.005486011505126953 337\n",
      "0.001405954360961914 160\n",
      "0.00012183189392089844 40\n",
      "0.0061228275299072266 337\n",
      "0.0016529560089111328 160\n",
      "0.0001533031463623047 40\n",
      "0.005639791488647461 337\n",
      "0.0012278556823730469 160\n",
      "0.00011515617370605469 40\n",
      "0.005755901336669922 337\n",
      "0.0012230873107910156 160\n",
      "0.00014901161193847656 40\n",
      "0.005597829818725586 337\n",
      "0.0012431144714355469 160\n",
      "0.00014328956604003906 40\n",
      "0.006124019622802734 337\n",
      "0.0012428760528564453 160\n",
      "0.00012683868408203125 40\n",
      "0.0031571388244628906 337\n",
      "0.0007898807525634766 160\n",
      "0.0001049041748046875 40\n",
      "0.006879329681396484 337\n",
      "0.001741170883178711 160\n",
      "0.0002028942108154297 40\n",
      "0.006855964660644531 337\n",
      "0.0015048980712890625 160\n",
      "0.00011920928955078125 40\n",
      "0.002950906753540039 337\n",
      "0.0005042552947998047 160\n",
      "7.414817810058594e-05 40\n",
      "Epoch 14, Validation Loss: 0.7536\n",
      "0.005733013153076172 337\n",
      "0.0014100074768066406 160\n",
      "0.00016021728515625 40\n",
      "0.00632786750793457 337\n",
      "0.001619100570678711 160\n",
      "0.0001480579376220703 40\n",
      "0.006022214889526367 337\n",
      "0.0013060569763183594 160\n",
      "0.0002009868621826172 40\n",
      "0.006056785583496094 337\n",
      "0.0015559196472167969 160\n",
      "0.00030422210693359375 40\n",
      "0.0071642398834228516 337\n",
      "0.0015230178833007812 160\n",
      "0.0001647472381591797 40\n",
      "0.005760908126831055 337\n",
      "0.0012099742889404297 160\n",
      "0.00014710426330566406 40\n",
      "0.005803108215332031 337\n",
      "0.0013191699981689453 160\n",
      "0.0001690387725830078 40\n",
      "0.005487203598022461 337\n",
      "0.0012280941009521484 160\n",
      "0.00012993812561035156 40\n",
      "0.005889177322387695 337\n",
      "0.0012280941009521484 160\n",
      "0.00018835067749023438 40\n",
      "0.0056722164154052734 337\n",
      "0.0012938976287841797 160\n",
      "0.00011181831359863281 40\n",
      "0.005677223205566406 337\n",
      "0.0016911029815673828 160\n",
      "0.00018095970153808594 40\n",
      "0.005568981170654297 337\n",
      "0.0012500286102294922 160\n",
      "0.00011110305786132812 40\n",
      "0.005723237991333008 337\n",
      "0.0014538764953613281 160\n",
      "0.00027179718017578125 40\n",
      "0.006913900375366211 337\n",
      "0.001619100570678711 160\n",
      "0.0004391670227050781 40\n",
      "0.0065419673919677734 337\n",
      "0.0015459060668945312 160\n",
      "0.00013303756713867188 40\n",
      "0.006734132766723633 337\n",
      "0.0019011497497558594 160\n",
      "0.0002300739288330078 40\n",
      "0.006196022033691406 337\n",
      "0.0014662742614746094 160\n",
      "0.0001270771026611328 40\n",
      "0.005682945251464844 337\n",
      "0.0012280941009521484 160\n",
      "9.894371032714844e-05 40\n",
      "0.00551605224609375 337\n",
      "0.0013623237609863281 160\n",
      "0.00018835067749023438 40\n",
      "0.005749702453613281 337\n",
      "0.0014209747314453125 160\n",
      "0.000102996826171875 40\n",
      "0.005650043487548828 337\n",
      "0.0013201236724853516 160\n",
      "0.0001609325408935547 40\n",
      "0.003156900405883789 337\n",
      "0.001028299331665039 160\n",
      "9.512901306152344e-05 40\n",
      "0.006383180618286133 337\n",
      "0.0015392303466796875 160\n",
      "0.00010704994201660156 40\n",
      "0.006804943084716797 337\n",
      "0.0013699531555175781 160\n",
      "0.00011277198791503906 40\n",
      "0.002597808837890625 337\n",
      "0.0004951953887939453 160\n",
      "5.984306335449219e-05 40\n",
      "Epoch 15, Validation Loss: 0.6908\n",
      "0.005398988723754883 337\n",
      "0.0013391971588134766 160\n",
      "0.00013375282287597656 40\n",
      "0.005808830261230469 337\n",
      "0.0013108253479003906 160\n",
      "0.0001289844512939453 40\n",
      "0.00556492805480957 337\n",
      "0.0013148784637451172 160\n",
      "0.000125885009765625 40\n",
      "0.006033897399902344 337\n",
      "0.001210927963256836 160\n",
      "0.00014209747314453125 40\n",
      "0.005883932113647461 337\n",
      "0.00121307373046875 160\n",
      "0.0001220703125 40\n",
      "0.005460977554321289 337\n",
      "0.0012118816375732422 160\n",
      "0.00011110305786132812 40\n",
      "0.005544900894165039 337\n",
      "0.0012962818145751953 160\n",
      "0.0001780986785888672 40\n",
      "0.0057871341705322266 337\n",
      "0.0012128353118896484 160\n",
      "0.00015687942504882812 40\n",
      "0.0059888362884521484 337\n",
      "0.0012111663818359375 160\n",
      "0.0001418590545654297 40\n",
      "0.006223917007446289 337\n",
      "0.0015630722045898438 160\n",
      "0.00012421607971191406 40\n",
      "0.005622148513793945 337\n",
      "0.001264333724975586 160\n",
      "0.00012493133544921875 40\n",
      "0.005709171295166016 337\n",
      "0.0012409687042236328 160\n",
      "0.00026607513427734375 40\n",
      "0.005458831787109375 337\n",
      "0.0011990070343017578 160\n",
      "0.00011587142944335938 40\n",
      "0.005364894866943359 337\n",
      "0.001361846923828125 160\n",
      "0.00024127960205078125 40\n",
      "0.00558018684387207 337\n",
      "0.001741647720336914 160\n",
      "0.0001239776611328125 40\n",
      "0.005790233612060547 337\n",
      "0.0012400150299072266 160\n",
      "0.00011992454528808594 40\n",
      "0.005647182464599609 337\n",
      "0.001249074935913086 160\n",
      "0.00011301040649414062 40\n",
      "0.005847930908203125 337\n",
      "0.001230001449584961 160\n",
      "0.00014209747314453125 40\n",
      "0.005795001983642578 337\n",
      "0.0012121200561523438 160\n",
      "0.0001571178436279297 40\n",
      "0.005693912506103516 337\n",
      "0.0012841224670410156 160\n",
      "0.0003001689910888672 40\n",
      "0.005506038665771484 337\n",
      "0.0013189315795898438 160\n",
      "0.00014781951904296875 40\n",
      "0.0031516551971435547 337\n",
      "0.0009107589721679688 160\n",
      "0.00017380714416503906 40\n",
      "0.0072400569915771484 337\n",
      "0.0016820430755615234 160\n",
      "0.0002579689025878906 40\n",
      "0.00779414176940918 337\n",
      "0.0018401145935058594 160\n",
      "0.00038313865661621094 40\n",
      "0.002839803695678711 337\n",
      "0.0007250308990478516 160\n",
      "0.0010631084442138672 40\n",
      "Epoch 16, Validation Loss: 0.7089\n",
      "0.006665945053100586 337\n",
      "0.001806020736694336 160\n",
      "0.00024127960205078125 40\n",
      "0.006431102752685547 337\n",
      "0.0015621185302734375 160\n",
      "0.0001468658447265625 40\n",
      "0.006352901458740234 337\n",
      "0.001232147216796875 160\n",
      "0.00011992454528808594 40\n",
      "0.005560159683227539 337\n",
      "0.0015060901641845703 160\n",
      "0.0001270771026611328 40\n",
      "0.005596160888671875 337\n",
      "0.0012140274047851562 160\n",
      "0.00018310546875 40\n",
      "0.005814075469970703 337\n",
      "0.0012009143829345703 160\n",
      "0.0001499652862548828 40\n",
      "0.005526065826416016 337\n",
      "0.0012509822845458984 160\n",
      "0.0002391338348388672 40\n",
      "0.005764007568359375 337\n",
      "0.0012030601501464844 160\n",
      "0.00019979476928710938 40\n",
      "0.0056610107421875 337\n",
      "0.00121307373046875 160\n",
      "0.0002129077911376953 40\n",
      "0.005753040313720703 337\n",
      "0.001313924789428711 160\n",
      "0.00014472007751464844 40\n",
      "0.005448818206787109 337\n",
      "0.0012998580932617188 160\n",
      "0.00019097328186035156 40\n",
      "0.006242990493774414 337\n",
      "0.0012247562408447266 160\n",
      "0.0001628398895263672 40\n",
      "0.00619196891784668 337\n",
      "0.0012021064758300781 160\n",
      "0.00013685226440429688 40\n",
      "0.005508899688720703 337\n",
      "0.0015249252319335938 160\n",
      "0.0001277923583984375 40\n",
      "0.005614042282104492 337\n",
      "0.0019142627716064453 160\n",
      "0.000186920166015625 40\n",
      "0.0057332515716552734 337\n",
      "0.0017170906066894531 160\n",
      "0.00014328956604003906 40\n",
      "0.0057489871978759766 337\n",
      "0.0016450881958007812 160\n",
      "0.0001430511474609375 40\n",
      "0.005738019943237305 337\n",
      "0.001171112060546875 160\n",
      "0.00018715858459472656 40\n",
      "0.00583195686340332 337\n",
      "0.0012278556823730469 160\n",
      "0.0001590251922607422 40\n",
      "0.0062770843505859375 337\n",
      "0.0012841224670410156 160\n",
      "0.0001552104949951172 40\n",
      "0.005548000335693359 337\n",
      "0.0012621879577636719 160\n",
      "0.0001270771026611328 40\n",
      "0.0032448768615722656 337\n",
      "0.0007030963897705078 160\n",
      "0.00010585784912109375 40\n",
      "0.006131887435913086 337\n",
      "0.0015339851379394531 160\n",
      "0.00015592575073242188 40\n",
      "0.006873130798339844 337\n",
      "0.0015070438385009766 160\n",
      "0.0001800060272216797 40\n",
      "0.0027561187744140625 337\n",
      "0.0006439685821533203 160\n",
      "8.225440979003906e-05 40\n",
      "Epoch 17, Validation Loss: 0.6607\n",
      "0.0060999393463134766 337\n",
      "0.0013608932495117188 160\n",
      "0.00015306472778320312 40\n",
      "0.005589962005615234 337\n",
      "0.0013170242309570312 160\n",
      "0.00012683868408203125 40\n",
      "0.005931854248046875 337\n",
      "0.0011949539184570312 160\n",
      "0.0002529621124267578 40\n",
      "0.005506992340087891 337\n",
      "0.001322031021118164 160\n",
      "0.00013685226440429688 40\n",
      "0.005675077438354492 337\n",
      "0.001222848892211914 160\n",
      "0.00011897087097167969 40\n",
      "0.0056149959564208984 337\n",
      "0.001341104507446289 160\n",
      "0.00011277198791503906 40\n",
      "0.005680084228515625 337\n",
      "0.0012197494506835938 160\n",
      "0.0002579689025878906 40\n",
      "0.005629301071166992 337\n",
      "0.00150299072265625 160\n",
      "0.00012111663818359375 40\n",
      "0.005521059036254883 337\n",
      "0.001538991928100586 160\n",
      "0.000125885009765625 40\n",
      "0.005697011947631836 337\n",
      "0.001558065414428711 160\n",
      "0.00014519691467285156 40\n",
      "0.005488157272338867 337\n",
      "0.0012819766998291016 160\n",
      "0.0001590251922607422 40\n",
      "0.005494117736816406 337\n",
      "0.0012700557708740234 160\n",
      "0.00015997886657714844 40\n",
      "0.0061151981353759766 337\n",
      "0.0012860298156738281 160\n",
      "0.00015997886657714844 40\n",
      "0.0055468082427978516 337\n",
      "0.0012133121490478516 160\n",
      "0.00011610984802246094 40\n",
      "0.005709171295166016 337\n",
      "0.0012412071228027344 160\n",
      "0.00012183189392089844 40\n",
      "0.005420684814453125 337\n",
      "0.0012791156768798828 160\n",
      "0.00017309188842773438 40\n",
      "0.005969047546386719 337\n",
      "0.0013158321380615234 160\n",
      "0.00012111663818359375 40\n",
      "0.005450010299682617 337\n",
      "0.0012331008911132812 160\n",
      "0.00011014938354492188 40\n",
      "0.005786895751953125 337\n",
      "0.0012238025665283203 160\n",
      "0.00016188621520996094 40\n",
      "0.005759000778198242 337\n",
      "0.0013041496276855469 160\n",
      "0.00018477439880371094 40\n",
      "0.006406068801879883 337\n",
      "0.0014729499816894531 160\n",
      "0.00011801719665527344 40\n",
      "0.003931283950805664 337\n",
      "0.0010020732879638672 160\n",
      "0.0001609325408935547 40\n",
      "0.007788181304931641 337\n",
      "0.0021119117736816406 160\n",
      "0.00013303756713867188 40\n",
      "0.008442878723144531 337\n",
      "0.002053976058959961 160\n",
      "0.00013685226440429688 40\n",
      "0.003142118453979492 337\n",
      "0.0008261203765869141 160\n",
      "0.0005550384521484375 40\n",
      "Epoch 18, Validation Loss: 0.6005\n",
      "0.006721019744873047 337\n",
      "0.0016300678253173828 160\n",
      "0.00011992454528808594 40\n",
      "0.0065958499908447266 337\n",
      "0.0016307830810546875 160\n",
      "0.0002799034118652344 40\n",
      "0.006883144378662109 337\n",
      "0.0017223358154296875 160\n",
      "0.00018310546875 40\n",
      "0.005600929260253906 337\n",
      "0.0014600753784179688 160\n",
      "0.0001957416534423828 40\n",
      "0.005702018737792969 337\n",
      "0.0017461776733398438 160\n",
      "0.00017404556274414062 40\n",
      "0.005818843841552734 337\n",
      "0.0012359619140625 160\n",
      "0.00012803077697753906 40\n",
      "0.0057871341705322266 337\n",
      "0.0013151168823242188 160\n",
      "0.00023293495178222656 40\n",
      "0.005873203277587891 337\n",
      "0.0012969970703125 160\n",
      "0.00011968612670898438 40\n",
      "0.008810281753540039 337\n",
      "0.0012230873107910156 160\n",
      "0.0001442432403564453 40\n",
      "0.0059740543365478516 337\n",
      "0.0013051033020019531 160\n",
      "0.00020241737365722656 40\n",
      "0.005936145782470703 337\n",
      "0.0012159347534179688 160\n",
      "0.00016117095947265625 40\n",
      "0.005516767501831055 337\n",
      "0.0013549327850341797 160\n",
      "0.00013399124145507812 40\n",
      "0.005697965621948242 337\n",
      "0.0012962818145751953 160\n",
      "0.00011920928955078125 40\n",
      "0.0061380863189697266 337\n",
      "0.0013039112091064453 160\n",
      "0.0001220703125 40\n",
      "0.005636930465698242 337\n",
      "0.0015079975128173828 160\n",
      "0.00011491775512695312 40\n",
      "0.005713224411010742 337\n",
      "0.0012040138244628906 160\n",
      "0.000125885009765625 40\n",
      "0.006065845489501953 337\n",
      "0.0013010501861572266 160\n",
      "0.00012683868408203125 40\n",
      "0.0056569576263427734 337\n",
      "0.0012500286102294922 160\n",
      "0.00011181831359863281 40\n",
      "0.005485057830810547 337\n",
      "0.0014388561248779297 160\n",
      "0.00013303756713867188 40\n",
      "0.005670785903930664 337\n",
      "0.0014369487762451172 160\n",
      "0.00015020370483398438 40\n",
      "0.005880117416381836 337\n",
      "0.0015060901641845703 160\n",
      "0.0001468658447265625 40\n",
      "0.0031349658966064453 337\n",
      "0.0006961822509765625 160\n",
      "0.00011205673217773438 40\n",
      "0.007354736328125 337\n",
      "0.0015270709991455078 160\n",
      "0.00010085105895996094 40\n",
      "0.007163286209106445 337\n",
      "0.0017580986022949219 160\n",
      "0.00010991096496582031 40\n",
      "0.0028390884399414062 337\n",
      "0.00051116943359375 160\n",
      "5.0067901611328125e-05 40\n",
      "Epoch 19, Validation Loss: 0.6540\n",
      "Early stopping after epoch 19 with validation loss 0.3776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FLANN(\n",
       "  (activation): ReLU()\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=337, out_features=160, bias=True)\n",
       "    (1): Linear(in_features=160, out_features=40, bias=True)\n",
       "    (2): Linear(in_features=40, out_features=10, bias=True)\n",
       "  )\n",
       "  (linear_norms): ModuleList(\n",
       "    (0): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (flas): ModuleList(\n",
       "    (0-2): 3 x FLAttention(\n",
       "      (alphas): ParameterDict(\n",
       "          (query_0): Parameter containing: [torch.FloatTensor of size 1]\n",
       "          (key_0): Parameter containing: [torch.FloatTensor of size 1]\n",
       "          (value_0): Parameter containing: [torch.FloatTensor of size 1]\n",
       "      )\n",
       "      (betas): ParameterDict(\n",
       "          (query_0): Parameter containing: [torch.FloatTensor of size 1]\n",
       "          (key_0): Parameter containing: [torch.FloatTensor of size 1]\n",
       "          (value_0): Parameter containing: [torch.FloatTensor of size 1]\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fla_norms): ModuleList(\n",
       "    (0): LayerNorm((337,), eps=1e-05, elementwise_affine=True)\n",
       "    (1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output): Linear(in_features=10, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "patience = 10\n",
    "early_stop_counter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    for inputs, labels in val_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels)\n",
    "            val_losses.append(val_loss.item())\n",
    "    \n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}')\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_model = model.state_dict()\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "    \n",
    "    if early_stop_counter >= patience:\n",
    "        print(f'Early stopping after epoch {epoch+1} with validation loss {best_val_loss:.4f}')\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007419109344482422 337\n",
      "0.0022988319396972656 160\n",
      "0.00013303756713867188 40\n",
      "0.007727146148681641 337\n",
      "0.0019152164459228516 160\n",
      "0.0002319812774658203 40\n",
      "0.007494211196899414 337\n",
      "0.00133514404296875 160\n",
      "0.0001728534698486328 40\n",
      "0.006352901458740234 337\n",
      "0.0015790462493896484 160\n",
      "0.00010704994201660156 40\n",
      "0.006112098693847656 337\n",
      "0.001466989517211914 160\n",
      "0.0001049041748046875 40\n",
      "0.006390094757080078 337\n",
      "0.0015370845794677734 160\n",
      "0.00018715858459472656 40\n",
      "Test Loss: 0.5382, Test Score: 0.8750, Predicted Proba: 0.5838\n"
     ]
    }
   ],
   "source": [
    "test_losses = []\n",
    "test_predictions = []\n",
    "test_true_labels = []\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        test_loss = criterion(outputs, labels)\n",
    "        test_losses.append(test_loss.item())\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        test_predictions.extend(predictions.cpu().numpy())\n",
    "        test_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = np.mean(test_losses)\n",
    "test_score = f1_score(test_true_labels, test_predictions, average='weighted')\n",
    "print(f'Test Loss: {avg_test_loss:.4f}, Test Score: {test_score:.4f}, Predicted Proba: {1/np.exp(avg_test_loss):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.1070], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1401], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.7694], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.5956], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4241], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.4487], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for x in model.flas[0].parameters():\n",
    "    print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
