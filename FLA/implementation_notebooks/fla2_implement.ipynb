{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import fla2 as a\n",
    "import pickle as pkl\n",
    "from torch.utils.data import DataLoader\n",
    "from main import npDataset\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from importlib import reload\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd=os.getcwd()\n",
    "with open(f\"{cwd}/data/diabetes/X.pkl\", \"rb\") as file:\n",
    "    X = pkl.load(file)\n",
    "with open(f\"{cwd}/data/diabetes/y.pkl\", \"rb\") as file:\n",
    "    y = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_counts = np.unique(y, return_counts=True)[1]\n",
    "weight = torch.tensor([y_counts[0]/y_counts[1]], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed 1, with 1 heads\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "was expecting embedding dimension of 2, but got 108",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m start_f \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 44\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m end_f \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     46\u001b[0m forward_times\u001b[38;5;241m.\u001b[39mappend(end_f\u001b[38;5;241m-\u001b[39mstart_f)\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/FLA/fla2.py:28\u001b[0m, in \u001b[0;36mTabularAttentionClassifier.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add sequence length dimension: (1, batch_size, embed_dim)\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attn_layer, fc_layer, layer_norm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norms):\n\u001b[0;32m---> 28\u001b[0m     attn_output, _ \u001b[38;5;241m=\u001b[39m \u001b[43mattn_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Multi-head attention\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     x \u001b[38;5;241m=\u001b[39m attn_output \u001b[38;5;241m+\u001b[39m x  \u001b[38;5;66;03m# Residual connection\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (1, batch_size, dim) -> (batch_size, 1, dim)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/.venv/lib/python3.11/site-packages/torch/nn/modules/activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1253\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1254\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1264\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/Documents/Python Projects/Feature Level Attention/Feature_Level_Attention/.venv/lib/python3.11/site-packages/torch/nn/functional.py:5344\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5339\u001b[0m         \u001b[38;5;66;03m# We have the attn_mask, and use that to merge kpm into it.\u001b[39;00m\n\u001b[1;32m   5340\u001b[0m         \u001b[38;5;66;03m# Turn off use of is_causal hint, as the merged mask is no\u001b[39;00m\n\u001b[1;32m   5341\u001b[0m         \u001b[38;5;66;03m# longer causal.\u001b[39;00m\n\u001b[1;32m   5342\u001b[0m         is_causal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m embed_dim \u001b[38;5;241m==\u001b[39m embed_dim_to_check, \\\n\u001b[1;32m   5345\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwas expecting embedding dimension of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_dim_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membed_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(embed_dim, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m   5347\u001b[0m     \u001b[38;5;66;03m# embed_dim can be a tensor when JIT tracing\u001b[39;00m\n\u001b[1;32m   5348\u001b[0m     head_dim \u001b[38;5;241m=\u001b[39m embed_dim\u001b[38;5;241m.\u001b[39mdiv(num_heads, rounding_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrunc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: was expecting embedding dimension of 2, but got 108"
     ]
    }
   ],
   "source": [
    "reload(a)\n",
    "head_counts = [1,2,3,4]\n",
    "test_prediction_dict = {h: [] for h in head_counts}\n",
    "test_label_list = []\n",
    "losses = {h: [] for h in head_counts}\n",
    "\n",
    "forward_times = []\n",
    "loss_times = []\n",
    "backwards_times = []\n",
    "optimizer_times = []\n",
    "\n",
    "for seed in range(10):\n",
    "    for i, head in enumerate(head_counts):\n",
    "        print(f'seed {seed+1}, with {head} heads')\n",
    "        #split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.2, random_state=seed)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train,y_train, stratify=y_train, test_size=0.1, random_state=seed)\n",
    "        train_dataset = npDataset(X_train,y_train)\n",
    "        test_dataset = npDataset(X_test,y_test)\n",
    "        val_dataset = npDataset(X_val,y_val)\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        #make model\n",
    "        hidden_dims = [50,25,10]\n",
    "        embed_dim = head\n",
    "        model = a.TabularAttentionClassifier(input_dim=108, embed_dim=2*head, hidden_dims=hidden_dims, num_heads=head)\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        #train\n",
    "        num_epochs = 500\n",
    "        best_val_loss = float('inf')\n",
    "        best_model = None\n",
    "        patience = 10\n",
    "        early_stop_counter = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                start_f = time.time()\n",
    "                outputs = model(inputs)\n",
    "                end_f = time.time()\n",
    "                forward_times.append(end_f-start_f)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                start_l = time.time()\n",
    "                loss = criterion(outputs, labels)\n",
    "                end_l = time.time()\n",
    "                loss_times.append(end_l-start_l)\n",
    "                start_b = time.time()\n",
    "                loss.backward()\n",
    "                end_b = time.time()\n",
    "                backwards_times.append(end_b-start_b)\n",
    "                start_o = time.time()\n",
    "                optimizer.step()\n",
    "                end_o = time.time()\n",
    "                optimizer_times.append(end_o-start_o)\n",
    "\n",
    "            model.eval()\n",
    "            val_losses = []\n",
    "            for inputs, labels in val_loader:\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(inputs)\n",
    "                    labels = labels.unsqueeze(1)\n",
    "                    val_loss = criterion(outputs, labels)\n",
    "                    val_losses.append(val_loss.item())\n",
    "            \n",
    "            avg_val_loss = np.mean(val_losses)\n",
    "            print(f'Epoch {epoch+1}, Validation Loss: {avg_val_loss:.4f}')\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                best_model = model.state_dict()\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "            \n",
    "            if early_stop_counter >= patience:\n",
    "                print(f'Early stopping after epoch {epoch+1} with validation loss {best_val_loss:.4f}')\n",
    "                break\n",
    "            \n",
    "        model.load_state_dict(best_model)\n",
    "\n",
    "        #eval\n",
    "        test_losses = []\n",
    "        test_predictions = []\n",
    "        test_true_labels = []\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.unsqueeze(1)\n",
    "                test_loss = criterion(outputs, labels)\n",
    "                test_losses.append(test_loss.item())\n",
    "                test_predictions.extend(outputs.cpu().numpy())\n",
    "                test_true_labels.extend(labels.cpu().numpy())\n",
    "        avg_test_loss = np.mean(test_losses)\n",
    "        test_predictions_f1 = [y>0.5 for y in test_predictions]\n",
    "        test_score = f1_score(test_true_labels, test_predictions_f1)\n",
    "        print(f'Test Loss: {avg_test_loss:.4f}, Test Score: {test_score:.4f} for seed {seed+1} and {head} heads.')\n",
    "        if i == 0:\n",
    "            test_label_list.append(test_true_labels)\n",
    "        test_prediction_dict[head].append(test_predictions)\n",
    "        losses[head].append(avg_test_loss)\n",
    "with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/fla2/diabetes/test_pred_dict_1_to_4.pkl\", \"wb\") as file:\n",
    "    pkl.dump(test_prediction_dict, file=file)\n",
    "with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/fla2/diabetes/test_losses_dict_1_to_4.pkl\", \"wb\") as file:\n",
    "    pkl.dump(losses, file=file)\n",
    "with open (\"/Users/aviadsusman/Documents/Python_Projects/FeatureLevelAttention/FLA/results/fla2/diabetes/test_labels.pkl\", \"wb\") as file:\n",
    "    pkl.dump(test_label_list, file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.2212318], dtype=float32),\n",
       " array([0.18830653], dtype=float32),\n",
       " array([0.4394591], dtype=float32),\n",
       " array([-1.0474021], dtype=float32),\n",
       " array([0.23518611], dtype=float32),\n",
       " array([0.01598065], dtype=float32),\n",
       " array([-0.9846909], dtype=float32),\n",
       " array([0.5603118], dtype=float32),\n",
       " array([0.8618928], dtype=float32),\n",
       " array([-1.1921793], dtype=float32),\n",
       " array([-0.43146533], dtype=float32),\n",
       " array([-0.8783313], dtype=float32),\n",
       " array([-0.07539515], dtype=float32),\n",
       " array([0.59515655], dtype=float32),\n",
       " array([1.1372019], dtype=float32),\n",
       " array([1.0608116], dtype=float32),\n",
       " array([-0.0414625], dtype=float32),\n",
       " array([-0.35973752], dtype=float32),\n",
       " array([0.9244994], dtype=float32),\n",
       " array([-1.2234756], dtype=float32),\n",
       " array([-0.72969186], dtype=float32),\n",
       " array([0.00058858], dtype=float32),\n",
       " array([0.6104087], dtype=float32),\n",
       " array([-1.2745628], dtype=float32),\n",
       " array([0.48556817], dtype=float32),\n",
       " array([-0.08482729], dtype=float32),\n",
       " array([-1.1975491], dtype=float32),\n",
       " array([0.21402432], dtype=float32),\n",
       " array([0.96594477], dtype=float32),\n",
       " array([0.02646022], dtype=float32),\n",
       " array([-0.7382663], dtype=float32),\n",
       " array([-1.338781], dtype=float32),\n",
       " array([0.9124966], dtype=float32),\n",
       " array([-1.314562], dtype=float32),\n",
       " array([0.0541292], dtype=float32),\n",
       " array([0.17576508], dtype=float32),\n",
       " array([0.5647603], dtype=float32),\n",
       " array([-0.22638862], dtype=float32),\n",
       " array([-1.1182759], dtype=float32),\n",
       " array([0.1736048], dtype=float32),\n",
       " array([0.60218924], dtype=float32),\n",
       " array([0.77072245], dtype=float32),\n",
       " array([-0.45087826], dtype=float32),\n",
       " array([-0.17043082], dtype=float32),\n",
       " array([0.8201369], dtype=float32),\n",
       " array([-0.56587064], dtype=float32),\n",
       " array([0.18548577], dtype=float32),\n",
       " array([0.8208728], dtype=float32),\n",
       " array([0.4541412], dtype=float32),\n",
       " array([-1.2792054], dtype=float32),\n",
       " array([0.64082825], dtype=float32),\n",
       " array([-0.4246863], dtype=float32),\n",
       " array([0.702612], dtype=float32),\n",
       " array([0.490766], dtype=float32),\n",
       " array([0.57563484], dtype=float32),\n",
       " array([0.552096], dtype=float32),\n",
       " array([0.0496053], dtype=float32),\n",
       " array([-1.2334813], dtype=float32),\n",
       " array([-1.096227], dtype=float32),\n",
       " array([-1.3155812], dtype=float32),\n",
       " array([1.0898799], dtype=float32),\n",
       " array([0.5642644], dtype=float32),\n",
       " array([0.28853917], dtype=float32),\n",
       " array([-1.3335806], dtype=float32),\n",
       " array([0.9405098], dtype=float32),\n",
       " array([0.4949156], dtype=float32),\n",
       " array([0.38972765], dtype=float32),\n",
       " array([0.36000216], dtype=float32),\n",
       " array([-0.53802025], dtype=float32),\n",
       " array([-1.1741451], dtype=float32),\n",
       " array([-0.93304884], dtype=float32),\n",
       " array([-0.06054346], dtype=float32),\n",
       " array([0.19360985], dtype=float32),\n",
       " array([0.6847733], dtype=float32),\n",
       " array([-1.3122323], dtype=float32),\n",
       " array([0.23727332], dtype=float32),\n",
       " array([0.18787561], dtype=float32),\n",
       " array([0.8234807], dtype=float32),\n",
       " array([-1.3160528], dtype=float32),\n",
       " array([0.41880685], dtype=float32),\n",
       " array([1.6536895], dtype=float32),\n",
       " array([0.42618865], dtype=float32),\n",
       " array([-0.1089078], dtype=float32),\n",
       " array([0.51700217], dtype=float32),\n",
       " array([-1.2878879], dtype=float32),\n",
       " array([0.49431944], dtype=float32),\n",
       " array([0.722924], dtype=float32),\n",
       " array([0.8935207], dtype=float32),\n",
       " array([-1.0821197], dtype=float32),\n",
       " array([-1.299076], dtype=float32),\n",
       " array([0.7444803], dtype=float32),\n",
       " array([0.4509309], dtype=float32),\n",
       " array([-0.31480747], dtype=float32),\n",
       " array([0.7779489], dtype=float32),\n",
       " array([1.3548241], dtype=float32),\n",
       " array([-1.3060635], dtype=float32),\n",
       " array([-1.1477886], dtype=float32),\n",
       " array([0.43803942], dtype=float32),\n",
       " array([0.32470387], dtype=float32),\n",
       " array([0.7402427], dtype=float32),\n",
       " array([-0.94180036], dtype=float32),\n",
       " array([-1.3205981], dtype=float32),\n",
       " array([-1.3198016], dtype=float32),\n",
       " array([-1.2585942], dtype=float32),\n",
       " array([0.39936703], dtype=float32),\n",
       " array([0.523685], dtype=float32),\n",
       " array([0.13636573], dtype=float32),\n",
       " array([-0.8586345], dtype=float32),\n",
       " array([1.444112], dtype=float32),\n",
       " array([0.49964845], dtype=float32),\n",
       " array([1.6405824], dtype=float32),\n",
       " array([0.6033375], dtype=float32),\n",
       " array([0.26623446], dtype=float32),\n",
       " array([0.7961268], dtype=float32),\n",
       " array([-1.3208354], dtype=float32),\n",
       " array([0.34806132], dtype=float32),\n",
       " array([-1.2804261], dtype=float32),\n",
       " array([0.15964957], dtype=float32),\n",
       " array([-0.7994921], dtype=float32),\n",
       " array([0.25452662], dtype=float32),\n",
       " array([-1.1344888], dtype=float32),\n",
       " array([0.41044593], dtype=float32),\n",
       " array([1.4678612], dtype=float32),\n",
       " array([-1.2304178], dtype=float32),\n",
       " array([0.42121094], dtype=float32),\n",
       " array([-1.244183], dtype=float32),\n",
       " array([0.7769394], dtype=float32),\n",
       " array([-1.2740837], dtype=float32),\n",
       " array([0.9426311], dtype=float32),\n",
       " array([-0.218114], dtype=float32),\n",
       " array([0.78164905], dtype=float32),\n",
       " array([-0.29082835], dtype=float32),\n",
       " array([-1.3300817], dtype=float32),\n",
       " array([0.16563196], dtype=float32),\n",
       " array([0.98819786], dtype=float32),\n",
       " array([-1.3123783], dtype=float32),\n",
       " array([0.45594978], dtype=float32),\n",
       " array([-1.3334842], dtype=float32),\n",
       " array([-0.77440274], dtype=float32),\n",
       " array([1.2595298], dtype=float32),\n",
       " array([0.47332495], dtype=float32),\n",
       " array([-1.2591716], dtype=float32),\n",
       " array([1.0599537], dtype=float32),\n",
       " array([-1.1615205], dtype=float32),\n",
       " array([0.5484788], dtype=float32),\n",
       " array([-0.7988962], dtype=float32),\n",
       " array([-1.3109279], dtype=float32),\n",
       " array([0.98869765], dtype=float32),\n",
       " array([0.62685955], dtype=float32),\n",
       " array([0.94632095], dtype=float32),\n",
       " array([0.7940224], dtype=float32),\n",
       " array([0.3000784], dtype=float32),\n",
       " array([0.13089843], dtype=float32),\n",
       " array([0.12550645], dtype=float32),\n",
       " array([0.77626675], dtype=float32),\n",
       " array([0.6671951], dtype=float32),\n",
       " array([0.26442772], dtype=float32),\n",
       " array([1.661511], dtype=float32),\n",
       " array([-1.3353225], dtype=float32),\n",
       " array([0.18083386], dtype=float32),\n",
       " array([-0.7844652], dtype=float32),\n",
       " array([1.1672755], dtype=float32),\n",
       " array([0.603691], dtype=float32),\n",
       " array([-0.99507046], dtype=float32),\n",
       " array([-1.3022135], dtype=float32),\n",
       " array([-1.3330988], dtype=float32),\n",
       " array([0.39180988], dtype=float32),\n",
       " array([0.06464915], dtype=float32),\n",
       " array([0.4070369], dtype=float32),\n",
       " array([-1.2493002], dtype=float32),\n",
       " array([0.00730972], dtype=float32),\n",
       " array([-1.2487811], dtype=float32),\n",
       " array([0.04011144], dtype=float32),\n",
       " array([-1.0470986], dtype=float32),\n",
       " array([-1.272616], dtype=float32),\n",
       " array([0.49907726], dtype=float32),\n",
       " array([0.42923176], dtype=float32),\n",
       " array([-1.2504047], dtype=float32),\n",
       " array([0.18188871], dtype=float32),\n",
       " array([0.16890155], dtype=float32),\n",
       " array([-0.89295304], dtype=float32),\n",
       " array([-0.39848197], dtype=float32),\n",
       " array([-1.3182961], dtype=float32),\n",
       " array([-1.1110983], dtype=float32),\n",
       " array([0.01295854], dtype=float32),\n",
       " array([-0.5926622], dtype=float32),\n",
       " array([1.1025225], dtype=float32),\n",
       " array([0.91744137], dtype=float32),\n",
       " array([0.93771386], dtype=float32),\n",
       " array([0.15075935], dtype=float32),\n",
       " array([1.0566745], dtype=float32),\n",
       " array([1.6579758], dtype=float32),\n",
       " array([0.72576725], dtype=float32),\n",
       " array([1.1271694], dtype=float32),\n",
       " array([0.5746021], dtype=float32),\n",
       " array([-0.6033563], dtype=float32),\n",
       " array([-0.6297237], dtype=float32),\n",
       " array([-1.201771], dtype=float32),\n",
       " array([-0.06452911], dtype=float32),\n",
       " array([0.7852757], dtype=float32),\n",
       " array([0.2487752], dtype=float32),\n",
       " array([-0.21885721], dtype=float32),\n",
       " array([-1.1504885], dtype=float32),\n",
       " array([-1.303347], dtype=float32),\n",
       " array([0.5466648], dtype=float32),\n",
       " array([-1.3077229], dtype=float32),\n",
       " array([0.66069216], dtype=float32),\n",
       " array([0.71246266], dtype=float32),\n",
       " array([0.11466984], dtype=float32),\n",
       " array([0.9353055], dtype=float32),\n",
       " array([-0.42215204], dtype=float32),\n",
       " array([0.8019834], dtype=float32),\n",
       " array([0.33597684], dtype=float32),\n",
       " array([-1.3273977], dtype=float32),\n",
       " array([1.0456629], dtype=float32),\n",
       " array([-1.335367], dtype=float32),\n",
       " array([-1.2414018], dtype=float32),\n",
       " array([-1.2688063], dtype=float32),\n",
       " array([-1.2694052], dtype=float32),\n",
       " array([-0.19949059], dtype=float32),\n",
       " array([0.65035486], dtype=float32),\n",
       " array([0.8636969], dtype=float32),\n",
       " array([-1.3349622], dtype=float32),\n",
       " array([-1.1369251], dtype=float32),\n",
       " array([-0.16009097], dtype=float32),\n",
       " array([0.31691974], dtype=float32),\n",
       " array([-0.951959], dtype=float32),\n",
       " array([-1.2645022], dtype=float32),\n",
       " array([-0.20099528], dtype=float32),\n",
       " array([1.4657179], dtype=float32),\n",
       " array([0.32644296], dtype=float32),\n",
       " array([-0.68769825], dtype=float32),\n",
       " array([0.47832954], dtype=float32),\n",
       " array([0.366574], dtype=float32),\n",
       " array([-0.96764696], dtype=float32),\n",
       " array([-0.27151585], dtype=float32),\n",
       " array([0.6097276], dtype=float32),\n",
       " array([0.90763825], dtype=float32),\n",
       " array([0.07008015], dtype=float32),\n",
       " array([-1.2642121], dtype=float32),\n",
       " array([1.6492405], dtype=float32),\n",
       " array([0.39989698], dtype=float32),\n",
       " array([-1.0564531], dtype=float32),\n",
       " array([0.34668237], dtype=float32),\n",
       " array([0.26667607], dtype=float32),\n",
       " array([0.19880272], dtype=float32),\n",
       " array([0.32400417], dtype=float32),\n",
       " array([-1.2323729], dtype=float32),\n",
       " array([0.40600914], dtype=float32),\n",
       " array([0.4104684], dtype=float32),\n",
       " array([0.6687104], dtype=float32),\n",
       " array([0.8857012], dtype=float32),\n",
       " array([0.37809783], dtype=float32),\n",
       " array([-1.3150694], dtype=float32),\n",
       " array([1.1946325], dtype=float32),\n",
       " array([-0.9677795], dtype=float32),\n",
       " array([-0.12270589], dtype=float32),\n",
       " array([-0.5528083], dtype=float32),\n",
       " array([-1.2185869], dtype=float32),\n",
       " array([0.76817733], dtype=float32),\n",
       " array([0.52689683], dtype=float32),\n",
       " array([-0.09273081], dtype=float32),\n",
       " array([0.45362687], dtype=float32),\n",
       " array([1.2056829], dtype=float32),\n",
       " array([-0.7612332], dtype=float32),\n",
       " array([-0.00324829], dtype=float32),\n",
       " array([-1.2891611], dtype=float32),\n",
       " array([0.49696833], dtype=float32),\n",
       " array([0.29106134], dtype=float32),\n",
       " array([0.6635699], dtype=float32),\n",
       " array([0.7319994], dtype=float32),\n",
       " array([-0.03809969], dtype=float32),\n",
       " array([0.3168683], dtype=float32),\n",
       " array([0.09547143], dtype=float32),\n",
       " array([-1.2971842], dtype=float32),\n",
       " array([0.5605053], dtype=float32),\n",
       " array([1.2528992], dtype=float32),\n",
       " array([0.93980396], dtype=float32),\n",
       " array([0.35246944], dtype=float32),\n",
       " array([0.4799375], dtype=float32),\n",
       " array([1.1090522], dtype=float32),\n",
       " array([0.14990695], dtype=float32),\n",
       " array([-1.3315562], dtype=float32),\n",
       " array([0.9916953], dtype=float32),\n",
       " array([0.44547743], dtype=float32),\n",
       " array([-1.2975248], dtype=float32),\n",
       " array([0.72031933], dtype=float32),\n",
       " array([0.5369169], dtype=float32),\n",
       " array([-0.9191696], dtype=float32),\n",
       " array([-0.21928911], dtype=float32),\n",
       " array([0.33653593], dtype=float32),\n",
       " array([-0.5263379], dtype=float32),\n",
       " array([-0.6884593], dtype=float32),\n",
       " array([0.36340392], dtype=float32),\n",
       " array([-0.49207926], dtype=float32),\n",
       " array([-1.3329127], dtype=float32),\n",
       " array([0.55485165], dtype=float32),\n",
       " array([0.37757385], dtype=float32),\n",
       " array([-1.3321037], dtype=float32),\n",
       " array([0.36259508], dtype=float32),\n",
       " array([0.55850583], dtype=float32),\n",
       " array([-1.1850069], dtype=float32),\n",
       " array([0.6329421], dtype=float32),\n",
       " array([-1.2804052], dtype=float32),\n",
       " array([-0.6929034], dtype=float32),\n",
       " array([0.11944567], dtype=float32),\n",
       " array([-1.0361643], dtype=float32),\n",
       " array([-1.2990028], dtype=float32),\n",
       " array([-1.1988803], dtype=float32),\n",
       " array([0.7584141], dtype=float32),\n",
       " array([-1.3351282], dtype=float32),\n",
       " array([0.2648455], dtype=float32),\n",
       " array([-1.3087882], dtype=float32),\n",
       " array([1.0158759], dtype=float32),\n",
       " array([-0.00578104], dtype=float32),\n",
       " array([-1.2318667], dtype=float32),\n",
       " array([-1.3288268], dtype=float32),\n",
       " array([1.1525205], dtype=float32),\n",
       " array([-1.313264], dtype=float32),\n",
       " array([-1.2184087], dtype=float32),\n",
       " array([0.7790433], dtype=float32),\n",
       " array([-1.3333133], dtype=float32),\n",
       " array([-0.75770485], dtype=float32),\n",
       " array([0.47949606], dtype=float32),\n",
       " array([-1.2487804], dtype=float32),\n",
       " array([-0.8885366], dtype=float32),\n",
       " array([0.35759777], dtype=float32),\n",
       " array([0.09095766], dtype=float32),\n",
       " array([0.7322684], dtype=float32),\n",
       " array([0.14656399], dtype=float32),\n",
       " array([0.62214124], dtype=float32),\n",
       " array([-1.3299335], dtype=float32),\n",
       " array([0.61747473], dtype=float32),\n",
       " array([0.66181713], dtype=float32),\n",
       " array([-1.335565], dtype=float32),\n",
       " array([-1.2460523], dtype=float32),\n",
       " array([1.4841489], dtype=float32),\n",
       " array([0.55161524], dtype=float32),\n",
       " array([-1.2982832], dtype=float32),\n",
       " array([-0.6865159], dtype=float32),\n",
       " array([-0.13061835], dtype=float32),\n",
       " array([-1.285004], dtype=float32),\n",
       " array([-0.12970541], dtype=float32),\n",
       " array([0.23600782], dtype=float32),\n",
       " array([-1.3240613], dtype=float32),\n",
       " array([0.3544131], dtype=float32),\n",
       " array([-1.1758167], dtype=float32),\n",
       " array([-1.029037], dtype=float32),\n",
       " array([0.56379986], dtype=float32),\n",
       " array([0.20622148], dtype=float32),\n",
       " array([0.8171617], dtype=float32),\n",
       " array([-0.6835115], dtype=float32),\n",
       " array([-1.3028127], dtype=float32),\n",
       " array([-1.1569109], dtype=float32),\n",
       " array([0.40068132], dtype=float32),\n",
       " array([0.52149785], dtype=float32),\n",
       " array([0.7366872], dtype=float32),\n",
       " array([-1.0927125], dtype=float32),\n",
       " array([0.01956545], dtype=float32),\n",
       " array([0.28173912], dtype=float32),\n",
       " array([0.34497446], dtype=float32),\n",
       " array([0.3349595], dtype=float32),\n",
       " array([1.4425293], dtype=float32),\n",
       " array([-0.42935264], dtype=float32),\n",
       " array([-1.3249356], dtype=float32),\n",
       " array([-1.0218432], dtype=float32),\n",
       " array([0.44533926], dtype=float32),\n",
       " array([0.06390144], dtype=float32),\n",
       " array([0.9097831], dtype=float32),\n",
       " array([0.43384236], dtype=float32),\n",
       " array([-1.025664], dtype=float32),\n",
       " array([0.51964957], dtype=float32),\n",
       " array([0.80896187], dtype=float32),\n",
       " array([-0.08079718], dtype=float32),\n",
       " array([0.61682], dtype=float32),\n",
       " array([-1.3212832], dtype=float32),\n",
       " array([0.89698476], dtype=float32),\n",
       " array([0.02475353], dtype=float32),\n",
       " array([-1.1527765], dtype=float32),\n",
       " array([0.8833009], dtype=float32),\n",
       " array([-1.3216318], dtype=float32),\n",
       " array([-0.24767934], dtype=float32),\n",
       " array([-0.91048414], dtype=float32),\n",
       " array([0.91738546], dtype=float32),\n",
       " array([-1.3107308], dtype=float32),\n",
       " array([0.05785115], dtype=float32),\n",
       " array([-1.3323249], dtype=float32),\n",
       " array([0.58525735], dtype=float32),\n",
       " array([0.05978175], dtype=float32),\n",
       " array([0.07283036], dtype=float32),\n",
       " array([-0.03649531], dtype=float32),\n",
       " array([1.2669717], dtype=float32),\n",
       " array([-1.3205186], dtype=float32),\n",
       " array([-0.16998832], dtype=float32),\n",
       " array([0.49125296], dtype=float32),\n",
       " array([-0.4054948], dtype=float32),\n",
       " array([0.75823224], dtype=float32),\n",
       " array([-0.06101649], dtype=float32),\n",
       " array([0.47343987], dtype=float32),\n",
       " array([0.8533869], dtype=float32),\n",
       " array([0.31963623], dtype=float32),\n",
       " array([1.023996], dtype=float32),\n",
       " array([0.5438619], dtype=float32),\n",
       " array([0.7328081], dtype=float32),\n",
       " array([0.5725691], dtype=float32),\n",
       " array([1.1264184], dtype=float32),\n",
       " array([0.59481806], dtype=float32),\n",
       " array([0.85442775], dtype=float32),\n",
       " array([0.91693735], dtype=float32),\n",
       " array([-0.549149], dtype=float32),\n",
       " array([-1.2424213], dtype=float32),\n",
       " array([0.6092222], dtype=float32),\n",
       " array([0.8885392], dtype=float32),\n",
       " array([-0.5883094], dtype=float32),\n",
       " array([0.68087685], dtype=float32),\n",
       " array([-0.6084985], dtype=float32),\n",
       " array([-0.03165685], dtype=float32),\n",
       " array([0.80373585], dtype=float32),\n",
       " array([-0.7567627], dtype=float32),\n",
       " array([-1.2927308], dtype=float32),\n",
       " array([0.38147342], dtype=float32),\n",
       " array([0.04417904], dtype=float32),\n",
       " array([-1.2423624], dtype=float32),\n",
       " array([-0.9808563], dtype=float32),\n",
       " array([0.05323599], dtype=float32),\n",
       " array([-1.3338419], dtype=float32),\n",
       " array([-1.3312192], dtype=float32),\n",
       " array([0.26890522], dtype=float32),\n",
       " array([-1.3041745], dtype=float32),\n",
       " array([-1.3228626], dtype=float32),\n",
       " array([1.0114167], dtype=float32),\n",
       " array([0.4899029], dtype=float32),\n",
       " array([1.1567922], dtype=float32),\n",
       " array([-0.18436189], dtype=float32),\n",
       " array([0.84523255], dtype=float32),\n",
       " array([0.9280819], dtype=float32),\n",
       " array([0.4985115], dtype=float32),\n",
       " array([1.2625676], dtype=float32),\n",
       " array([0.7054452], dtype=float32),\n",
       " array([-0.48234177], dtype=float32),\n",
       " array([0.9152993], dtype=float32),\n",
       " array([-1.3230363], dtype=float32),\n",
       " array([0.7999128], dtype=float32),\n",
       " array([0.01319976], dtype=float32),\n",
       " array([0.34533852], dtype=float32),\n",
       " array([0.5763587], dtype=float32),\n",
       " array([0.4988379], dtype=float32),\n",
       " array([0.18932383], dtype=float32),\n",
       " array([0.5902594], dtype=float32),\n",
       " array([0.57124275], dtype=float32),\n",
       " array([0.9745624], dtype=float32),\n",
       " array([0.22383465], dtype=float32),\n",
       " array([0.49504125], dtype=float32),\n",
       " array([-1.3351427], dtype=float32),\n",
       " array([0.5326626], dtype=float32),\n",
       " array([1.0148659], dtype=float32),\n",
       " array([0.17240216], dtype=float32),\n",
       " array([0.2354122], dtype=float32),\n",
       " array([0.24072425], dtype=float32),\n",
       " array([0.93820494], dtype=float32),\n",
       " array([0.46403706], dtype=float32),\n",
       " array([0.80563486], dtype=float32),\n",
       " array([0.6207072], dtype=float32),\n",
       " array([0.94018483], dtype=float32),\n",
       " array([0.56691235], dtype=float32),\n",
       " array([-1.3202336], dtype=float32),\n",
       " array([0.80232793], dtype=float32),\n",
       " array([-1.2058554], dtype=float32),\n",
       " array([0.20949279], dtype=float32),\n",
       " array([-1.3335483], dtype=float32),\n",
       " array([0.32397783], dtype=float32),\n",
       " array([-0.7558458], dtype=float32),\n",
       " array([0.04044147], dtype=float32),\n",
       " array([0.05704625], dtype=float32),\n",
       " array([0.5847435], dtype=float32),\n",
       " array([0.5778856], dtype=float32),\n",
       " array([1.3393167], dtype=float32),\n",
       " array([-1.332033], dtype=float32),\n",
       " array([-1.2864678], dtype=float32),\n",
       " array([0.4704244], dtype=float32),\n",
       " array([0.20944561], dtype=float32),\n",
       " array([-1.063119], dtype=float32),\n",
       " array([-0.0316536], dtype=float32),\n",
       " array([0.35043097], dtype=float32),\n",
       " array([0.33361483], dtype=float32),\n",
       " array([-1.3100163], dtype=float32),\n",
       " array([0.63006526], dtype=float32),\n",
       " array([0.5736526], dtype=float32),\n",
       " array([0.3031242], dtype=float32),\n",
       " array([-1.332355], dtype=float32),\n",
       " array([0.09762116], dtype=float32),\n",
       " array([-1.2206494], dtype=float32),\n",
       " array([-1.3323538], dtype=float32),\n",
       " array([0.30790144], dtype=float32),\n",
       " array([0.59310305], dtype=float32),\n",
       " array([-0.5328943], dtype=float32),\n",
       " array([0.6295597], dtype=float32),\n",
       " array([0.480511], dtype=float32),\n",
       " array([0.5329823], dtype=float32),\n",
       " array([0.08102532], dtype=float32),\n",
       " array([-1.3219644], dtype=float32),\n",
       " array([-1.204775], dtype=float32),\n",
       " array([0.50247204], dtype=float32),\n",
       " array([0.37772918], dtype=float32),\n",
       " array([0.59873414], dtype=float32),\n",
       " array([-1.3211243], dtype=float32),\n",
       " array([-0.60207385], dtype=float32),\n",
       " array([-1.3128434], dtype=float32),\n",
       " array([0.08929192], dtype=float32),\n",
       " array([0.45047784], dtype=float32),\n",
       " array([-1.1383704], dtype=float32),\n",
       " array([-1.296839], dtype=float32),\n",
       " array([0.25036973], dtype=float32),\n",
       " array([0.21560518], dtype=float32),\n",
       " array([0.76250696], dtype=float32),\n",
       " array([0.43673158], dtype=float32),\n",
       " array([-1.3178489], dtype=float32),\n",
       " array([0.7239397], dtype=float32),\n",
       " array([0.48096687], dtype=float32),\n",
       " array([-0.649738], dtype=float32),\n",
       " array([-0.9115697], dtype=float32),\n",
       " array([-1.3323914], dtype=float32),\n",
       " array([0.430897], dtype=float32),\n",
       " array([-1.259833], dtype=float32),\n",
       " array([1.4539052], dtype=float32),\n",
       " array([0.80257136], dtype=float32),\n",
       " array([-1.2726943], dtype=float32),\n",
       " array([-0.6433877], dtype=float32),\n",
       " array([0.65512025], dtype=float32),\n",
       " array([0.6110681], dtype=float32),\n",
       " array([1.0426528], dtype=float32),\n",
       " array([0.09189095], dtype=float32),\n",
       " array([0.44221205], dtype=float32),\n",
       " array([0.6946289], dtype=float32),\n",
       " array([0.48913193], dtype=float32),\n",
       " array([0.9070301], dtype=float32),\n",
       " array([0.1650338], dtype=float32),\n",
       " array([-1.2588624], dtype=float32),\n",
       " array([0.5543316], dtype=float32),\n",
       " array([0.06296913], dtype=float32),\n",
       " array([0.44895482], dtype=float32),\n",
       " array([1.1027851], dtype=float32),\n",
       " array([-1.2956643], dtype=float32),\n",
       " array([0.97794735], dtype=float32),\n",
       " array([-1.336986], dtype=float32),\n",
       " array([0.5865452], dtype=float32),\n",
       " array([0.5417376], dtype=float32),\n",
       " array([0.34286577], dtype=float32),\n",
       " array([-1.3143245], dtype=float32),\n",
       " array([0.69185656], dtype=float32),\n",
       " array([0.06087856], dtype=float32),\n",
       " array([0.9718643], dtype=float32),\n",
       " array([0.7155458], dtype=float32),\n",
       " array([0.4527226], dtype=float32),\n",
       " array([1.0108945], dtype=float32),\n",
       " array([0.6137811], dtype=float32),\n",
       " array([-1.0375284], dtype=float32),\n",
       " array([0.51352453], dtype=float32),\n",
       " array([-1.2868623], dtype=float32),\n",
       " array([0.6052656], dtype=float32),\n",
       " array([-1.3343838], dtype=float32),\n",
       " array([-1.3029155], dtype=float32),\n",
       " array([0.4157164], dtype=float32),\n",
       " array([-1.279352], dtype=float32),\n",
       " array([1.3359691], dtype=float32),\n",
       " array([0.5321639], dtype=float32),\n",
       " array([0.6259578], dtype=float32),\n",
       " array([1.6506141], dtype=float32),\n",
       " array([0.6820675], dtype=float32),\n",
       " array([-1.031734], dtype=float32),\n",
       " array([-1.2798463], dtype=float32),\n",
       " array([0.9077013], dtype=float32),\n",
       " array([0.19066681], dtype=float32),\n",
       " array([-1.120259], dtype=float32),\n",
       " array([-0.25971514], dtype=float32),\n",
       " array([-1.1881708], dtype=float32),\n",
       " array([0.05551045], dtype=float32),\n",
       " array([0.46080863], dtype=float32),\n",
       " array([0.19607054], dtype=float32),\n",
       " array([-1.2508026], dtype=float32),\n",
       " array([-0.8938864], dtype=float32),\n",
       " array([0.008624], dtype=float32),\n",
       " array([-1.3322881], dtype=float32),\n",
       " array([0.33762974], dtype=float32),\n",
       " array([-0.26275146], dtype=float32),\n",
       " array([0.48629475], dtype=float32),\n",
       " array([0.84515643], dtype=float32),\n",
       " array([-1.0535809], dtype=float32),\n",
       " array([-0.20043932], dtype=float32),\n",
       " array([-1.1483141], dtype=float32),\n",
       " array([-0.9212661], dtype=float32),\n",
       " array([-0.5675138], dtype=float32),\n",
       " array([0.8254946], dtype=float32),\n",
       " array([0.82154894], dtype=float32),\n",
       " array([0.7282122], dtype=float32),\n",
       " array([1.2306223], dtype=float32),\n",
       " array([-0.12330951], dtype=float32),\n",
       " array([0.58777624], dtype=float32),\n",
       " array([0.09598942], dtype=float32),\n",
       " array([1.6369411], dtype=float32),\n",
       " array([-1.1999226], dtype=float32),\n",
       " array([0.6099696], dtype=float32),\n",
       " array([1.1136925], dtype=float32),\n",
       " array([-1.3355184], dtype=float32),\n",
       " array([1.5029168], dtype=float32),\n",
       " array([-1.2280023], dtype=float32),\n",
       " array([-1.2518024], dtype=float32),\n",
       " array([0.8896573], dtype=float32),\n",
       " array([0.82724375], dtype=float32),\n",
       " array([0.5224717], dtype=float32),\n",
       " array([-1.1046803], dtype=float32),\n",
       " array([-0.9669186], dtype=float32),\n",
       " array([-1.1511004], dtype=float32),\n",
       " array([1.355551], dtype=float32),\n",
       " array([0.28306675], dtype=float32),\n",
       " array([0.37899035], dtype=float32),\n",
       " array([1.0759326], dtype=float32),\n",
       " array([-0.17656003], dtype=float32),\n",
       " array([-1.2861997], dtype=float32),\n",
       " array([-1.2702203], dtype=float32),\n",
       " array([-1.327865], dtype=float32),\n",
       " array([-0.9221509], dtype=float32),\n",
       " array([0.00974347], dtype=float32),\n",
       " array([0.21941419], dtype=float32),\n",
       " array([0.27364403], dtype=float32),\n",
       " array([-1.275922], dtype=float32),\n",
       " array([-0.7753749], dtype=float32),\n",
       " array([-1.331638], dtype=float32),\n",
       " array([1.2310853], dtype=float32),\n",
       " array([0.15940739], dtype=float32),\n",
       " array([0.3617437], dtype=float32),\n",
       " array([-1.3061099], dtype=float32),\n",
       " array([-0.29431963], dtype=float32),\n",
       " array([0.55233645], dtype=float32),\n",
       " array([-0.6290442], dtype=float32),\n",
       " array([0.23249717], dtype=float32),\n",
       " array([0.68910754], dtype=float32),\n",
       " array([-1.1140572], dtype=float32),\n",
       " array([0.31576234], dtype=float32),\n",
       " array([-0.59551764], dtype=float32),\n",
       " array([-0.18372299], dtype=float32),\n",
       " array([0.16347207], dtype=float32),\n",
       " array([-0.62293935], dtype=float32),\n",
       " array([-1.2175528], dtype=float32),\n",
       " array([-1.298451], dtype=float32),\n",
       " array([-0.45351875], dtype=float32),\n",
       " array([-0.90991974], dtype=float32),\n",
       " array([-0.10380195], dtype=float32),\n",
       " array([-1.3225528], dtype=float32),\n",
       " array([0.15305619], dtype=float32),\n",
       " array([0.7433356], dtype=float32),\n",
       " array([0.24864252], dtype=float32),\n",
       " array([0.00170158], dtype=float32),\n",
       " array([0.41492152], dtype=float32),\n",
       " array([-0.17676164], dtype=float32),\n",
       " array([0.8514838], dtype=float32),\n",
       " array([0.90746504], dtype=float32),\n",
       " array([0.8600762], dtype=float32),\n",
       " array([0.17304261], dtype=float32),\n",
       " array([1.4484295], dtype=float32),\n",
       " array([0.11572082], dtype=float32),\n",
       " array([0.9020031], dtype=float32),\n",
       " array([0.9426943], dtype=float32),\n",
       " array([-1.063047], dtype=float32),\n",
       " array([1.0517073], dtype=float32),\n",
       " array([-0.35416466], dtype=float32),\n",
       " array([-1.242838], dtype=float32),\n",
       " array([0.00748368], dtype=float32),\n",
       " array([-1.3288358], dtype=float32),\n",
       " array([-0.27940017], dtype=float32),\n",
       " array([0.38390398], dtype=float32),\n",
       " array([1.0795527], dtype=float32),\n",
       " array([-1.3358713], dtype=float32),\n",
       " array([-0.6880462], dtype=float32),\n",
       " array([-0.713634], dtype=float32),\n",
       " array([0.1957872], dtype=float32),\n",
       " array([0.37968558], dtype=float32),\n",
       " array([-0.5404081], dtype=float32),\n",
       " array([0.20489337], dtype=float32),\n",
       " array([0.50637954], dtype=float32),\n",
       " array([0.24652253], dtype=float32),\n",
       " array([-1.2693844], dtype=float32),\n",
       " array([0.08534659], dtype=float32),\n",
       " array([0.55378884], dtype=float32),\n",
       " array([0.22221877], dtype=float32),\n",
       " array([-1.1965345], dtype=float32),\n",
       " array([-1.3037328], dtype=float32),\n",
       " array([0.28827477], dtype=float32),\n",
       " array([0.10449864], dtype=float32),\n",
       " array([0.3762226], dtype=float32),\n",
       " array([0.81712973], dtype=float32),\n",
       " array([0.7895343], dtype=float32),\n",
       " array([1.0570021], dtype=float32),\n",
       " array([0.13275422], dtype=float32),\n",
       " array([-0.8350771], dtype=float32),\n",
       " array([0.10706796], dtype=float32),\n",
       " array([-0.77401644], dtype=float32),\n",
       " array([1.586275], dtype=float32),\n",
       " array([-1.3139981], dtype=float32),\n",
       " array([-1.0673729], dtype=float32),\n",
       " array([0.7255352], dtype=float32),\n",
       " array([0.43922746], dtype=float32),\n",
       " array([1.2146677], dtype=float32),\n",
       " array([-1.3143013], dtype=float32),\n",
       " array([-1.3168042], dtype=float32),\n",
       " array([0.29238415], dtype=float32),\n",
       " array([-1.3232956], dtype=float32),\n",
       " array([-0.8604131], dtype=float32),\n",
       " array([1.4521354], dtype=float32),\n",
       " array([0.1132694], dtype=float32),\n",
       " array([-0.47973984], dtype=float32),\n",
       " array([-1.3025112], dtype=float32),\n",
       " array([-0.76694167], dtype=float32),\n",
       " array([0.31316572], dtype=float32),\n",
       " array([1.2130872], dtype=float32),\n",
       " array([-1.2877308], dtype=float32),\n",
       " array([-1.3162127], dtype=float32),\n",
       " array([-1.3350334], dtype=float32),\n",
       " array([0.6509968], dtype=float32),\n",
       " array([1.0655795], dtype=float32),\n",
       " array([-1.3122617], dtype=float32),\n",
       " array([0.40463316], dtype=float32),\n",
       " array([0.9004974], dtype=float32),\n",
       " array([0.7626158], dtype=float32),\n",
       " array([-1.3299229], dtype=float32),\n",
       " array([-1.2254506], dtype=float32),\n",
       " array([-0.520638], dtype=float32),\n",
       " array([-1.3141992], dtype=float32),\n",
       " array([1.5867412], dtype=float32),\n",
       " array([0.5253366], dtype=float32),\n",
       " array([-0.60739565], dtype=float32),\n",
       " array([-0.6114743], dtype=float32),\n",
       " array([-1.3338599], dtype=float32),\n",
       " array([0.6147503], dtype=float32),\n",
       " array([0.2763871], dtype=float32),\n",
       " array([0.51964605], dtype=float32),\n",
       " array([-0.3073107], dtype=float32),\n",
       " array([0.18162121], dtype=float32),\n",
       " array([0.84712815], dtype=float32),\n",
       " array([-1.3114249], dtype=float32),\n",
       " array([-1.3329693], dtype=float32),\n",
       " array([0.49694663], dtype=float32),\n",
       " array([-0.7602682], dtype=float32),\n",
       " array([-1.3342117], dtype=float32),\n",
       " array([0.5923946], dtype=float32),\n",
       " array([0.60084724], dtype=float32),\n",
       " array([0.44831657], dtype=float32),\n",
       " array([0.9512338], dtype=float32),\n",
       " array([0.50446403], dtype=float32),\n",
       " array([0.12596928], dtype=float32),\n",
       " array([-1.227316], dtype=float32),\n",
       " array([-1.0172943], dtype=float32),\n",
       " array([-1.324176], dtype=float32),\n",
       " array([0.9628463], dtype=float32),\n",
       " array([-0.04851253], dtype=float32),\n",
       " array([1.641333], dtype=float32),\n",
       " array([0.21900754], dtype=float32),\n",
       " array([0.07755546], dtype=float32),\n",
       " array([0.5640853], dtype=float32),\n",
       " array([-0.6884099], dtype=float32),\n",
       " array([0.8355141], dtype=float32),\n",
       " array([0.41391325], dtype=float32),\n",
       " array([-0.64636284], dtype=float32),\n",
       " array([-0.02102323], dtype=float32),\n",
       " array([0.5261704], dtype=float32),\n",
       " array([-1.1192364], dtype=float32),\n",
       " array([-1.3358217], dtype=float32),\n",
       " array([-0.34956485], dtype=float32),\n",
       " array([0.9760925], dtype=float32),\n",
       " array([-0.8877032], dtype=float32),\n",
       " array([-1.2831329], dtype=float32),\n",
       " array([-0.05235527], dtype=float32),\n",
       " array([0.6646992], dtype=float32),\n",
       " array([0.41366255], dtype=float32),\n",
       " array([-1.3087215], dtype=float32),\n",
       " array([0.17448129], dtype=float32),\n",
       " array([-1.3305894], dtype=float32),\n",
       " array([-1.3350855], dtype=float32),\n",
       " array([-1.30721], dtype=float32),\n",
       " array([0.72363454], dtype=float32),\n",
       " array([-1.3332347], dtype=float32),\n",
       " array([-1.2084931], dtype=float32),\n",
       " array([0.12015148], dtype=float32),\n",
       " array([0.6662707], dtype=float32),\n",
       " array([-1.290088], dtype=float32),\n",
       " array([0.69914085], dtype=float32),\n",
       " array([1.2105001], dtype=float32),\n",
       " array([0.8085803], dtype=float32),\n",
       " array([0.917715], dtype=float32),\n",
       " array([-1.3312724], dtype=float32),\n",
       " array([0.43925303], dtype=float32),\n",
       " array([0.0158173], dtype=float32),\n",
       " array([0.892076], dtype=float32),\n",
       " array([-1.3096579], dtype=float32),\n",
       " array([0.45752162], dtype=float32),\n",
       " array([-1.1389434], dtype=float32),\n",
       " array([-1.3053643], dtype=float32),\n",
       " array([0.26741982], dtype=float32),\n",
       " array([-0.74159575], dtype=float32),\n",
       " array([1.1258566], dtype=float32),\n",
       " array([0.7101097], dtype=float32),\n",
       " array([0.2574802], dtype=float32),\n",
       " array([0.38088584], dtype=float32),\n",
       " array([0.30391413], dtype=float32),\n",
       " array([0.11195333], dtype=float32),\n",
       " array([0.20900603], dtype=float32),\n",
       " array([-0.9888834], dtype=float32),\n",
       " array([0.47682917], dtype=float32),\n",
       " array([0.83478403], dtype=float32),\n",
       " array([-1.1892833], dtype=float32),\n",
       " array([0.04477082], dtype=float32),\n",
       " array([0.44565713], dtype=float32),\n",
       " array([0.25248283], dtype=float32),\n",
       " array([0.771187], dtype=float32),\n",
       " array([-0.5951173], dtype=float32),\n",
       " array([-1.2944016], dtype=float32),\n",
       " array([0.4690302], dtype=float32),\n",
       " array([0.35046375], dtype=float32),\n",
       " array([0.6407937], dtype=float32),\n",
       " array([0.5293972], dtype=float32),\n",
       " array([0.00610961], dtype=float32),\n",
       " array([1.1914247], dtype=float32),\n",
       " array([-1.3267981], dtype=float32),\n",
       " array([0.58851415], dtype=float32),\n",
       " array([1.1640847], dtype=float32),\n",
       " array([-0.7322073], dtype=float32),\n",
       " array([-0.48694658], dtype=float32),\n",
       " array([1.6540143], dtype=float32),\n",
       " array([-0.9619936], dtype=float32),\n",
       " array([0.0097238], dtype=float32),\n",
       " array([0.56507695], dtype=float32),\n",
       " array([-1.3245108], dtype=float32),\n",
       " array([-0.86169994], dtype=float32),\n",
       " array([0.4747666], dtype=float32),\n",
       " array([-1.2206789], dtype=float32),\n",
       " array([0.15851544], dtype=float32),\n",
       " array([-0.55721986], dtype=float32),\n",
       " array([0.08230568], dtype=float32),\n",
       " array([-1.2753297], dtype=float32),\n",
       " array([-1.1691808], dtype=float32),\n",
       " array([-0.4384678], dtype=float32),\n",
       " array([-1.3356797], dtype=float32),\n",
       " array([-1.2996219], dtype=float32),\n",
       " array([1.6455573], dtype=float32),\n",
       " array([-0.6796118], dtype=float32),\n",
       " array([-1.3205544], dtype=float32),\n",
       " array([-1.2943535], dtype=float32),\n",
       " array([-1.2897259], dtype=float32),\n",
       " array([-0.8190212], dtype=float32),\n",
       " array([0.8156731], dtype=float32),\n",
       " array([-0.2526422], dtype=float32),\n",
       " array([-0.06196563], dtype=float32),\n",
       " array([0.499031], dtype=float32),\n",
       " array([-0.0361795], dtype=float32),\n",
       " array([-1.3345484], dtype=float32),\n",
       " array([-1.3239955], dtype=float32),\n",
       " array([-1.3341523], dtype=float32),\n",
       " array([-1.0865562], dtype=float32),\n",
       " array([0.33237636], dtype=float32),\n",
       " array([-0.26058215], dtype=float32),\n",
       " array([-1.3340724], dtype=float32),\n",
       " array([-1.2661289], dtype=float32),\n",
       " array([0.05241366], dtype=float32),\n",
       " array([-1.3037233], dtype=float32),\n",
       " array([-0.14175135], dtype=float32),\n",
       " array([1.6595392], dtype=float32),\n",
       " array([-0.20894103], dtype=float32),\n",
       " array([0.24181016], dtype=float32),\n",
       " array([0.30437624], dtype=float32),\n",
       " array([0.11751772], dtype=float32),\n",
       " array([-0.24293618], dtype=float32),\n",
       " array([0.8229949], dtype=float32),\n",
       " array([0.7391187], dtype=float32),\n",
       " array([0.25305426], dtype=float32),\n",
       " array([-1.2084002], dtype=float32),\n",
       " array([0.95908266], dtype=float32),\n",
       " array([1.632105], dtype=float32),\n",
       " array([0.9415449], dtype=float32),\n",
       " array([0.33061492], dtype=float32),\n",
       " array([-1.2830908], dtype=float32),\n",
       " array([0.39481473], dtype=float32),\n",
       " array([-1.3349817], dtype=float32),\n",
       " array([0.7369307], dtype=float32),\n",
       " array([1.6081749], dtype=float32),\n",
       " array([-1.214456], dtype=float32),\n",
       " array([-1.206741], dtype=float32),\n",
       " array([-0.66972595], dtype=float32),\n",
       " array([-0.4103018], dtype=float32),\n",
       " array([1.1288236], dtype=float32),\n",
       " array([0.25219512], dtype=float32),\n",
       " array([0.03002761], dtype=float32),\n",
       " array([0.6566164], dtype=float32),\n",
       " array([-1.3354447], dtype=float32),\n",
       " array([0.38048267], dtype=float32),\n",
       " array([-0.8080677], dtype=float32),\n",
       " array([0.60242724], dtype=float32),\n",
       " array([0.36427605], dtype=float32),\n",
       " array([0.5230185], dtype=float32),\n",
       " array([-1.2648301], dtype=float32),\n",
       " array([0.8377427], dtype=float32),\n",
       " array([0.36960256], dtype=float32),\n",
       " array([-0.2507488], dtype=float32),\n",
       " array([1.1430933], dtype=float32),\n",
       " array([0.71702015], dtype=float32),\n",
       " array([-0.22610618], dtype=float32),\n",
       " array([-1.299377], dtype=float32),\n",
       " array([-0.3978048], dtype=float32),\n",
       " array([0.14304094], dtype=float32),\n",
       " array([0.52646786], dtype=float32),\n",
       " array([1.5996784], dtype=float32),\n",
       " array([-1.3346426], dtype=float32),\n",
       " array([0.36336523], dtype=float32),\n",
       " array([-1.2942797], dtype=float32),\n",
       " array([0.71195805], dtype=float32),\n",
       " array([-1.2578555], dtype=float32),\n",
       " array([-0.9803294], dtype=float32),\n",
       " array([0.47618473], dtype=float32),\n",
       " array([1.0670453], dtype=float32),\n",
       " array([0.93542683], dtype=float32),\n",
       " array([0.50320035], dtype=float32),\n",
       " array([-0.14705397], dtype=float32),\n",
       " array([0.3414712], dtype=float32),\n",
       " array([-1.3203511], dtype=float32),\n",
       " array([-1.2818093], dtype=float32),\n",
       " array([-1.2976934], dtype=float32),\n",
       " array([0.58750534], dtype=float32),\n",
       " array([-1.1566987], dtype=float32),\n",
       " array([-1.3145436], dtype=float32),\n",
       " array([1.1136965], dtype=float32),\n",
       " array([0.15640704], dtype=float32),\n",
       " array([-0.13774674], dtype=float32),\n",
       " array([0.48568076], dtype=float32),\n",
       " array([0.8921389], dtype=float32),\n",
       " array([0.6491787], dtype=float32),\n",
       " array([-1.2963498], dtype=float32),\n",
       " array([-1.3301431], dtype=float32),\n",
       " array([1.0109432], dtype=float32),\n",
       " array([-1.2530814], dtype=float32),\n",
       " array([-1.326802], dtype=float32),\n",
       " array([-0.38528794], dtype=float32),\n",
       " array([0.6575054], dtype=float32),\n",
       " array([0.7859145], dtype=float32),\n",
       " array([-1.0489182], dtype=float32),\n",
       " array([0.7772733], dtype=float32),\n",
       " array([0.407497], dtype=float32),\n",
       " array([0.01455273], dtype=float32),\n",
       " array([-0.28752267], dtype=float32),\n",
       " array([0.5603778], dtype=float32),\n",
       " array([-0.45036942], dtype=float32),\n",
       " array([0.79463774], dtype=float32),\n",
       " array([-1.2153543], dtype=float32),\n",
       " array([-1.2236536], dtype=float32),\n",
       " array([0.9022342], dtype=float32),\n",
       " array([0.28394556], dtype=float32),\n",
       " array([-0.7566525], dtype=float32),\n",
       " array([-0.25752753], dtype=float32),\n",
       " array([0.10728313], dtype=float32),\n",
       " array([1.0278052], dtype=float32),\n",
       " array([0.88616467], dtype=float32),\n",
       " array([-0.5790585], dtype=float32),\n",
       " array([0.4966367], dtype=float32),\n",
       " array([-1.275132], dtype=float32),\n",
       " array([0.8175795], dtype=float32),\n",
       " array([0.49275136], dtype=float32),\n",
       " array([-0.55093306], dtype=float32),\n",
       " array([-0.39480436], dtype=float32),\n",
       " array([-0.30356705], dtype=float32),\n",
       " array([-1.303902], dtype=float32),\n",
       " array([-1.3229896], dtype=float32),\n",
       " array([0.67693394], dtype=float32),\n",
       " array([0.00440143], dtype=float32),\n",
       " array([-1.3125073], dtype=float32),\n",
       " array([-1.0552737], dtype=float32),\n",
       " array([0.59767], dtype=float32),\n",
       " array([-1.2044598], dtype=float32),\n",
       " array([-1.2080939], dtype=float32),\n",
       " array([0.02303858], dtype=float32),\n",
       " array([0.30493563], dtype=float32),\n",
       " array([1.5710655], dtype=float32),\n",
       " array([1.0713389], dtype=float32),\n",
       " array([1.1151776], dtype=float32),\n",
       " array([0.7971865], dtype=float32),\n",
       " array([-1.301484], dtype=float32),\n",
       " array([-1.33444], dtype=float32),\n",
       " array([0.15739004], dtype=float32),\n",
       " array([0.9599489], dtype=float32),\n",
       " array([0.44510996], dtype=float32),\n",
       " array([0.5721523], dtype=float32),\n",
       " array([-0.65658915], dtype=float32),\n",
       " array([0.04049788], dtype=float32),\n",
       " array([0.54995716], dtype=float32),\n",
       " array([0.26731545], dtype=float32),\n",
       " array([1.0595738], dtype=float32),\n",
       " array([-0.3396054], dtype=float32),\n",
       " array([0.21466072], dtype=float32),\n",
       " array([0.77196133], dtype=float32),\n",
       " array([0.26813334], dtype=float32),\n",
       " array([0.53959066], dtype=float32),\n",
       " array([-1.2474686], dtype=float32),\n",
       " array([0.22496475], dtype=float32),\n",
       " ...]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction_dict[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
