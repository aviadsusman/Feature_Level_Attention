{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([1, 5])\n",
      "torch.Size([5, 1])\n",
      "tensor([[2., 5., 4., 3., 6.]])\n",
      "tensor([[7.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [4.],\n",
      "        [7.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 1.],\n",
       "        [5., 2., 3., 4., 1.],\n",
       "        [6., 3., 4., 5., 2.],\n",
       "        [2., 1., 0., 1., 2.],\n",
       "        [5., 2., 3., 4., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 1e-8\n",
    "x = torch.randint(0,10,(5,), dtype=torch.float32)\n",
    "y = torch.randint(0,10,(5,), dtype=torch.float32)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "x = x.unsqueeze(0)\n",
    "y = y.unsqueeze(1)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x)\n",
    "print(y)\n",
    "diff_matrix = torch.abs(x - y)\n",
    "diff_matrix\n",
    "# sim_matrix = 1.0 / diff_matrix\n",
    "\n",
    "# sim_matrix = F.softmax(sim_matrix, dim=-1) / torch.sqrt(torch.tensor(y.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000e-01, 5.0000e-01, 3.3333e-01, 2.5000e-01, 1.0000e+00],\n",
       "        [2.0000e-01, 5.0000e-01, 3.3333e-01, 2.5000e-01, 1.0000e+00],\n",
       "        [1.6667e-01, 3.3333e-01, 2.5000e-01, 2.0000e-01, 5.0000e-01],\n",
       "        [5.0000e-01, 1.0000e+00, 1.0000e+08, 1.0000e+00, 5.0000e-01],\n",
       "        [2.0000e-01, 5.0000e-01, 3.3333e-01, 2.5000e-01, 1.0000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_matrix += epsilon\n",
    "sim_matrix = 1.0 / diff_matrix\n",
    "sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_matrix = F.softmax(sim_matrix, dim=-1)# / torch.sqrt(torch.tensor(y.shape[1]))\n",
    "type(sim_matrix.size(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 1])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[38, 35],\n",
       "          [23, 20],\n",
       "          [23, 20]]]),\n",
       " torch.Size([1, 3, 2]),\n",
       " tensor([[[20, 37]],\n",
       " \n",
       "         [[14, 22]],\n",
       " \n",
       "         [[14, 22]]]),\n",
       " torch.Size([3, 1, 2]),\n",
       " tensor([[[ 18,  -2],\n",
       "          [  3, -17],\n",
       "          [  3, -17]],\n",
       " \n",
       "         [[ 24,  13],\n",
       "          [  9,  -2],\n",
       "          [  9,  -2]],\n",
       " \n",
       "         [[ 24,  13],\n",
       "          [  9,  -2],\n",
       "          [  9,  -2]]]),\n",
       " torch.Size([3, 3, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_heads = 2\n",
    "dim = 3\n",
    "bsz = 5\n",
    "alphaq = torch.randint(10,(1,num_heads))\n",
    "betaq = torch.randint(10,(1,num_heads))\n",
    "alphak = torch.randint(10,(1,num_heads))\n",
    "betak = torch.randint(10,(1,num_heads))\n",
    "x = torch.randint(10,(bsz,dim,1))\n",
    "print(x.shape)\n",
    "print(alphaq.shape)\n",
    "q = (x@alphaq + torch.ones((dim,1),dtype=torch.int64)@betaq).unsqueeze(1)\n",
    "k = (x@alphak + torch.ones((dim,1), dtype=torch.int64)@betak).unsqueeze(2)\n",
    "q[0], q[0].size(), k[0], k[0].size(), (q-k)[0], ((q-k)[0]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18,  3,  3],\n",
       "        [24,  9,  9],\n",
       "        [24,  9,  9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(q-k)[0][:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h=2\n",
    "a_q = nn.Parameter(torch.Tensor(1,h))\n",
    "x = torch.rand((3,1))\n",
    "(x@a_q).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[48.,  0., 23.],\n",
      "        [50., 33., 89.],\n",
      "        [14.,  7., 86.]])\n",
      "tensor([[1.0000e+00, 1.4252e-21, 1.3888e-11],\n",
      "        [1.1548e-17, 4.7809e-25, 1.0000e+00],\n",
      "        [5.3802e-32, 4.9061e-35, 1.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "similarity = torch.randint(100,(10,3,3,2), dtype=torch.float32)\n",
    "print(similarity[0][:,:,0])\n",
    "similarity=F.softmax(similarity, dim=-2)\n",
    "print(similarity[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 8., 2.])\n",
      "tensor([[94., 59., 58.],\n",
      "        [99., 32., 68.],\n",
      "        [98., 18., 52.]])\n",
      "tensor([[92., 57., 56.],\n",
      "        [91., 24., 60.],\n",
      "        [96., 16., 50.]])\n",
      "tensor([[1.0000e+00, 6.3051e-16, 2.3195e-16],\n",
      "        [1.0000e+00, 7.9849e-30, 3.4425e-14],\n",
      "        [1.0000e+00, 1.8049e-35, 1.0531e-20]])\n",
      "torch.Size([5, 3, 1, 2])\n",
      "torch.Size([5, 3, 3, 2])\n",
      "torch.Size([5, 3, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "batch = 5\n",
    "length = 3\n",
    "heads =2\n",
    "q = torch.randint(10, (batch,length,heads), dtype=torch.float32)\n",
    "k = torch.randint(100,(batch,length,length,heads), dtype=torch.float32)\n",
    "sim = torch.abs(q.unsqueeze(2)-k)\n",
    "print(q[0,:,0])\n",
    "print(k[0,:,:,0])\n",
    "print(sim[0,:,:,0])\n",
    "print(F.softmax(sim, dim=-2)[0,:,:,0])\n",
    "print(q.unsqueeze(2).shape)\n",
    "print(k.shape)\n",
    "print(sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([92., 57., 56.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim[0,0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 10\n",
    "x = torch.rand(batch, dim)\n",
    "query_weights = torch.randint(10,(dim,num_heads), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 10]), torch.Size([10, 2]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, query_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_x = torch.stack([torch.diag(x[i]) for i in range(batch)])\n",
    "q = torch.matmul(diag_x, query_weights)\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.5160, 0.8387],\n",
      "        [0.0000, 0.9487],\n",
      "        [5.9575, 0.0000],\n",
      "        [0.0000, 0.6820],\n",
      "        [0.8469, 7.6225],\n",
      "        [1.2656, 0.9492],\n",
      "        [0.5763, 0.0000],\n",
      "        [3.7921, 0.0000],\n",
      "        [1.4309, 1.2264],\n",
      "        [0.0000, 1.0502]])\n",
      "tensor([[2, 0],\n",
      "        [3, 3],\n",
      "        [0, 0],\n",
      "        [2, 1],\n",
      "        [1, 2],\n",
      "        [1, 4],\n",
      "        [2, 4],\n",
      "        [3, 1],\n",
      "        [3, 1],\n",
      "        [0, 0]])\n",
      "tensor([[4.5160, 0.8387],\n",
      "        [3.0000, 3.9487],\n",
      "        [5.9575, 0.0000],\n",
      "        [2.0000, 1.6820],\n",
      "        [1.8469, 9.6225],\n",
      "        [2.2656, 4.9492],\n",
      "        [2.5763, 4.0000],\n",
      "        [6.7921, 1.0000],\n",
      "        [4.4309, 2.2264],\n",
      "        [0.0000, 1.0502]])\n"
     ]
    }
   ],
   "source": [
    "query_biases = torch.randint(5,(dim, num_heads))\n",
    "print(q[0])\n",
    "print(query_biases)\n",
    "full_q = q+query_biases\n",
    "print(full_q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "randint(): argument 'size' (position 2) must be tuple of ints, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: randint(): argument 'size' (position 2) must be tuple of ints, not int"
     ]
    }
   ],
   "source": [
    "k = torch.randint(10,(dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.7609, 4.4685, 4.8301, 4.6567, 4.9927], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import fla_parallelized as a\n",
    "reload(a)\n",
    "x = torch.randint(10,(10,), dtype=torch.float32)\n",
    "model = a.LinearSoftmax(10,5)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[9., 3., 3., 7., 8., 7., 4., 3., 0., 2.],\n",
       "         [6., 1., 2., 9., 9., 3., 8., 2., 4., 2.],\n",
       "         [4., 3., 1., 7., 6., 4., 1., 3., 1., 3.],\n",
       "         [9., 1., 6., 7., 3., 4., 1., 7., 5., 4.],\n",
       "         [1., 4., 8., 6., 1., 1., 3., 4., 7., 8.],\n",
       "         [8., 3., 8., 3., 6., 8., 7., 2., 1., 8.],\n",
       "         [9., 7., 2., 6., 2., 2., 7., 2., 7., 4.],\n",
       "         [3., 0., 0., 2., 1., 9., 5., 4., 5., 7.],\n",
       "         [4., 1., 2., 1., 9., 8., 4., 6., 7., 0.],\n",
       "         [7., 4., 5., 0., 4., 5., 2., 6., 7., 3.]]),\n",
       " tensor([[0.0000, 0.7746],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.7184, 0.6146],\n",
       "         [1.5866, 0.0000],\n",
       "         [1.2549, 2.4687],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.4834, 0.0000],\n",
       "         [0.3534, 0.0000],\n",
       "         [0.5376, 0.6380],\n",
       "         [0.2101, 0.6911],\n",
       "         [0.4776, 0.2762],\n",
       "         [0.6951, 0.5044],\n",
       "         [0.1637, 0.4765],\n",
       "         [0.2528, 0.8749],\n",
       "         [0.4655, 0.7006],\n",
       "         [0.7071, 0.2550],\n",
       "         [0.7649, 0.1928],\n",
       "         [0.7740, 0.3491],\n",
       "         [0.8234, 0.7709],\n",
       "         [0.9878, 0.8040],\n",
       "         [0.2264, 0.7658],\n",
       "         [0.9449, 0.7114],\n",
       "         [0.4915, 0.1764],\n",
       "         [0.9949, 0.3859],\n",
       "         [0.5085, 0.9254],\n",
       "         [0.9982, 0.3613],\n",
       "         [0.3395, 0.8802],\n",
       "         [0.4596, 0.9962]], grad_fn=<CatBackward0>))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = a.MultiActivationLinear(input_dim=10, activations=[nn.ReLU, nn.Sigmoid, a.GaussianActivation] ,nodes_per_activation=2)\n",
    "x = torch.randint(10,(10,10), dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dz/88r06kr52bj9mbdq8tdjz0m80000gn/T/ipykernel_33576/892072556.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(torch.tensor(sim([0.001,2,3,4,5,6,7]), dtype=torch.float32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([9.9987e-01, 2.7244e-05, 2.3336e-05, 2.1561e-05, 2.0549e-05, 1.9897e-05,\n",
       "        1.9442e-05])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sim(row, ep=1e-8, a=1, b=0.09):\n",
    "    return [1/(abs(a)*abs(x+b)+ep) for x in row]\n",
    "F.softmax(torch.tensor(sim([0.001,2,3,4,5,6,7]), dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.6153e-01, 2.3733e-01, 2.9955e-02, 4.1295e-01, 1.5652e-03, 1.2752e-02,\n",
       "         7.4756e-03, 9.7862e-04, 3.5584e-04, 9.8035e-05],\n",
       "        [1.5483e-04, 1.1816e-02, 2.2134e-01, 2.0559e-02, 2.3229e-01, 9.4227e-02,\n",
       "         5.5238e-02, 1.3244e-04, 5.2812e-02, 2.9224e-01],\n",
       "        [3.1097e-03, 3.2119e-02, 1.4914e-03, 5.5886e-02, 3.1437e-02, 4.6913e-03,\n",
       "         1.5015e-01, 5.3431e-02, 4.8158e-05, 2.9224e-01],\n",
       "        [5.6957e-05, 2.3733e-01, 2.2134e-01, 1.3853e-04, 2.3229e-01, 6.3489e-04,\n",
       "         1.5015e-01, 3.9480e-01, 3.9023e-01, 3.6065e-05],\n",
       "        [6.2461e-02, 5.8828e-04, 1.4914e-03, 4.1295e-01, 1.5652e-03, 6.3489e-04,\n",
       "         4.0815e-01, 3.6001e-04, 3.5584e-04, 7.2439e-04],\n",
       "        [4.2086e-04, 2.3733e-01, 2.0184e-04, 3.7656e-04, 4.2546e-03, 9.4227e-02,\n",
       "         3.7219e-04, 3.6001e-04, 1.9428e-02, 1.4550e-02],\n",
       "        [1.1440e-03, 2.3733e-01, 2.2134e-01, 2.0559e-02, 3.1437e-02, 1.7258e-03,\n",
       "         5.5238e-02, 3.9480e-01, 3.9023e-01, 2.9224e-01],\n",
       "        [1.1440e-03, 2.1642e-04, 7.4251e-05, 5.5886e-02, 2.3229e-01, 6.3489e-04,\n",
       "         2.7501e-03, 7.2311e-03, 1.4356e-01, 9.8035e-05],\n",
       "        [8.4532e-03, 1.5991e-03, 2.2134e-01, 2.0559e-02, 5.7579e-04, 9.4227e-02,\n",
       "         1.5015e-01, 2.6602e-03, 2.6293e-03, 2.6649e-04],\n",
       "        [4.6153e-01, 4.3468e-03, 8.1426e-02, 1.3853e-04, 2.3229e-01, 6.9625e-01,\n",
       "         2.0321e-02, 1.4524e-01, 3.5584e-04, 1.0751e-01]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(10,(10,10), dtype=torch.float32)\n",
    "x.softmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1, 0, 1],\n",
      "        [1, 0, 0, 1, 0],\n",
      "        [1, 0, 1, 0, 0],\n",
      "        [1, 1, 1, 0, 0],\n",
      "        [1, 0, 0, 0, 1]])\n",
      "tensor([1, 6, 7])\n",
      "tensor([[6, 6, 6, 0, 6],\n",
      "        [6, 0, 0, 6, 0],\n",
      "        [6, 0, 6, 0, 0],\n",
      "        [6, 6, 6, 0, 0],\n",
      "        [6, 0, 0, 0, 6]])\n"
     ]
    }
   ],
   "source": [
    "b=10\n",
    "d = 5\n",
    "h=3\n",
    "slice = 1\n",
    "similarity_matrix = torch.randint(2,(b,d,d,h))\n",
    "alphas = torch.randint(10,(h,))\n",
    "print(similarity_matrix[0,:,:,slice])\n",
    "print(alphas)\n",
    "print((similarity_matrix*alphas)[0,:,:,slice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non softmax time: 3.479398727416992\n",
      "softmax time: 4.029902219772339\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def compute_S_multiheaded(x, y, epsilon=1e-8):\n",
    "    x = x.unsqueeze(2)\n",
    "    y = y.unsqueeze(1)\n",
    "    \n",
    "    abs_diff = torch.abs(x - y) + epsilon\n",
    "    reciprocal_diff = 1 / abs_diff\n",
    "    \n",
    "    sum_reciprocal_diff = reciprocal_diff.sum(dim=2, keepdim=True)\n",
    "    reciprocal_diff /= (sum_reciprocal_diff * torch.sqrt(torch.tensor(x.shape[-1], dtype=reciprocal_diff.dtype)))\n",
    "    \n",
    "    return reciprocal_diff\n",
    "\n",
    "\n",
    "\n",
    "def compute_sim(x, y, epsilon=1e-8):\n",
    "    x = x.unsqueeze(1)\n",
    "    y = y.unsqueeze(2)\n",
    "    diff_matrix = torch.abs(x - y) + epsilon\n",
    "    # diff_matrix += epsilon\n",
    "    sim_matrix = torch.reciprocal(diff_matrix)\n",
    "    sim_matrix = F.softmax(sim_matrix, dim=-2) / torch.sqrt(torch.tensor(sim_matrix.shape[-1]))\n",
    "    return sim_matrix\n",
    "\n",
    "# Example usage\n",
    "batch_size = 128\n",
    "n = 400\n",
    "h=30\n",
    "\n",
    "x = torch.randint(10, (batch_size,n,h))\n",
    "y = torch.randint(10, (batch_size,n,h))\n",
    "\n",
    "start = time.time()\n",
    "compute_S_multiheaded(x, y)\n",
    "end = time.time()\n",
    "print(f'non softmax time: {end-start}')\n",
    "\n",
    "start = time.time()\n",
    "compute_sim(x, y)\n",
    "end = time.time()\n",
    "print(f'softmax time: {end-start}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
