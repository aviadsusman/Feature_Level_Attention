We attempt to transfer the mechanism and inductive bias of attention to structured data. 
Self-attention between features is achieved via affine projections for shared semantic representations followed by a similarity matrix of inverse distances between query and key pairings.
Less faithful attempts at information sharing between features in between dense layers are also implemented for comparison.
